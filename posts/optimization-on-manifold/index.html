<!doctype html><html lang=en><head><title>Optimization on manifold · Aleksandr Mikoff's blog
</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Aleksandr Mikoff"><meta name=description content="Optimization on manifold Link to heading In the following post I would like to summarize my perception of poses&rsquo; optimization problem. Such a problem often occurs in robotics and other related fields. Usually we want jointly optimize the poses, their increments and various measurements. What we want to find is such set of parameters, that minimize the sum of residuals, or differences, between the real measurements and measurements, that we derive from our state."><meta name=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="Optimization on manifold"><meta name=twitter:description content="Optimization on manifold Link to heading In the following post I would like to summarize my perception of poses&rsquo; optimization problem. Such a problem often occurs in robotics and other related fields. Usually we want jointly optimize the poses, their increments and various measurements. What we want to find is such set of parameters, that minimize the sum of residuals, or differences, between the real measurements and measurements, that we derive from our state."><meta property="og:title" content="Optimization on manifold"><meta property="og:description" content="Optimization on manifold Link to heading In the following post I would like to summarize my perception of poses&rsquo; optimization problem. Such a problem often occurs in robotics and other related fields. Usually we want jointly optimize the poses, their increments and various measurements. What we want to find is such set of parameters, that minimize the sum of residuals, or differences, between the real measurements and measurements, that we derive from our state."><meta property="og:type" content="article"><meta property="og:url" content="https://mikoff.github.io/posts/optimization-on-manifold/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-11-20T21:00:00+03:00"><meta property="article:modified_time" content="2022-11-20T21:00:00+03:00"><link rel=canonical href=https://mikoff.github.io/posts/optimization-on-manifold/><link rel=preload href=/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.577e3c5ead537873430da16f0964b754a120fd87c4e2203a00686e7c75b51378.css integrity="sha256-V348Xq1TeHNDDaFvCWS3VKEg/YfE4iA6AGhufHW1E3g=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/image.min.c1a5dfc6bac0eb1b85bcd8abf8aba0d18e0bf02fc972f9a0b17d2962f5ca8dd5.css integrity="sha256-waXfxrrA6xuFvNir+Kug0Y4L8C/JcvmgsX0pYvXKjdU=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/spoiler.min.bf901294afff95f520a8150a4df4249576eb9c49c4f40f5f9c2de750588dd594.css integrity="sha256-v5ASlK//lfUgqBUKTfQklXbrnEnE9A9fnC3nUFiN1ZQ=" crossorigin=anonymous media=screen><link rel=stylesheet href=/plugins/academic-icons/css/academicons.min.f6abb61f6b9b2e784eba22dfb93cd399ce30ee01825791830a2737d6bfcd2be9.css integrity="sha256-9qu2H2ubLnhOuiLfuTzTmc4w7gGCV5GDCic31r/NK+k=" crossorigin=anonymous media=screen><link rel=icon type=image/svg+xml href=/images/favicon.svg sizes=any><link rel=icon type=image/png href=/img/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/img/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://mikoff.github.io/>Aleksandr Mikoff's blog
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa-solid fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/about/>About</a></li><li class=navigation-item><a class=navigation-link href=/posts/>Posts</a></li><li class=navigation-item><a class=navigation-link href=/tags>Tags</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://mikoff.github.io/posts/optimization-on-manifold/>Optimization on manifold</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa-solid fa-calendar" aria-hidden=true></i>
<time datetime=2022-11-20T21:00:00+03:00>November 20, 2022
</time></span><span class=reading-time><i class="fa-solid fa-clock" aria-hidden=true></i>
10-minute read</span></div><div class=tags><i class="fa-solid fa-tag" aria-hidden=true></i>
<span class=tag><a href=/tags/optimization/>Optimization</a>
</span><span class=separator>•</span>
<span class=tag><a href=/tags/least-squares/>Least Squares</a>
</span><span class=separator>•</span>
<span class=tag><a href=/tags/factor-graph/>Factor Graph</a>
</span><span class=separator>•</span>
<span class=tag><a href=/tags/manifolds/>Manifolds</a></span></div></div></header><div class=post-content><h1 id=optimization-on-manifold>Optimization on manifold
<a class=heading-link href=#optimization-on-manifold><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><p>In the following post I would like to summarize my perception of poses&rsquo; optimization problem. Such a problem often occurs in robotics and other related fields. Usually we want jointly optimize the poses, their increments and various measurements. What we want to find is such set of parameters, that minimize the sum of residuals, or differences, between the real measurements and measurements, that we derive from our state.</p><p>Assume that we have the prior on pose of our object origin $b$ w.r.t. the world origin $w$ at time $i$ - $\mathbf{T}_{wb_i}$, we also know the prior on pose at time ${i+1}$ - $\mathbf{T}_{wb_{i+1}}$, and the relative pose between them $\mathbf{T}_{b_i b_{i+1}}$:</p>$$
\mathbf{T}_{w b_{i+1}} = \mathbf{T}_{w b_{i}}\mathbf{T}_{b_{i}b_{i+1}}.
$$<p>In such a case we have only two poses and one pose difference between them. Real-life examples are usually much more harder, and include hundreds of parameters. Nevertheless, even in such a simple case, how can we formulate it in a way that we can optimize?</p><p>If we have two poses $\mathbf{T}_{wb_i}$ and $\mathbf{T}_{wb_{i+1}}$, we can define the measurement function $\mathbf{h}$ as their composition:</p>$$
\mathbf{h}\left(\mathbf{T}_{wb_i}, \mathbf{T}_{wb_{i+1}}\right) = \hat{\mathbf{T}}_{b_{i}b_{i+1}} = \mathbf{T}_{wb_{i}}^{-1}\mathbf{T}_{wb_{i+1}}
$$<p>Now, having an estimated and real measurements we can find their difference as:</p>$$
\hat{\mathbf{T}}_{b_{i}b_{i+1}}^{-1}\mathbf{T}_{b_{i}b_{i+1}}.
$$<p>To find the minimum we should find the derivative w.r.t. the minimization parameters (our matrices!), set it to zero and solve for the parameters. Of course, we could try to directly solve such a problem, but imagine a beast that comes out as a result such attempt. There should be a better way of doing this.
This way utilizes the following math concepts:</p><ol><li>Define residuals on the tangent space of the manifold.</li><li>Use first-order approximation - it allows us to describe how the non-linear function behaves near the linearization point, and allows to deduce standard Jacobian blocks.</li><li>Use the first-order approximation to rewrite the problem in standard linear form that allows to use standard Jacobians that depend only on the measurement function.</li></ol><h2 id=residuals-minimization-on-manifold>Residuals minimization on Manifold
<a class=heading-link href=#residuals-minimization-on-manifold><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><h3 id=step-1>Step 1
<a class=heading-link href=#step-1><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>We want to minimize the following cost function:</p>$$
\left|\left|\log\left(\hat{\mathbf{T}}_{b_{i}b_{i+1}}^{-1}\mathbf{T}_{b_{i}b_{i+1}}\right)\right|\right|^2.
$$<p>We can interpret this function intuitively:</p><ul><li>by group definition if the elements $\hat{\mathbf{T}}$ and $\mathbf{T}$ are equal, then their composition $\hat{\mathbf{T}}^{-1}\mathbf{T}$ is the identity, if they differ, then the composition allows us to find this difference;</li><li>$\log$ operations maps the difference from the manifold to the tangent space, $\log: \mathcal{M} \to \mathcal{R}^3$, that is the vector space;</li><li>norm operator measures the size of our difference, since we use $\mathcal{l}^2$ norm, we can easily find the derivative.</li></ul><h3 id=step-2>Step 2
<a class=heading-link href=#step-2><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>The solution of the problem $\mathbf{L} = \arg\underset{x}{\min}||\mathbf{A}\mathbf{x} - \mathbf{b}||^2$ is well-known and can be derived quite easily:</p>$$
\mathbf{x} = (\mathbf{A}^T\mathbf{A})^{-1}\mathbf{A}^T\mathbf{b}.
$$<p>The aforementioned cost function expression, however, has the different form. But let&rsquo;s use first-order approximation for the measurement function $\mathbf{h}$, where $\delta\mathbf{x}$ is state perturbation around our current estimate $\mathbf{\hat{x}}$:</p>$$\mathbf{h}(\mathbf{\hat{x}} + \delta\mathbf{x}) \approx \mathbf{h}(\mathbf{\hat{x}}) + \mathbf{J}^{\mathbf{h}}_{\mathbf{x}}(\mathbf{\hat{x}}) \delta \mathbf{x}$$<p>After trivial rewriting we can identify the standard form:</p>$$
\mathbf{L} = \arg\underset{\delta\mathbf{x}}{\min}\left|\left| \mathbf{J}^{\mathbf{h}}_{\mathbf{x}}(\mathbf{\hat{x}}) \delta \mathbf{x} - \left(\mathbf{h}(\mathbf{\hat{x}} + \delta\mathbf{x}) - \mathbf{h}(\mathbf{\hat{x}}) \right)\right|\right|^2 ,
$$<p>noticing that $\mathbf{\hat{x}} + \delta\mathbf{x} = \mathbf{x}$, where $\mathbf{x}$ is the true state, we substitute $\mathbf{h}(\mathbf{x})$ with our measurement $\mathbf{z}$, we simplifying the expression one step further:</p>$$
\mathbf{L} = \arg\underset{\delta\mathbf{x}}{\min}\left|\left| \underbrace{\mathbf{J}^{\mathbf{h}}_{\mathbf{x}}(\mathbf{\hat{x}})}_{\vphantom{f}\mathbf{A}} \delta \mathbf{x} - \underbrace{\left(\mathbf{z} - \mathbf{h}(\mathbf{\hat{x}}) \right)}_{\vphantom{f}\mathbf{b}}\right|\right|^2.
$$<p>In this form we clearly identify the linear residuals form! Since $\mathbf{b} = \log\left(\hat{\mathbf{T}}_{b_{i}b_{i+1}}^{-1}\mathbf{T}_{b_{i}b_{i+1}}\right)$ and has vector form only one thing that is needed now is the jacobian $\mathbf{J}^{\mathbf{h}}$.</p><h3 id=step-3>Step 3
<a class=heading-link href=#step-3><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>To find the Jacobian we can use the elementary blocks and chain rule, as stated in <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>. Note, that after our former reformulation we need to find the Jacobian of the measurement function $\mathbf{h}$ w.r.t. the state, not w.r.t. the squared residual:</p>$$
\mathbf{J}^{\mathbf{h}}_{\mathbf{x}} = \frac{D \mathbf{h}(\mathbf{x})}{D \mathbf{x}}.
$$<p>Having the measurement function</p>$$\mathbf{h}\left(\mathbf{T}_{wb_i}, \mathbf{T}_{wb_{i+1}}\right) = \hat{\mathbf{T}}_{b_{i}b_{i+1}} = \mathbf{T}_{wb_{i}}^{-1}\mathbf{T}_{wb_{i+1}}$$<p>we can use the jacobians that already derived for us in the literature, for example the jacobians w.r.t. $\mathbf{T}_{wb_{i}}$ and $\mathbf{T}_{wb_{i+1}}$ can be found to be (eq. (82) and (83) in <sup id=fnref1:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>):</p>$$
\begin{gather}
\mathbf{J}^\mathbf{h}_{\mathbf{x}_{\mathbf{T}_{wb_{i}}}} = -\mathbf{J}_l^{-1}\left(\mathbf{e}\right), \\\\
\mathbf{J}^\mathbf{h}_{\mathbf{x}_{\mathbf{T}_{wb_{i+1}}}} =\mathbf{J}_r^{-1}\left(\mathbf{e}\right),
\end{gather}
$$<p>and $\mathbf{e}=\log\left(\mathbf{T}_{wb_{i}}^{-1}\mathbf{T}_{wb_{i+1}}\right) \in \mathcal{T}_{b_i}\mathcal{M}$.</p><p>Equipped with Jacobians we can write our toy problem. Assume that we know prior robot poses $\{\mathbf{T}_{wb_{1}}, \mathbf{T}_{wb_{2}}, \mathbf{T}_{wb_{3}}\} \in SE(2)$ and the measured pose increments between them $\{\mathbf{\tau}_{b_{1}b_{2}}, \mathbf{\tau}_{b_{2}b_{3}} \} \in \mathcal{T}\mathcal{M}$. Our state consist of three poses, and we have two increments. Then we can define our problem using matrices:</p>$$
\underbrace{
\begin{bmatrix}
-\mathbf{J}_l^{-1}\left(\log\left(\mathbf{T}_{wb_{1}}^{-1}\mathbf{T}_{wb_{2}}\right)\right) & \mathbf{J}_r^{-1}\left(\log\left(\mathbf{T}_{wb_{1}}^{-1}\mathbf{T}_{wb_{2}}\right)\right) & \mathbf{0}_{3\times3}\\\\
 \mathbf{0}_{3\times3} & -\mathbf{J}_l^{-1}\left(\log\left(\mathbf{T}_{wb_{2}}^{-1}\mathbf{T}_{wb_{3}}\right)\right) & \mathbf{J}_r^{-1}\left(\log\left(\mathbf{T}_{wb_{2}}^{-1}\mathbf{T}_{wb_{3}}\right)\right)
\end{bmatrix}}_{\mathbf{J}_{6\times 9}} \delta\mathbf{x} =
\underbrace{
\begin{bmatrix}
\mathbf{\tau}_{b_{1}b_{2}} - \log\left(\mathbf{T}_{wb_{1}}^{-1}\mathbf{T}_{wb_{2}}\right) \\\\
\mathbf{\tau}_{b_{2}b_{3}} - \log\left(\mathbf{T}_{wb_{2}}^{-1}\mathbf{T}_{wb_{3}}\right)
\end{bmatrix}}_{\mathbf{r}_{6\times 1}}
$$<p>This can be solved using least-squares, the errors, or perturbation can be found to be:</p>$$
\delta\mathbf{x} = \left(\mathbf{J}^T\mathbf{J}\right)^{-1}\mathbf{J}^T\mathbf{r}
$$<p>then these errors are injected into the current, or nominal state: $\mathbf{x} \leftarrow \mathbf{x} + \delta\mathbf{x}$. The procedure is repeated until convergence.
Doing so we evenly distribute the total error vector between the whole elements of the state vector. To overcome this issue we can use weighted least squares and assign weight to each residual based on our confidence in it.</p><p>Note that this problem can be described using factor graph <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>: this uncovers the close relationship between graphs and linear algebra.</p><h3 id=arbitrary-measurement-functions>Arbitrary measurement functions
<a class=heading-link href=#arbitrary-measurement-functions><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>Last thing I would like to tackle in this post is the arbitrary measurement functions.
Assume that we have a sensor that gives us the range measurements to the landmark, and the landmark position $\mathbf{p}_{wl}$ is known. How can we add such a sensor in our setup?
As usual, we have to define the measurement function $\mathbf{h}$:</p>$$
\mathbf{h}_{r}\left(\mathbf{T}_{wb}, \mathbf{p}_{wl}\right) = \sqrt{\mathbf{t}^T \mathbf{t}},
$$<p>where $\mathbf{t} = \begin{bmatrix}\mathbf{T}_{wb}^x - \mathbf{p}_{wl}^x \\ \mathbf{T}_{wb}^y - \mathbf{p}_{wl}^y\end{bmatrix}$ is the translation between origin of the body frame and the landmark.</p><p>Only one thing we need is to find the derivative of $\mathbf{h}_r$ w.r.t. our state. First, let&rsquo;s resolve the landmark position in body frame (doing so we don&rsquo;t need to calculate the difference before dot product):</p>$$
\mathbf{p}_{bl} = \mathbf{T}_{bw}\mathbf{p}_{wl} = \mathbf{T}_{wb}^{-1}\mathbf{p}_{wl}
$$<p>substituting into the $\mathbf{h}_{r}$ and extracting only pose component of state vector we get:</p>$$
\mathbf{h}_{r}\left(\mathbf{T}_{wb}, \mathbf{p}_{wl}\right) = \sqrt{\left(\mathbf{T}_{wb}^{-1}\mathbf{p}_{wl}\right)^T \left(\mathbf{T}_{wb}^{-1}\mathbf{p}_{wl}\right)},
$$<p>We can think write our measurement function $\mathbf{h}$ as composition of $\mathbf{f} \circ \mathbf{g} \circ \mathbf{n}$,
where</p><ul><li>$\mathbf{n}\left(\mathbf{T}\right) = \mathbf{T}^{-1}$;</li><li>$\mathbf{g}\left(\mathbf{T}, \mathbf{p}\right) = \mathbf{T} \mathbf{p}$;</li><li>$\mathbf{f}\left(\mathbf{p}'\right) = \sqrt{\mathbf{p'}_x^2 + \mathbf{p'}_y^2}$.</li></ul><p>The derivative w.r.t. to state can be found using chain rule:</p>$$
\mathbf{J}^{\mathbf{f}}_{\mathbf{T}} = \mathbf{J}^{\mathbf{f}}_{\mathbf{p}'} \mathbf{J}^{\mathbf{T}^{-1}\mathbf{p}}_{\mathbf{T}^{-1}} \mathbf{J}^{\mathbf{T}^{-1}}_{\mathbf{T}}.
$$<p>For $SE(2)$ the latter two are derived in <sup id=fnref2:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> by equations (166) and (62).
The derivation of $\mathbf{J}^{\mathbf{f}}_{\mathbf{p}'}$ is trivial:</p>$$
\mathbf{J}^{\mathbf{f}}_{\mathbf{p}'} = \begin{bmatrix}\frac{\mathbf{p'}_x}{r} & \frac{\mathbf{p'}_y}{r}\end{bmatrix}, ~r = \sqrt{\mathbf{p'}_x^2 + \mathbf{p'}_y^2}.
$$<p>Now, if we have two landmarks $\mathbf{l}_1$ and $\mathbf{l}_2$, and our robot sees first landmark only at $\mathbf{T}_{wb_1}$ and second landmark only at $\mathbf{T}_{wb_3}$, we have to add two extra rows at our matrix $\mathbf{J}$ to account for this data:</p>$$
\underbrace{
\begin{bmatrix}
&\mathbf{J}_{6\times 9}& \\\\
\mathbf{J}^{\mathbf{f}}_{\mathbf{T}_{wb_1}} & \mathbf{0}_{1\times 3} & \mathbf{0}_{1\times 3} \\\\
\mathbf{0}_{1\times 3} & \mathbf{0}_{1\times 3} & \mathbf{J}^{\mathbf{f}}_{\mathbf{T}_{wb_3}}
\end{bmatrix}}_{\mathbf{J}_{8\times 9}}
\delta\mathbf{x} =
\underbrace{
\begin{bmatrix}
\mathbf{r}_{6\times 1} \\\\
r_1 - \mathbf{h}_r\left( \mathbf{T}_{wb_1}, \mathbf{p}_{wl_1} \right) \\\\
r_2 - \mathbf{h}_r\left( \mathbf{T}_{wb_3}, \mathbf{p}_{wl_2} \right)
\end{bmatrix}}_{\mathbf{r}_{8\times 1}},
$$<p>where $r_1$ and $r_2$ - range measurements.</p><h2 id=implementation>Implementation
<a class=heading-link href=#implementation><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>Now let&rsquo;s give the numerical example to all aforementioned concepts and functions.</p><p>First, define all needed operations for Lie groups and associated algebras.</p><div class=spoiler><span class=spoilerText>Spoiler</span>
<input class=spoilerChecked type=checkbox showtext=Code><div class=spoilerContent><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000;font-weight:700>import</span> <span style=color:#555>numpy</span> <span style=color:#000;font-weight:700>as</span> <span style=color:#555>np</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>import</span> <span style=color:#555>scipy.linalg</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>Jr</span>(tau):
</span></span><span style=display:flex><span>    <span style=color:#d14>&#39;&#39;&#39;Right jacobian for SE2, eq. (163) from [1].&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span>    x, y, theta <span style=color:#000;font-weight:700>=</span> tau<span style=color:#000;font-weight:700>.</span>flatten()
</span></span><span style=display:flex><span>    s, c <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>sin(theta), np<span style=color:#000;font-weight:700>.</span>cos(theta)
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>return</span> np<span style=color:#000;font-weight:700>.</span>array([[s <span style=color:#000;font-weight:700>/</span> theta, (<span style=color:#099>1</span> <span style=color:#000;font-weight:700>-</span> c) <span style=color:#000;font-weight:700>/</span> theta, (theta <span style=color:#000;font-weight:700>*</span> x <span style=color:#000;font-weight:700>-</span> y <span style=color:#000;font-weight:700>+</span> y <span style=color:#000;font-weight:700>*</span> c <span style=color:#000;font-weight:700>-</span> x <span style=color:#000;font-weight:700>*</span> s) <span style=color:#000;font-weight:700>/</span> theta<span style=color:#000;font-weight:700>**</span><span style=color:#099>2</span>],
</span></span><span style=display:flex><span>                     [(c <span style=color:#000;font-weight:700>-</span> <span style=color:#099>1</span>) <span style=color:#000;font-weight:700>/</span> theta, s <span style=color:#000;font-weight:700>/</span> theta, (x <span style=color:#000;font-weight:700>+</span> theta <span style=color:#000;font-weight:700>*</span> y <span style=color:#000;font-weight:700>-</span> x <span style=color:#000;font-weight:700>*</span> c <span style=color:#000;font-weight:700>-</span> y <span style=color:#000;font-weight:700>*</span> s) <span style=color:#000;font-weight:700>/</span> theta<span style=color:#000;font-weight:700>**</span><span style=color:#099>2</span>],
</span></span><span style=display:flex><span>                     [<span style=color:#099>0.</span>, <span style=color:#099>0.</span>, <span style=color:#099>1.</span>]])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>Jl</span>(tau):
</span></span><span style=display:flex><span>    <span style=color:#d14>&#39;&#39;&#39;Left jacobian for SE2, eq. (163) from [1].&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span>    x, y, theta <span style=color:#000;font-weight:700>=</span> tau<span style=color:#000;font-weight:700>.</span>flatten()
</span></span><span style=display:flex><span>    s, c <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>sin(theta), np<span style=color:#000;font-weight:700>.</span>cos(theta)
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>return</span> np<span style=color:#000;font-weight:700>.</span>array([[s <span style=color:#000;font-weight:700>/</span> theta, (c <span style=color:#000;font-weight:700>-</span> <span style=color:#099>1</span>) <span style=color:#000;font-weight:700>/</span> theta, (theta <span style=color:#000;font-weight:700>*</span> x <span style=color:#000;font-weight:700>+</span> y <span style=color:#000;font-weight:700>-</span> y <span style=color:#000;font-weight:700>*</span> c <span style=color:#000;font-weight:700>-</span> x <span style=color:#000;font-weight:700>*</span> s) <span style=color:#000;font-weight:700>/</span> theta<span style=color:#000;font-weight:700>**</span><span style=color:#099>2</span>],
</span></span><span style=display:flex><span>                     [(<span style=color:#099>1</span> <span style=color:#000;font-weight:700>-</span> c) <span style=color:#000;font-weight:700>/</span> theta, s <span style=color:#000;font-weight:700>/</span> theta, (<span style=color:#000;font-weight:700>-</span>x <span style=color:#000;font-weight:700>+</span> theta <span style=color:#000;font-weight:700>*</span> y <span style=color:#000;font-weight:700>+</span> x <span style=color:#000;font-weight:700>*</span> c <span style=color:#000;font-weight:700>-</span> y <span style=color:#000;font-weight:700>*</span> s) <span style=color:#000;font-weight:700>/</span> theta<span style=color:#000;font-weight:700>**</span><span style=color:#099>2</span>],
</span></span><span style=display:flex><span>                     [<span style=color:#099>0.</span>, <span style=color:#099>0.</span>, <span style=color:#099>1.</span>]])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>T</span>(x, y, theta):
</span></span><span style=display:flex><span>    <span style=color:#d14>&#39;&#39;&#39;Returns transformation matrix for given x, y and theta parameters.&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>return</span> np<span style=color:#000;font-weight:700>.</span>array([[np<span style=color:#000;font-weight:700>.</span>cos(theta), <span style=color:#000;font-weight:700>-</span>np<span style=color:#000;font-weight:700>.</span>sin(theta), x], [np<span style=color:#000;font-weight:700>.</span>sin(theta), np<span style=color:#000;font-weight:700>.</span>cos(theta), y], [<span style=color:#099>0.</span>, <span style=color:#099>0.</span>, <span style=color:#099>1.</span>]])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>Exp</span>(tau):
</span></span><span style=display:flex><span>    <span style=color:#d14>&#39;&#39;&#39;Exponent, transfers Lie algebra to the group, known as retraction.&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span>    tau <span style=color:#000;font-weight:700>=</span> tau<span style=color:#000;font-weight:700>.</span>flatten()
</span></span><span style=display:flex><span>    x, y, theta <span style=color:#000;font-weight:700>=</span> tau[<span style=color:#099>0</span>], tau[<span style=color:#099>1</span>], tau[<span style=color:#099>2</span>]
</span></span><span style=display:flex><span>    T <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>zeros((<span style=color:#099>3</span>, <span style=color:#099>3</span>))
</span></span><span style=display:flex><span>    T[<span style=color:#099>0</span>:<span style=color:#099>2</span>, <span style=color:#099>0</span>:<span style=color:#099>2</span>] <span style=color:#000;font-weight:700>=</span> scipy<span style=color:#000;font-weight:700>.</span>linalg<span style=color:#000;font-weight:700>.</span>expm(np<span style=color:#000;font-weight:700>.</span>array([[<span style=color:#099>0</span>, <span style=color:#000;font-weight:700>-</span>theta], [theta, <span style=color:#099>0</span>]]))
</span></span><span style=display:flex><span>    V_theta <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>sin(theta) <span style=color:#000;font-weight:700>/</span> theta <span style=color:#000;font-weight:700>*</span> np<span style=color:#000;font-weight:700>.</span>eye(<span style=color:#099>2</span>) <span style=color:#000;font-weight:700>+</span> (<span style=color:#099>1.</span> <span style=color:#000;font-weight:700>-</span> np<span style=color:#000;font-weight:700>.</span>cos(theta)) <span style=color:#000;font-weight:700>/</span> theta <span style=color:#000;font-weight:700>*</span> np<span style=color:#000;font-weight:700>.</span>array([[<span style=color:#099>0</span>, <span style=color:#000;font-weight:700>-</span><span style=color:#099>1</span>], [<span style=color:#099>1</span>, <span style=color:#099>0</span>]])
</span></span><span style=display:flex><span>    p <span style=color:#000;font-weight:700>=</span> V_theta <span style=color:#000;font-weight:700>@</span> np<span style=color:#000;font-weight:700>.</span>array([[x], [y]])
</span></span><span style=display:flex><span>    T[<span style=color:#099>0</span>:<span style=color:#099>2</span>, <span style=color:#099>2</span>] <span style=color:#000;font-weight:700>=</span> p<span style=color:#000;font-weight:700>.</span>flatten()
</span></span><span style=display:flex><span>    T[<span style=color:#099>2</span>, <span style=color:#099>2</span>] <span style=color:#000;font-weight:700>=</span> <span style=color:#099>1.0</span>
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>return</span> T
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>Log</span>(T):
</span></span><span style=display:flex><span>    <span style=color:#d14>&#39;&#39;&#39;Inverse of Exp, unwraps group to Lie algebra.&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span>    t <span style=color:#000;font-weight:700>=</span> T[<span style=color:#099>1</span>, <span style=color:#099>0</span>] <span style=color:#000;font-weight:700>/</span> T[<span style=color:#099>0</span>, <span style=color:#099>0</span>]
</span></span><span style=display:flex><span>    x, y, theta <span style=color:#000;font-weight:700>=</span> T[<span style=color:#099>0</span>, <span style=color:#099>2</span>], T[<span style=color:#099>1</span>, <span style=color:#099>2</span>], np<span style=color:#000;font-weight:700>.</span>arctan2(T[<span style=color:#099>1</span>, <span style=color:#099>0</span>], T[<span style=color:#099>0</span>, <span style=color:#099>0</span>])
</span></span><span style=display:flex><span>    V_theta <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>sin(theta) <span style=color:#000;font-weight:700>/</span> theta <span style=color:#000;font-weight:700>*</span> np<span style=color:#000;font-weight:700>.</span>eye(<span style=color:#099>2</span>) <span style=color:#000;font-weight:700>+</span> (<span style=color:#099>1.</span> <span style=color:#000;font-weight:700>-</span> np<span style=color:#000;font-weight:700>.</span>cos(theta)) <span style=color:#000;font-weight:700>/</span> theta <span style=color:#000;font-weight:700>*</span> np<span style=color:#000;font-weight:700>.</span>array([[<span style=color:#099>0</span>, <span style=color:#000;font-weight:700>-</span><span style=color:#099>1</span>], [<span style=color:#099>1</span>, <span style=color:#099>0</span>]])
</span></span><span style=display:flex><span>    v <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>linalg<span style=color:#000;font-weight:700>.</span>inv(V_theta) <span style=color:#000;font-weight:700>@</span> np<span style=color:#000;font-weight:700>.</span>array([[x], [y]])
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>return</span> np<span style=color:#000;font-weight:700>.</span>array([[v[<span style=color:#099>0</span>, <span style=color:#099>0</span>]], [v[<span style=color:#099>1</span>, <span style=color:#099>0</span>]], [theta]])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>Ad</span>(T):
</span></span><span style=display:flex><span>    <span style=color:#d14>&#39;&#39;&#39;Adjoint, linear transform that transforms tangent space at X to tangent space at identity.&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span>    Ad <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>copy(T[:, :])
</span></span><span style=display:flex><span>    Ad[<span style=color:#099>0</span>:<span style=color:#099>2</span>, <span style=color:#099>2</span>] <span style=color:#000;font-weight:700>=</span> <span style=color:#000;font-weight:700>-</span>np<span style=color:#000;font-weight:700>.</span>array([[<span style=color:#099>0.</span>, <span style=color:#000;font-weight:700>-</span><span style=color:#099>1.</span>], [<span style=color:#099>1.</span>, <span style=color:#099>0</span>]]) <span style=color:#000;font-weight:700>@</span> T[<span style=color:#099>0</span>:<span style=color:#099>2</span>, <span style=color:#099>2</span>]
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>return</span> Ad[:, :]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>J_df_dp</span>(p):
</span></span><span style=display:flex><span>    px, py <span style=color:#000;font-weight:700>=</span> p[<span style=color:#099>0</span>], p[<span style=color:#099>1</span>]
</span></span><span style=display:flex><span>    r <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>sqrt(px<span style=color:#000;font-weight:700>**</span><span style=color:#099>2</span> <span style=color:#000;font-weight:700>+</span> py<span style=color:#000;font-weight:700>**</span><span style=color:#099>2</span>)
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>return</span> np<span style=color:#000;font-weight:700>.</span>array([px <span style=color:#000;font-weight:700>/</span> r, py <span style=color:#000;font-weight:700>/</span> r, <span style=color:#099>0.</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>J_dTp_dT</span>(T, p):
</span></span><span style=display:flex><span>    J <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>eye(<span style=color:#099>3</span>)
</span></span><span style=display:flex><span>    J[<span style=color:#099>0</span>:<span style=color:#099>2</span>, <span style=color:#099>0</span>:<span style=color:#099>2</span>] <span style=color:#000;font-weight:700>=</span> T[<span style=color:#099>0</span>:<span style=color:#099>2</span>, <span style=color:#099>0</span>:<span style=color:#099>2</span>]
</span></span><span style=display:flex><span>    J[<span style=color:#099>0</span>:<span style=color:#099>2</span>, <span style=color:#099>2</span>] <span style=color:#000;font-weight:700>=</span> T[<span style=color:#099>0</span>:<span style=color:#099>2</span>, <span style=color:#099>0</span>:<span style=color:#099>2</span>] <span style=color:#000;font-weight:700>@</span> np<span style=color:#000;font-weight:700>.</span>array([[<span style=color:#099>0</span>, <span style=color:#000;font-weight:700>-</span><span style=color:#099>1.</span>], [<span style=color:#099>1.</span>, <span style=color:#099>0</span>]]) <span style=color:#000;font-weight:700>@</span> p
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>return</span> J
</span></span></code></pre></div></div></div><p>Now select true values, measurements and add noise to them.</p><div class=spoiler><span class=spoilerText>Spoiler</span>
<input class=spoilerChecked type=checkbox showtext=Code><div class=spoilerContent><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#998;font-style:italic># true values</span>
</span></span><span style=display:flex><span>trueT_1 <span style=color:#000;font-weight:700>=</span> T(<span style=color:#099>2.</span>, <span style=color:#099>4.</span>, np<span style=color:#000;font-weight:700>.</span>deg2rad(<span style=color:#099>35</span>))
</span></span><span style=display:flex><span>trueT_2 <span style=color:#000;font-weight:700>=</span> T(<span style=color:#099>2.</span>, <span style=color:#099>3.</span>, np<span style=color:#000;font-weight:700>.</span>deg2rad(<span style=color:#099>50</span>))
</span></span><span style=display:flex><span>trueT_3 <span style=color:#000;font-weight:700>=</span> T(<span style=color:#099>4.</span>, <span style=color:#099>3.</span>, np<span style=color:#000;font-weight:700>.</span>deg2rad(<span style=color:#099>70</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#998;font-style:italic># landmark positions</span>
</span></span><span style=display:flex><span>L1 <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>array([<span style=color:#099>1.5</span>, <span style=color:#099>3.75</span>, <span style=color:#099>1.</span>])
</span></span><span style=display:flex><span>L2 <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>array([<span style=color:#099>4.5</span>, <span style=color:#099>3.</span>, <span style=color:#099>1.</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#998;font-style:italic># pose increments measured + noise</span>
</span></span><span style=display:flex><span>dT_noise <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>array([<span style=color:#099>0.01</span>, <span style=color:#099>0.01</span>, <span style=color:#099>0.01</span>])
</span></span><span style=display:flex><span>T_12 <span style=color:#000;font-weight:700>=</span> Log(np<span style=color:#000;font-weight:700>.</span>linalg<span style=color:#000;font-weight:700>.</span>inv(trueT_1) <span style=color:#000;font-weight:700>@</span> trueT_2) <span style=color:#000;font-weight:700>+</span> np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>normal(scale <span style=color:#000;font-weight:700>=</span> dT_noise)<span style=color:#000;font-weight:700>.</span>reshape((<span style=color:#099>3</span>, <span style=color:#099>1</span>))
</span></span><span style=display:flex><span>T_23 <span style=color:#000;font-weight:700>=</span> Log(np<span style=color:#000;font-weight:700>.</span>linalg<span style=color:#000;font-weight:700>.</span>inv(trueT_2) <span style=color:#000;font-weight:700>@</span> trueT_3) <span style=color:#000;font-weight:700>+</span> np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>normal(scale <span style=color:#000;font-weight:700>=</span> dT_noise)<span style=color:#000;font-weight:700>.</span>reshape((<span style=color:#099>3</span>, <span style=color:#099>1</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#998;font-style:italic># ranges measured + noise</span>
</span></span><span style=display:flex><span>dR_noise <span style=color:#000;font-weight:700>=</span> <span style=color:#099>0.01</span>
</span></span><span style=display:flex><span>R1 <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>sqrt(np<span style=color:#000;font-weight:700>.</span>sum((trueT_1[:, <span style=color:#099>2</span>] <span style=color:#000;font-weight:700>-</span> L1) <span style=color:#000;font-weight:700>**</span> <span style=color:#099>2</span>)) <span style=color:#000;font-weight:700>+</span> np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>normal(scale <span style=color:#000;font-weight:700>=</span> dR_noise)
</span></span><span style=display:flex><span>R2 <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>sqrt(np<span style=color:#000;font-weight:700>.</span>sum((trueT_3[:, <span style=color:#099>2</span>] <span style=color:#000;font-weight:700>-</span> L2) <span style=color:#000;font-weight:700>**</span> <span style=color:#099>2</span>)) <span style=color:#000;font-weight:700>+</span> np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>normal(scale <span style=color:#000;font-weight:700>=</span> dR_noise)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#998;font-style:italic># noise prior estimates</span>
</span></span><span style=display:flex><span>T_1 <span style=color:#000;font-weight:700>=</span> trueT_1 <span style=color:#000;font-weight:700>@</span> Exp(np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>normal(scale <span style=color:#000;font-weight:700>=</span> <span style=color:#099>20</span> <span style=color:#000;font-weight:700>*</span> dT_noise))
</span></span><span style=display:flex><span>T_2 <span style=color:#000;font-weight:700>=</span> trueT_2 <span style=color:#000;font-weight:700>@</span> Exp(np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>normal(scale <span style=color:#000;font-weight:700>=</span> <span style=color:#099>20</span> <span style=color:#000;font-weight:700>*</span> dT_noise))
</span></span><span style=display:flex><span>T_3 <span style=color:#000;font-weight:700>=</span> trueT_3 <span style=color:#000;font-weight:700>@</span> Exp(np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>normal(scale <span style=color:#000;font-weight:700>=</span> <span style=color:#099>20</span> <span style=color:#000;font-weight:700>*</span> dT_noise))
</span></span><span style=display:flex><span>pT_1, pT_2, pT_3 <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>copy(T_1), np<span style=color:#000;font-weight:700>.</span>copy(T_2), np<span style=color:#000;font-weight:700>.</span>copy(T_3)
</span></span></code></pre></div></div></div><p>Fill-in jacobians and solve the problem iteratively:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>u_sigmas <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>array([<span style=color:#099>0.01</span>, <span style=color:#099>0.01</span>, <span style=color:#099>0.01</span>, <span style=color:#099>0.01</span>, <span style=color:#099>0.01</span>, <span style=color:#099>0.01</span>, <span style=color:#099>0.00001</span>, <span style=color:#099>0.00001</span>])
</span></span><span style=display:flex><span>W <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>diagflat(<span style=color:#099>1.</span><span style=color:#000;font-weight:700>/</span>u_sigmas)  <span style=color:#998;font-style:italic># this is Q^(-T/2)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>for</span> i <span style=color:#000;font-weight:700>in</span> <span style=color:#0086b3>range</span>(<span style=color:#099>0</span>, <span style=color:#099>1000</span>):
</span></span><span style=display:flex><span>    H <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>zeros((<span style=color:#099>8</span>, <span style=color:#099>9</span>))
</span></span><span style=display:flex><span>    est_T_12 <span style=color:#000;font-weight:700>=</span> Log(np<span style=color:#000;font-weight:700>.</span>linalg<span style=color:#000;font-weight:700>.</span>inv(T_1) <span style=color:#000;font-weight:700>@</span> T_2)
</span></span><span style=display:flex><span>    H[<span style=color:#099>0</span>:<span style=color:#099>3</span>, <span style=color:#099>0</span>:<span style=color:#099>3</span>] <span style=color:#000;font-weight:700>=</span> <span style=color:#000;font-weight:700>-</span>np<span style=color:#000;font-weight:700>.</span>linalg<span style=color:#000;font-weight:700>.</span>inv(Jl(est_T_12))
</span></span><span style=display:flex><span>    H[<span style=color:#099>0</span>:<span style=color:#099>3</span>, <span style=color:#099>3</span>:<span style=color:#099>6</span>] <span style=color:#000;font-weight:700>=</span>  np<span style=color:#000;font-weight:700>.</span>linalg<span style=color:#000;font-weight:700>.</span>inv(Jr(est_T_12))
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    est_T_23 <span style=color:#000;font-weight:700>=</span> Log(np<span style=color:#000;font-weight:700>.</span>linalg<span style=color:#000;font-weight:700>.</span>inv(T_2) <span style=color:#000;font-weight:700>@</span> T_3)
</span></span><span style=display:flex><span>    H[<span style=color:#099>3</span>:<span style=color:#099>6</span>, <span style=color:#099>3</span>:<span style=color:#099>6</span>] <span style=color:#000;font-weight:700>=</span> <span style=color:#000;font-weight:700>-</span>np<span style=color:#000;font-weight:700>.</span>linalg<span style=color:#000;font-weight:700>.</span>inv(Jl(est_T_23))
</span></span><span style=display:flex><span>    H[<span style=color:#099>3</span>:<span style=color:#099>6</span>, <span style=color:#099>6</span>:<span style=color:#099>9</span>] <span style=color:#000;font-weight:700>=</span>  np<span style=color:#000;font-weight:700>.</span>linalg<span style=color:#000;font-weight:700>.</span>inv(Jr(est_T_23))
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    est_range_R1 <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>sqrt(np<span style=color:#000;font-weight:700>.</span>sum((T_1[:, <span style=color:#099>2</span>] <span style=color:#000;font-weight:700>-</span> L1) <span style=color:#000;font-weight:700>**</span> <span style=color:#099>2</span>))
</span></span><span style=display:flex><span>    <span style=color:#998;font-style:italic># chain rule</span>
</span></span><span style=display:flex><span>    T1_inv <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>linalg<span style=color:#000;font-weight:700>.</span>inv(T_1)
</span></span><span style=display:flex><span>    L1_transformed <span style=color:#000;font-weight:700>=</span> (T1_inv <span style=color:#000;font-weight:700>@</span> L1)[<span style=color:#099>0</span>:<span style=color:#099>2</span>]
</span></span><span style=display:flex><span>    H[<span style=color:#099>6</span>, <span style=color:#099>0</span>:<span style=color:#099>3</span>] <span style=color:#000;font-weight:700>=</span> J_df_dp(L1_transformed) <span style=color:#000;font-weight:700>@</span> J_dTp_dT(T1_inv, L1[<span style=color:#099>0</span>:<span style=color:#099>2</span>]) <span style=color:#000;font-weight:700>@</span> <span style=color:#000;font-weight:700>-</span>Ad(T_1)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    est_range_R2 <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>sqrt(np<span style=color:#000;font-weight:700>.</span>sum((T_3[:, <span style=color:#099>2</span>] <span style=color:#000;font-weight:700>-</span> L2) <span style=color:#000;font-weight:700>**</span> <span style=color:#099>2</span>))
</span></span><span style=display:flex><span>    <span style=color:#998;font-style:italic># chain rule</span>
</span></span><span style=display:flex><span>    T3_inv <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>linalg<span style=color:#000;font-weight:700>.</span>inv(T_3)
</span></span><span style=display:flex><span>    L2_transformed <span style=color:#000;font-weight:700>=</span> (T3_inv <span style=color:#000;font-weight:700>@</span> L2)[<span style=color:#099>0</span>:<span style=color:#099>2</span>]
</span></span><span style=display:flex><span>    H[<span style=color:#099>7</span>, <span style=color:#099>6</span>:<span style=color:#099>9</span>] <span style=color:#000;font-weight:700>=</span> J_df_dp(L2_transformed) <span style=color:#000;font-weight:700>@</span> J_dTp_dT(T3_inv, L2[<span style=color:#099>0</span>:<span style=color:#099>2</span>]) <span style=color:#000;font-weight:700>@</span> <span style=color:#000;font-weight:700>-</span>Ad(T_3)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    residual <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>vstack((T_12 <span style=color:#000;font-weight:700>-</span> est_T_12, 
</span></span><span style=display:flex><span>                          T_23 <span style=color:#000;font-weight:700>-</span> est_T_23, 
</span></span><span style=display:flex><span>                          R1 <span style=color:#000;font-weight:700>-</span> est_range_R1,
</span></span><span style=display:flex><span>                          R2 <span style=color:#000;font-weight:700>-</span> est_range_R2))
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    delta <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>linalg<span style=color:#000;font-weight:700>.</span>pinv(H<span style=color:#000;font-weight:700>.</span>T <span style=color:#000;font-weight:700>@</span> W <span style=color:#000;font-weight:700>@</span> H) <span style=color:#000;font-weight:700>@</span> H<span style=color:#000;font-weight:700>.</span>T <span style=color:#000;font-weight:700>@</span> W <span style=color:#000;font-weight:700>@</span> residual
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    T_1 <span style=color:#000;font-weight:700>=</span> T_1 <span style=color:#000;font-weight:700>@</span> Exp(delta[<span style=color:#099>0</span>:<span style=color:#099>3</span>, :])
</span></span><span style=display:flex><span>    T_2 <span style=color:#000;font-weight:700>=</span> T_2 <span style=color:#000;font-weight:700>@</span> Exp(delta[<span style=color:#099>3</span>:<span style=color:#099>6</span>, :])
</span></span><span style=display:flex><span>    T_3 <span style=color:#000;font-weight:700>=</span> T_3 <span style=color:#000;font-weight:700>@</span> Exp(delta[<span style=color:#099>6</span>:<span style=color:#099>9</span>, :])
</span></span></code></pre></div><div class=spoiler><span class=spoilerText>Spoiler</span>
<input class=spoilerChecked type=checkbox showtext=Code><div class=spoilerContent><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000;font-weight:700>import</span> <span style=color:#555>matplotlib.pylab</span> <span style=color:#000;font-weight:700>as</span> <span style=color:#555>plt</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>from</span> <span style=color:#555>matplotlib.patches</span> <span style=color:#000;font-weight:700>import</span> Circle
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>%</span>config InlineBackend<span style=color:#000;font-weight:700>.</span>figure_format<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;retina&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, ax <span style=color:#000;font-weight:700>=</span> plt<span style=color:#000;font-weight:700>.</span>subplots(<span style=color:#099>1</span>, <span style=color:#099>1</span>, figsize <span style=color:#000;font-weight:700>=</span> (<span style=color:#099>7</span>, <span style=color:#099>5</span>))
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>plot([trueT_1[<span style=color:#099>0</span>, <span style=color:#099>2</span>], trueT_2[<span style=color:#099>0</span>, <span style=color:#099>2</span>], trueT_3[<span style=color:#099>0</span>, <span style=color:#099>2</span>]], [trueT_1[<span style=color:#099>1</span>, <span style=color:#099>2</span>], trueT_2[<span style=color:#099>1</span>, <span style=color:#099>2</span>], trueT_3[<span style=color:#099>1</span>, <span style=color:#099>2</span>]], <span style=color:#d14>&#39;o-&#39;</span>, label <span style=color:#000;font-weight:700>=</span> <span style=color:#d14>&#39;True&#39;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>plot([T_1[<span style=color:#099>0</span>, <span style=color:#099>2</span>], T_2[<span style=color:#099>0</span>, <span style=color:#099>2</span>], T_3[<span style=color:#099>0</span>, <span style=color:#099>2</span>]], [T_1[<span style=color:#099>1</span>, <span style=color:#099>2</span>], T_2[<span style=color:#099>1</span>, <span style=color:#099>2</span>], T_3[<span style=color:#099>1</span>, <span style=color:#099>2</span>]], <span style=color:#d14>&#39;o-&#39;</span>, label <span style=color:#000;font-weight:700>=</span> <span style=color:#d14>&#39;Optimized&#39;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>plot([pT_1[<span style=color:#099>0</span>, <span style=color:#099>2</span>], pT_2[<span style=color:#099>0</span>, <span style=color:#099>2</span>], pT_3[<span style=color:#099>0</span>, <span style=color:#099>2</span>]], [pT_1[<span style=color:#099>1</span>, <span style=color:#099>2</span>], pT_2[<span style=color:#099>1</span>, <span style=color:#099>2</span>], pT_3[<span style=color:#099>1</span>, <span style=color:#099>2</span>]], <span style=color:#d14>&#39;o-&#39;</span>, label <span style=color:#000;font-weight:700>=</span> <span style=color:#d14>&#39;Initial&#39;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>scatter([L1[<span style=color:#099>0</span>], L2[<span style=color:#099>0</span>]], [L1[<span style=color:#099>1</span>], L2[<span style=color:#099>1</span>]], marker<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;x&#39;</span>, s <span style=color:#000;font-weight:700>=</span> <span style=color:#099>120</span>, label <span style=color:#000;font-weight:700>=</span> <span style=color:#d14>&#39;Landmarks&#39;</span>)
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>for</span> l, r <span style=color:#000;font-weight:700>in</span> <span style=color:#0086b3>zip</span>((L1, L2), (R1, R2)):
</span></span><span style=display:flex><span>    circle <span style=color:#000;font-weight:700>=</span> Circle((l[<span style=color:#099>0</span>], l[<span style=color:#099>1</span>]), r, facecolor<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;none&#39;</span>, edgecolor<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;tab:blue&#39;</span>, linewidth<span style=color:#000;font-weight:700>=</span><span style=color:#099>3</span>, alpha<span style=color:#000;font-weight:700>=</span><span style=color:#099>0.5</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#000;font-weight:700>.</span>add_patch(circle)
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>axis(<span style=color:#d14>&#34;equal&#34;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>legend()
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>grid()
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>set_title(<span style=color:#d14>&#34;True, initial and estimated trajectories&#34;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>text(<span style=color:#099>1</span>, <span style=color:#099>2.25</span>, <span style=color:#d14>&#34;Circles - measured distances to the landmarks&#34;</span>, c <span style=color:#000;font-weight:700>=</span> <span style=color:#d14>&#34;tab:blue&#34;</span>, alpha <span style=color:#000;font-weight:700>=</span> <span style=color:#099>0.8</span>);
</span></span></code></pre></div></div></div><p><img src=output_25_1.png#center alt=png></p><h1 id=references>References
<a class=heading-link href=#references><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://arxiv.org/abs/1812.01537 class=external-link target=_blank rel=noopener>https://arxiv.org/abs/1812.01537</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref2:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href=https://www.roboticsbook.org/S44_logistics_perception.html class=external-link target=_blank rel=noopener>https://www.roboticsbook.org/S44_logistics_perception.html</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//mikoff-github-io.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}(),document.addEventListener("themeChanged",function(){document.readyState=="complete"&&DISQUS.reset({reload:!0,config:disqus_config})})</script></footer></article><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0 crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})'></script></section></div><footer class=footer><section class=container>©
2024
Aleksandr Mikoff
·
Powered by <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/ target=_blank rel=noopener>Coder</a>.</section></footer></main><script src=/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script></body></html>