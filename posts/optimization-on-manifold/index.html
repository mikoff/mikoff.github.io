<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Aleksandr Mikoff"><meta name=twitter:card content="summary"><meta name=twitter:title content="Optimization on manifold"><meta name=twitter:description content="Optimization on manifold In the following post I would like to summarize my perception of poses&rsquo; optimization problem. Such a problem often occures in robotics and other related fields. Usually we want jointly optimize the poses, their increments and various measurements. What we want to find is such set of parameters, that minimize the sum of residuals, or differences, between the real measurements and measurements, that we derive from our state."><meta property="og:title" content="Optimization on manifold"><meta property="og:description" content="Optimization on manifold In the following post I would like to summarize my perception of poses&rsquo; optimization problem. Such a problem often occures in robotics and other related fields. Usually we want jointly optimize the poses, their increments and various measurements. What we want to find is such set of parameters, that minimize the sum of residuals, or differences, between the real measurements and measurements, that we derive from our state."><meta property="og:type" content="article"><meta property="og:url" content="https://mikoff.github.io/posts/optimization-on-manifold/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-11-20T21:00:00+03:00"><meta property="article:modified_time" content="2022-11-20T21:00:00+03:00"><base href=https://mikoff.github.io/posts/optimization-on-manifold/><title>Optimization on manifold · Aleksandr Mikoff's blog</title><link rel=canonical href=https://mikoff.github.io/posts/optimization-on-manifold/><link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.11.2/css/all.css integrity=sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin=anonymous><link rel=stylesheet href=https://mikoff.github.io/fontdata/css/academicons.min.css><link rel=stylesheet href=https://mikoff.github.io/css/coder.min.a4f332213a21ce8eb521670c614470c58923aaaf385e2a73982c31dd7642decb.css integrity="sha256-pPMyITohzo61IWcMYURwxYkjqq84XipzmCwx3XZC3ss=" crossorigin=anonymous media=screen><link rel=stylesheet href=https://mikoff.github.io/css/coder-dark.min.83a2010dac9f59f943b3004cd6c4f230507ad036da635d3621401d42ec4e2835.css integrity="sha256-g6IBDayfWflDswBM1sTyMFB60DbaY102IUAdQuxOKDU=" crossorigin=anonymous media=screen><link rel=stylesheet href=https://mikoff.github.io/css/image.css><link rel=stylesheet href=https://mikoff.github.io/css/spoiler.css><link rel=icon type=image/png href=https://mikoff.github.io/img/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=https://mikoff.github.io/img/favicon-16x16.png sizes=16x16><meta name=generator content="Hugo 0.106.0"></head><body class=colorscheme-auto><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://mikoff.github.io/>Aleksandr Mikoff's blog</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fas fa-bars"></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=https://mikoff.github.io/about/>About</a></li><li class=navigation-item><a class=navigation-link href=https://mikoff.github.io/posts/>Posts</a></li><li class=navigation-item><a class=navigation-link href=https://mikoff.github.io/tags>Tags</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title>Optimization on manifold</h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fas fa-calendar"></i>
<time datetime=2022-11-20T21:00:00+03:00>November 20, 2022</time></span>
<span class=reading-time><i class="fas fa-clock"></i>
10-minute read</span></div><div class=tags><i class="fas fa-tag"></i>
<a href=https://mikoff.github.io/tags/optimization/>Optimization</a>
<span class=separator>•</span>
<a href=https://mikoff.github.io/tags/least-squares/>Least squares</a>
<span class=separator>•</span>
<a href=https://mikoff.github.io/tags/factor-graph/>Factor graph</a>
<span class=separator>•</span>
<a href=https://mikoff.github.io/tags/manifolds/>Manifolds</a></div></div></header><div><h1 id=optimization-on-manifold>Optimization on manifold</h1><p>In the following post I would like to summarize my perception of poses&rsquo; optimization problem. Such a problem often occures in robotics and other related fields. Usually we want jointly optimize the poses, their increments and various measurements. What we want to find is such set of parameters, that minimize the sum of residuals, or differences, between the real measurements and measurements, that we derive from our state.</p><p>Assume that we have the prior on pose of our object origin $b$ w.r.t. the world origin $w$ at time $i$ - $\mathbf{T}_{wb_i}$, we also know the prior on pose at time ${i+1}$ - $\mathbf{T}_{wb_{i+1}}$, and the relative pose between them $\mathbf{T}_{b_i b_{i+1}}$:
$$
\mathbf{T}_{w b_{i+1}} = \mathbf{T}_{w b_{i}}\mathbf{T}_{b_{i}b_{i+1}}.
$$
In such a case we have only two poses and one pose difference between them. Real-life examples are usually much more harder, and include hundreds of parameters. Nevertheless, even in such a simple case, how can we formulate it in a way that we can optimize?</p><p>If we have two poses $\mathbf{T}_{wb_i}$ and $\mathbf{T}_{wb_{i+1}}$, we can define the measurement function $\mathbf{h}$ as their composition:
$$
\mathbf{h}\left(\mathbf{T}_{wb_i}, \mathbf{T}_{wb_{i+1}}\right) = \hat{\mathbf{T}}_{b_{i}b_{i+1}} = \mathbf{T}_{wb_{i}}^{-1}\mathbf{T}_{wb_{i+1}}
$$</p><p>Now, having an estimated and real measurements we can find their difference as:
$$
\hat{\mathbf{T}}_{b_{i}b_{i+1}}^{-1}\mathbf{T}_{b_{i}b_{i+1}}.
$$</p><p>To find the minimum we should find the derivative w.r.t. the minimization parameters (our matrices!), set it to zero and solve for the parameters. Of course, we could try to directly solve such a problem, but imagine a beast that comes out as a result such attempt. There should be a better way of doing this.
This way utilizes the following math concepts:</p><ol><li>Define residuals on the tangent space of the manifold.</li><li>Use first-order approximation - it allows us to describe how the non-linear function behaves near the linearization point, and allows to deduce standard Jacobian blocks.</li><li>Use the first-order approximation to rewrite the problem in standard linear form that allows to use standard Jacobians that depend only on the measurement function.</li></ol><h2 id=residuals-minimization-on-manifold>Residuals minimization on Manifold</h2><h3 id=step-1>Step 1</h3><p>We want to minimize the following cost function:
$$
\left|\left|\log\left(\hat{\mathbf{T}}_{b_{i}b_{i+1}}^{-1}\mathbf{T}_{b_{i}b_{i+1}}\right)\right|\right|^2.
$$
We can interpret this function intuitively:</p><ul><li>by group definition if the elements $\hat{\mathbf{T}}$ and $\mathbf{T}$ are equal, then their composition $\hat{\mathbf{T}}^{-1}\mathbf{T}$ is the identity, if they differ, then the composition allows us to find this difference;</li><li>$\log$ operations maps the difference from the manifold to the tangent space, $\log: \mathcal{M} \to \mathcal{R}^3$, that is the vector space;</li><li>norm operator measures the size of our difference, since we use $\mathcal{l}^2$ norm, we can easily find the derivative.</li></ul><h3 id=step-2>Step 2</h3><p>The solution of the problem $\mathbf{L} = \arg\underset{x}{\min}||\mathbf{A}\mathbf{x} - \mathbf{b}||^2$ is well-known and can be derived quite easily:
$$
\mathbf{x} = (\mathbf{A}^T\mathbf{A})^{-1}\mathbf{A}^T\mathbf{b}.
$$</p><p>The aforementioned cost function expression, however, has the different form. But let&rsquo;s use first-order approximation for the measurement function $\mathbf{h}$, where $\delta\mathbf{x}$ is state perturbation around our current estimate $\mathbf{\hat{x}}$:</p><p>$$\mathbf{h}(\mathbf{\hat{x}} + \delta\mathbf{x}) \approx \mathbf{h}(\mathbf{\hat{x}}) + \mathbf{J}^{\mathbf{h}}_{\mathbf{x}}(\mathbf{\hat{x}}) \delta \mathbf{x}$$</p><p>After trivial rewriting we can identify the standard form:
$$
\mathbf{L} = \arg\underset{\delta\mathbf{x}}{\min}\left|\left| \mathbf{J}^{\mathbf{h}}_{\mathbf{x}}(\mathbf{\hat{x}}) \delta \mathbf{x} - \left(\mathbf{h}(\mathbf{\hat{x}} + \delta\mathbf{x}) - \mathbf{h}(\mathbf{\hat{x}}) \right)\right|\right|^2 ,
$$
noticing that $\mathbf{\hat{x}} + \delta\mathbf{x} = \mathbf{x}$, where $\mathbf{x}$ is the true state, we substitute $\mathbf{h}(\mathbf{x})$ with our measurement $\mathbf{z}$, we simplifying the expression one step further:
$$
\mathbf{L} = \arg\underset{\delta\mathbf{x}}{\min}\left|\left| \underbrace{\mathbf{J}^{\mathbf{h}}_{\mathbf{x}}(\mathbf{\hat{x}})}_{\vphantom{f}\mathbf{A}} \delta \mathbf{x} - \underbrace{\left(\mathbf{z} - \mathbf{h}(\mathbf{\hat{x}}) \right)}_{\vphantom{f}\mathbf{b}}\right|\right|^2.
$$
In this form we clearly identify the linear residuals form! Since $\mathbf{b} = \log\left(\hat{\mathbf{T}}_{b_{i}b_{i+1}}^{-1}\mathbf{T}_{b_{i}b_{i+1}}\right)$ and has vector form only one thing that is needed now is the jacobian $\mathbf{J}^{\mathbf{h}}$.</p><h3 id=step-3>Step 3</h3><p>To find the jacobians we can use the elementary blocks and chain rule, as stated in <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>. Note, that after our former reformulation we need to find the Jacobian of the measuremnt function $\mathbf{h}$ w.r.t. the state, not w.r.t. the squared residual:
$$
\mathbf{J}^{\mathbf{h}}_{\mathbf{x}} = \frac{D \mathbf{h}(\mathbf{x})}{D \mathbf{x}}.
$$
Having the measurement function
$$\mathbf{h}\left(\mathbf{T}_{wb_i}, \mathbf{T}_{wb_{i+1}}\right) = \hat{\mathbf{T}}_{b_{i}b_{i+1}} = \mathbf{T}_{wb_{i}}^{-1}\mathbf{T}_{wb_{i+1}}$$
we can use the jacobians that already derived for us in the literature, for example the jacobians w.r.t. $\mathbf{T}_{wb_{i}}$ and $\mathbf{T}_{wb_{i+1}}$ can be found to be (eq. (82) and (83) in <sup id=fnref1:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>):
$$
\begin{gather}
\mathbf{J}^\mathbf{h}_{\mathbf{x}_{\mathbf{T}_{wb_{i}}}} = -\mathbf{J}_l^{-1}\left(\mathbf{e}\right), \\
\mathbf{J}^\mathbf{h}_{\mathbf{x}_{\mathbf{T}_{wb_{i+1}}}} =\mathbf{J}_r^{-1}\left(\mathbf{e}\right),
\end{gather}
$$
and $\mathbf{e}=\log\left(\mathbf{T}_{wb_{i}}^{-1}\mathbf{T}_{wb_{i+1}}\right) \in \mathcal{T}_{b_i}\mathcal{M}$.</p><p>Equipped with Jacobians we can write our toy problem. Assume that we know prior robot poses ${\mathbf{T}_{wb_{1}}, \mathbf{T}_{wb_{2}}, \mathbf{T}_{wb_{3}}} \in SE(2)$ and the measured pose increments between them ${\mathbf{\tau}_{b_{1}b_{2}}, \mathbf{\tau}_{b_{2}b_{3}} } \in \mathcal{T}\mathcal{M}$. Our state consits of three poses, and we have two increments. Then we can define our problem using matrices:
$$
\underbrace{
\begin{bmatrix}
-\mathbf{J}_l^{-1}\left(\log\left(\mathbf{T}_{wb_{1}}^{-1}\mathbf{T}_{wb_{2}}\right)\right) & \mathbf{J}_r^{-1}\left(\log\left(\mathbf{T}_{wb_{1}}^{-1}\mathbf{T}_{wb_{2}}\right)\right) & \mathbf{0}_{3\times3}\\
\mathbf{0}_{3\times3} & -\mathbf{J}_l^{-1}\left(\log\left(\mathbf{T}_{wb_{2}}^{-1}\mathbf{T}_{wb_{3}}\right)\right) & \mathbf{J}_r^{-1}\left(\log\left(\mathbf{T}_{wb_{2}}^{-1}\mathbf{T}_{wb_{3}}\right)\right)
\end{bmatrix}}_{\mathbf{J}_{6\times 9}} \delta\mathbf{x} =
\underbrace{
\begin{bmatrix}
\mathbf{\tau}_{b_{1}b_{2}} - \log\left(\mathbf{T}_{wb_{1}}^{-1}\mathbf{T}_{wb_{2}}\right) \\
\mathbf{\tau}_{b_{2}b_{3}} - \log\left(\mathbf{T}_{wb_{2}}^{-1}\mathbf{T}_{wb_{3}}\right)
\end{bmatrix}}_{\mathbf{r}_{6\times 1}}
$$</p><p>This can be solved using least-squares, the errors, or perturbation can be found to be:
$$
\delta\mathbf{x} = \left(\mathbf{J}^T\mathbf{J}\right)^{-1}\mathbf{J}^T\mathbf{r}
$$
then these errors are injected into the current, or nominal state: $\mathbf{x} \leftarrow \mathbf{x} + \delta\mathbf{x}$. The procedure is repeated until convergence.
Doing so we evenly distribute the total error vector between the whole elements of the state vector. To overcome this issue we can use weighted least squares and assign weight to each residual based on our confidence in it.</p><p>Note that this problem can be described using factor graph <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>: this uncovers the close relationship between graphs and linear algebra.</p><h3 id=arbitrary-measurement-functions>Arbitrary measurement functions</h3><p>Last thing I would like to tackle in this post is the arbitrary measurement functions.
Assume that we have a sensor that gives us the range measurements to the landmark, and the landmark position $\mathbf{p}_{wl}$ is known. How can we add such a sensor in our setup?
As usual, we have to define the measurement function $\mathbf{h}$:
$$
\mathbf{h}_{r}\left(\mathbf{T}_{wb}, \mathbf{p}_{wl}\right) = \sqrt{\mathbf{t}^T \mathbf{t}},
$$
where $\mathbf{t} = \begin{bmatrix}\mathbf{T}_{wb}^x - \mathbf{p}_{wl}^x \ \mathbf{T}_{wb}^y - \mathbf{p}_{wl}^y\end{bmatrix}$ is the translation between origin of the body frame and the landmark.</p><p>Only one thing we need is to find the derivative of $\mathbf{h}_r$ w.r.t. our state. First, let&rsquo;s resolve the landmark position in body frame (doing so we don&rsquo;t need to calculate the difference before dot product):
$$
\mathbf{p}_{bl} = \mathbf{T}_{bw}\mathbf{p}_{wl} = \mathbf{T}_{wb}^{-1}\mathbf{p}_{wl}
$$
substituing into the $\mathbf{h}_{r}$ and extracting only pose component of state vector we get:
$$
\mathbf{h}_{r}\left(\mathbf{T}_{wb}, \mathbf{p}_{wl}\right) = \sqrt{\left(\mathbf{T}_{wb}^{-1}\mathbf{p}_{wl}\right)^T \left(\mathbf{T}_{wb}^{-1}\mathbf{p}_{wl}\right)},
$$</p><p>We can think write our measurement function $\mathbf{h}$ as composition of $\mathbf{f} \circ \mathbf{g} \circ \mathbf{n}$,
where</p><ul><li>$\mathbf{n}\left(\mathbf{T}\right) = \mathbf{T}^{-1}$;</li><li>$\mathbf{g}\left(\mathbf{T}, \mathbf{p}\right) = \mathbf{T} \mathbf{p}$;</li><li>$\mathbf{f}\left(\mathbf{p}&rsquo;\right) = \sqrt{\mathbf{p&rsquo;}_x^2 + \mathbf{p&rsquo;}_y^2}$.</li></ul><p>The derivative w.r.t. to state can be found using chain rule:
$$
\mathbf{J}^{\mathbf{f}}_{\mathbf{T}} = \mathbf{J}^{\mathbf{f}}_{\mathbf{p}&rsquo;} \mathbf{J}^{\mathbf{T}^{-1}\mathbf{p}}_{\mathbf{T}^{-1}} \mathbf{J}^{\mathbf{T}^{-1}}_{\mathbf{T}}.
$$
For $SE(2)$ the latter two are derived in <sup id=fnref2:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> by equations (166) and (62).
The derivation of $\mathbf{J}^{\mathbf{f}}_{\mathbf{p}&rsquo;}$ is trivial:
$$
\mathbf{J}^{\mathbf{f}}_{\mathbf{p}&rsquo;} = \begin{bmatrix}\frac{\mathbf{p&rsquo;}_x}{r} & \frac{\mathbf{p&rsquo;}_y}{r}\end{bmatrix}, ~r = \sqrt{\mathbf{p&rsquo;}_x^2 + \mathbf{p&rsquo;}_y^2}.
$$</p><p>Now, if we have two landmarks $\mathbf{l}_1$ and $\mathbf{l}_2$, and our robot sees first landmark only at $\mathbf{T}_{wb_1}$ and second landmark only at $\mathbf{T}_{wb_3}$, we have to add two extra rows at our matrix $\mathbf{J}$ to account for this data:
$$
\underbrace{
\begin{bmatrix}
&\mathbf{J}_{6\times 9}& \
\mathbf{J}^{\mathbf{f}}_{\mathbf{T}_{wb_1}} & \mathbf{0}_{1\times 3} & \mathbf{0}_{1\times 3} \\
\mathbf{0}_{1\times 3} & \mathbf{0}_{1\times 3} & \mathbf{J}^{\mathbf{f}}_{\mathbf{T}_{wb_3}}
\end{bmatrix}}_{\mathbf{J}_{8\times 9}}
\delta\mathbf{x} =
\underbrace{
\begin{bmatrix}
\mathbf{r}_{6\times 1} \
r_1 - \mathbf{h}_r\left( \mathbf{T}_{wb_1}, \mathbf{p}_{wl_1} \right) \\
r_2 - \mathbf{h}_r\left( \mathbf{T}_{wb_3}, \mathbf{p}_{wl_2} \right)
\end{bmatrix}}_{\mathbf{r}_{8\times 1}},
$$
where $r_1$ and $r_2$ - range measurements.</p><h2 id=implementation>Implementation</h2><p>Now let&rsquo;s give the numerical example to all aforementioned concepts and functions.</p><p>First, define all needed operations for Lie groups and associated algebras.</p><div class=spoiler><span class=spoilerText>Spoiler</span>
<input class=spoilerChecked type=checkbox showtext=Code><div class=spoilerContent><div class=highlight><pre tabindex=0 style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#069;font-weight:700>import</span> <span style=color:#0cf;font-weight:700>numpy</span> <span style=color:#069;font-weight:700>as</span> <span style=color:#0cf;font-weight:700>np</span>
</span></span><span style=display:flex><span><span style=color:#069;font-weight:700>import</span> <span style=color:#0cf;font-weight:700>scipy.linalg</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#069;font-weight:700>def</span> <span style=color:#c0f>Jr</span>(tau):
</span></span><span style=display:flex><span>    <span style=color:#c30>&#39;&#39;&#39;Right jacobian for SE2, eq. (163) from [1].&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span>    x, y, theta <span style=color:#555>=</span> tau<span style=color:#555>.</span>flatten()
</span></span><span style=display:flex><span>    s, c <span style=color:#555>=</span> np<span style=color:#555>.</span>sin(theta), np<span style=color:#555>.</span>cos(theta)
</span></span><span style=display:flex><span>    <span style=color:#069;font-weight:700>return</span> np<span style=color:#555>.</span>array([[s <span style=color:#555>/</span> theta, (<span style=color:#f60>1</span> <span style=color:#555>-</span> c) <span style=color:#555>/</span> theta, (theta <span style=color:#555>*</span> x <span style=color:#555>-</span> y <span style=color:#555>+</span> y <span style=color:#555>*</span> c <span style=color:#555>-</span> x <span style=color:#555>*</span> s) <span style=color:#555>/</span> theta<span style=color:#555>**</span><span style=color:#f60>2</span>],
</span></span><span style=display:flex><span>                     [(c <span style=color:#555>-</span> <span style=color:#f60>1</span>) <span style=color:#555>/</span> theta, s <span style=color:#555>/</span> theta, (x <span style=color:#555>+</span> theta <span style=color:#555>*</span> y <span style=color:#555>-</span> x <span style=color:#555>*</span> c <span style=color:#555>-</span> y <span style=color:#555>*</span> s) <span style=color:#555>/</span> theta<span style=color:#555>**</span><span style=color:#f60>2</span>],
</span></span><span style=display:flex><span>                     [<span style=color:#f60>0.</span>, <span style=color:#f60>0.</span>, <span style=color:#f60>1.</span>]])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#069;font-weight:700>def</span> <span style=color:#c0f>Jl</span>(tau):
</span></span><span style=display:flex><span>    <span style=color:#c30>&#39;&#39;&#39;Left jacobian for SE2, eq. (163) from [1].&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span>    x, y, theta <span style=color:#555>=</span> tau<span style=color:#555>.</span>flatten()
</span></span><span style=display:flex><span>    s, c <span style=color:#555>=</span> np<span style=color:#555>.</span>sin(theta), np<span style=color:#555>.</span>cos(theta)
</span></span><span style=display:flex><span>    <span style=color:#069;font-weight:700>return</span> np<span style=color:#555>.</span>array([[s <span style=color:#555>/</span> theta, (c <span style=color:#555>-</span> <span style=color:#f60>1</span>) <span style=color:#555>/</span> theta, (theta <span style=color:#555>*</span> x <span style=color:#555>+</span> y <span style=color:#555>-</span> y <span style=color:#555>*</span> c <span style=color:#555>-</span> x <span style=color:#555>*</span> s) <span style=color:#555>/</span> theta<span style=color:#555>**</span><span style=color:#f60>2</span>],
</span></span><span style=display:flex><span>                     [(<span style=color:#f60>1</span> <span style=color:#555>-</span> c) <span style=color:#555>/</span> theta, s <span style=color:#555>/</span> theta, (<span style=color:#555>-</span>x <span style=color:#555>+</span> theta <span style=color:#555>*</span> y <span style=color:#555>+</span> x <span style=color:#555>*</span> c <span style=color:#555>-</span> y <span style=color:#555>*</span> s) <span style=color:#555>/</span> theta<span style=color:#555>**</span><span style=color:#f60>2</span>],
</span></span><span style=display:flex><span>                     [<span style=color:#f60>0.</span>, <span style=color:#f60>0.</span>, <span style=color:#f60>1.</span>]])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#069;font-weight:700>def</span> <span style=color:#c0f>T</span>(x, y, theta):
</span></span><span style=display:flex><span>    <span style=color:#c30>&#39;&#39;&#39;Returns transformation matrix for given x, y and theta parameters.&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#069;font-weight:700>return</span> np<span style=color:#555>.</span>array([[np<span style=color:#555>.</span>cos(theta), <span style=color:#555>-</span>np<span style=color:#555>.</span>sin(theta), x], [np<span style=color:#555>.</span>sin(theta), np<span style=color:#555>.</span>cos(theta), y], [<span style=color:#f60>0.</span>, <span style=color:#f60>0.</span>, <span style=color:#f60>1.</span>]])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#069;font-weight:700>def</span> <span style=color:#c0f>Exp</span>(tau):
</span></span><span style=display:flex><span>    <span style=color:#c30>&#39;&#39;&#39;Exponent, transfers Lie algebra to the group, known as retraction.&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span>    tau <span style=color:#555>=</span> tau<span style=color:#555>.</span>flatten()
</span></span><span style=display:flex><span>    x, y, theta <span style=color:#555>=</span> tau[<span style=color:#f60>0</span>], tau[<span style=color:#f60>1</span>], tau[<span style=color:#f60>2</span>]
</span></span><span style=display:flex><span>    T <span style=color:#555>=</span> np<span style=color:#555>.</span>zeros((<span style=color:#f60>3</span>, <span style=color:#f60>3</span>))
</span></span><span style=display:flex><span>    T[<span style=color:#f60>0</span>:<span style=color:#f60>2</span>, <span style=color:#f60>0</span>:<span style=color:#f60>2</span>] <span style=color:#555>=</span> scipy<span style=color:#555>.</span>linalg<span style=color:#555>.</span>expm(np<span style=color:#555>.</span>array([[<span style=color:#f60>0</span>, <span style=color:#555>-</span>theta], [theta, <span style=color:#f60>0</span>]]))
</span></span><span style=display:flex><span>    V_theta <span style=color:#555>=</span> np<span style=color:#555>.</span>sin(theta) <span style=color:#555>/</span> theta <span style=color:#555>*</span> np<span style=color:#555>.</span>eye(<span style=color:#f60>2</span>) <span style=color:#555>+</span> (<span style=color:#f60>1.</span> <span style=color:#555>-</span> np<span style=color:#555>.</span>cos(theta)) <span style=color:#555>/</span> theta <span style=color:#555>*</span> np<span style=color:#555>.</span>array([[<span style=color:#f60>0</span>, <span style=color:#555>-</span><span style=color:#f60>1</span>], [<span style=color:#f60>1</span>, <span style=color:#f60>0</span>]])
</span></span><span style=display:flex><span>    p <span style=color:#555>=</span> V_theta <span style=color:#555>@</span> np<span style=color:#555>.</span>array([[x], [y]])
</span></span><span style=display:flex><span>    T[<span style=color:#f60>0</span>:<span style=color:#f60>2</span>, <span style=color:#f60>2</span>] <span style=color:#555>=</span> p<span style=color:#555>.</span>flatten()
</span></span><span style=display:flex><span>    T[<span style=color:#f60>2</span>, <span style=color:#f60>2</span>] <span style=color:#555>=</span> <span style=color:#f60>1.0</span>
</span></span><span style=display:flex><span>    <span style=color:#069;font-weight:700>return</span> T
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#069;font-weight:700>def</span> <span style=color:#c0f>Log</span>(T):
</span></span><span style=display:flex><span>    <span style=color:#c30>&#39;&#39;&#39;Inverse of Exp, unwraps group to Lie algebra.&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span>    t <span style=color:#555>=</span> T[<span style=color:#f60>1</span>, <span style=color:#f60>0</span>] <span style=color:#555>/</span> T[<span style=color:#f60>0</span>, <span style=color:#f60>0</span>]
</span></span><span style=display:flex><span>    x, y, theta <span style=color:#555>=</span> T[<span style=color:#f60>0</span>, <span style=color:#f60>2</span>], T[<span style=color:#f60>1</span>, <span style=color:#f60>2</span>], np<span style=color:#555>.</span>arctan2(T[<span style=color:#f60>1</span>, <span style=color:#f60>0</span>], T[<span style=color:#f60>0</span>, <span style=color:#f60>0</span>])
</span></span><span style=display:flex><span>    V_theta <span style=color:#555>=</span> np<span style=color:#555>.</span>sin(theta) <span style=color:#555>/</span> theta <span style=color:#555>*</span> np<span style=color:#555>.</span>eye(<span style=color:#f60>2</span>) <span style=color:#555>+</span> (<span style=color:#f60>1.</span> <span style=color:#555>-</span> np<span style=color:#555>.</span>cos(theta)) <span style=color:#555>/</span> theta <span style=color:#555>*</span> np<span style=color:#555>.</span>array([[<span style=color:#f60>0</span>, <span style=color:#555>-</span><span style=color:#f60>1</span>], [<span style=color:#f60>1</span>, <span style=color:#f60>0</span>]])
</span></span><span style=display:flex><span>    v <span style=color:#555>=</span> np<span style=color:#555>.</span>linalg<span style=color:#555>.</span>inv(V_theta) <span style=color:#555>@</span> np<span style=color:#555>.</span>array([[x], [y]])
</span></span><span style=display:flex><span>    <span style=color:#069;font-weight:700>return</span> np<span style=color:#555>.</span>array([[v[<span style=color:#f60>0</span>, <span style=color:#f60>0</span>]], [v[<span style=color:#f60>1</span>, <span style=color:#f60>0</span>]], [theta]])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#069;font-weight:700>def</span> <span style=color:#c0f>Ad</span>(T):
</span></span><span style=display:flex><span>    <span style=color:#c30>&#39;&#39;&#39;Adjoint, linear transform that transforms tangent space at X to tangent space at identity.&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span>    Ad <span style=color:#555>=</span> np<span style=color:#555>.</span>copy(T[:, :])
</span></span><span style=display:flex><span>    Ad[<span style=color:#f60>0</span>:<span style=color:#f60>2</span>, <span style=color:#f60>2</span>] <span style=color:#555>=</span> <span style=color:#555>-</span>np<span style=color:#555>.</span>array([[<span style=color:#f60>0.</span>, <span style=color:#555>-</span><span style=color:#f60>1.</span>], [<span style=color:#f60>1.</span>, <span style=color:#f60>0</span>]]) <span style=color:#555>@</span> T[<span style=color:#f60>0</span>:<span style=color:#f60>2</span>, <span style=color:#f60>2</span>]
</span></span><span style=display:flex><span>    <span style=color:#069;font-weight:700>return</span> Ad[:, :]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#069;font-weight:700>def</span> <span style=color:#c0f>J_df_dp</span>(p):
</span></span><span style=display:flex><span>    px, py <span style=color:#555>=</span> p[<span style=color:#f60>0</span>], p[<span style=color:#f60>1</span>]
</span></span><span style=display:flex><span>    r <span style=color:#555>=</span> np<span style=color:#555>.</span>sqrt(px<span style=color:#555>**</span><span style=color:#f60>2</span> <span style=color:#555>+</span> py<span style=color:#555>**</span><span style=color:#f60>2</span>)
</span></span><span style=display:flex><span>    <span style=color:#069;font-weight:700>return</span> np<span style=color:#555>.</span>array([px <span style=color:#555>/</span> r, py <span style=color:#555>/</span> r, <span style=color:#f60>0.</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#069;font-weight:700>def</span> <span style=color:#c0f>J_dTp_dT</span>(T, p):
</span></span><span style=display:flex><span>    J <span style=color:#555>=</span> np<span style=color:#555>.</span>eye(<span style=color:#f60>3</span>)
</span></span><span style=display:flex><span>    J[<span style=color:#f60>0</span>:<span style=color:#f60>2</span>, <span style=color:#f60>0</span>:<span style=color:#f60>2</span>] <span style=color:#555>=</span> T[<span style=color:#f60>0</span>:<span style=color:#f60>2</span>, <span style=color:#f60>0</span>:<span style=color:#f60>2</span>]
</span></span><span style=display:flex><span>    J[<span style=color:#f60>0</span>:<span style=color:#f60>2</span>, <span style=color:#f60>2</span>] <span style=color:#555>=</span> T[<span style=color:#f60>0</span>:<span style=color:#f60>2</span>, <span style=color:#f60>0</span>:<span style=color:#f60>2</span>] <span style=color:#555>@</span> np<span style=color:#555>.</span>array([[<span style=color:#f60>0</span>, <span style=color:#555>-</span><span style=color:#f60>1.</span>], [<span style=color:#f60>1.</span>, <span style=color:#f60>0</span>]]) <span style=color:#555>@</span> p
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#069;font-weight:700>return</span> J
</span></span></code></pre></div></div></div><p>Now select true values, measurements and add noise to them.</p><div class=spoiler><span class=spoilerText>Spoiler</span>
<input class=spoilerChecked type=checkbox showtext=Code><div class=spoilerContent><div class=highlight><pre tabindex=0 style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#09f;font-style:italic># true values</span>
</span></span><span style=display:flex><span>trueT_1 <span style=color:#555>=</span> T(<span style=color:#f60>2.</span>, <span style=color:#f60>4.</span>, np<span style=color:#555>.</span>deg2rad(<span style=color:#f60>35</span>))
</span></span><span style=display:flex><span>trueT_2 <span style=color:#555>=</span> T(<span style=color:#f60>2.</span>, <span style=color:#f60>3.</span>, np<span style=color:#555>.</span>deg2rad(<span style=color:#f60>50</span>))
</span></span><span style=display:flex><span>trueT_3 <span style=color:#555>=</span> T(<span style=color:#f60>4.</span>, <span style=color:#f60>3.</span>, np<span style=color:#555>.</span>deg2rad(<span style=color:#f60>70</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#09f;font-style:italic># landmark positions</span>
</span></span><span style=display:flex><span>L1 <span style=color:#555>=</span> np<span style=color:#555>.</span>array([<span style=color:#f60>1.5</span>, <span style=color:#f60>3.75</span>, <span style=color:#f60>1.</span>])
</span></span><span style=display:flex><span>L2 <span style=color:#555>=</span> np<span style=color:#555>.</span>array([<span style=color:#f60>4.5</span>, <span style=color:#f60>3.</span>, <span style=color:#f60>1.</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#09f;font-style:italic># pose increments measured + noise</span>
</span></span><span style=display:flex><span>dT_noise <span style=color:#555>=</span> np<span style=color:#555>.</span>array([<span style=color:#f60>0.01</span>, <span style=color:#f60>0.01</span>, <span style=color:#f60>0.01</span>])
</span></span><span style=display:flex><span>T_12 <span style=color:#555>=</span> Log(np<span style=color:#555>.</span>linalg<span style=color:#555>.</span>inv(trueT_1) <span style=color:#555>@</span> trueT_2) <span style=color:#555>+</span> np<span style=color:#555>.</span>random<span style=color:#555>.</span>normal(scale <span style=color:#555>=</span> dT_noise)<span style=color:#555>.</span>reshape((<span style=color:#f60>3</span>, <span style=color:#f60>1</span>))
</span></span><span style=display:flex><span>T_23 <span style=color:#555>=</span> Log(np<span style=color:#555>.</span>linalg<span style=color:#555>.</span>inv(trueT_2) <span style=color:#555>@</span> trueT_3) <span style=color:#555>+</span> np<span style=color:#555>.</span>random<span style=color:#555>.</span>normal(scale <span style=color:#555>=</span> dT_noise)<span style=color:#555>.</span>reshape((<span style=color:#f60>3</span>, <span style=color:#f60>1</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#09f;font-style:italic># ranges measured + noise</span>
</span></span><span style=display:flex><span>dR_noise <span style=color:#555>=</span> <span style=color:#f60>0.01</span>
</span></span><span style=display:flex><span>R1 <span style=color:#555>=</span> np<span style=color:#555>.</span>sqrt(np<span style=color:#555>.</span>sum((trueT_1[:, <span style=color:#f60>2</span>] <span style=color:#555>-</span> L1) <span style=color:#555>**</span> <span style=color:#f60>2</span>)) <span style=color:#555>+</span> np<span style=color:#555>.</span>random<span style=color:#555>.</span>normal(scale <span style=color:#555>=</span> dR_noise)
</span></span><span style=display:flex><span>R2 <span style=color:#555>=</span> np<span style=color:#555>.</span>sqrt(np<span style=color:#555>.</span>sum((trueT_3[:, <span style=color:#f60>2</span>] <span style=color:#555>-</span> L2) <span style=color:#555>**</span> <span style=color:#f60>2</span>)) <span style=color:#555>+</span> np<span style=color:#555>.</span>random<span style=color:#555>.</span>normal(scale <span style=color:#555>=</span> dR_noise)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#09f;font-style:italic># noise prior estimates</span>
</span></span><span style=display:flex><span>T_1 <span style=color:#555>=</span> trueT_1 <span style=color:#555>@</span> Exp(np<span style=color:#555>.</span>random<span style=color:#555>.</span>normal(scale <span style=color:#555>=</span> <span style=color:#f60>20</span> <span style=color:#555>*</span> dT_noise))
</span></span><span style=display:flex><span>T_2 <span style=color:#555>=</span> trueT_2 <span style=color:#555>@</span> Exp(np<span style=color:#555>.</span>random<span style=color:#555>.</span>normal(scale <span style=color:#555>=</span> <span style=color:#f60>20</span> <span style=color:#555>*</span> dT_noise))
</span></span><span style=display:flex><span>T_3 <span style=color:#555>=</span> trueT_3 <span style=color:#555>@</span> Exp(np<span style=color:#555>.</span>random<span style=color:#555>.</span>normal(scale <span style=color:#555>=</span> <span style=color:#f60>20</span> <span style=color:#555>*</span> dT_noise))
</span></span><span style=display:flex><span>pT_1, pT_2, pT_3 <span style=color:#555>=</span> np<span style=color:#555>.</span>copy(T_1), np<span style=color:#555>.</span>copy(T_2), np<span style=color:#555>.</span>copy(T_3)
</span></span></code></pre></div></div></div><p>Fill-in jacobians and solve the problem iteratively:</p><div class=highlight><pre tabindex=0 style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>u_sigmas <span style=color:#555>=</span> np<span style=color:#555>.</span>array([<span style=color:#f60>0.01</span>, <span style=color:#f60>0.01</span>, <span style=color:#f60>0.01</span>, <span style=color:#f60>0.01</span>, <span style=color:#f60>0.01</span>, <span style=color:#f60>0.01</span>, <span style=color:#f60>0.00001</span>, <span style=color:#f60>0.00001</span>])
</span></span><span style=display:flex><span>W <span style=color:#555>=</span> np<span style=color:#555>.</span>diagflat(<span style=color:#f60>1.</span><span style=color:#555>/</span>u_sigmas)  <span style=color:#09f;font-style:italic># this is Q^(-T/2)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#069;font-weight:700>for</span> i <span style=color:#000;font-weight:700>in</span> <span style=color:#366>range</span>(<span style=color:#f60>0</span>, <span style=color:#f60>1000</span>):
</span></span><span style=display:flex><span>    H <span style=color:#555>=</span> np<span style=color:#555>.</span>zeros((<span style=color:#f60>8</span>, <span style=color:#f60>9</span>))
</span></span><span style=display:flex><span>    est_T_12 <span style=color:#555>=</span> Log(np<span style=color:#555>.</span>linalg<span style=color:#555>.</span>inv(T_1) <span style=color:#555>@</span> T_2)
</span></span><span style=display:flex><span>    H[<span style=color:#f60>0</span>:<span style=color:#f60>3</span>, <span style=color:#f60>0</span>:<span style=color:#f60>3</span>] <span style=color:#555>=</span> <span style=color:#555>-</span>np<span style=color:#555>.</span>linalg<span style=color:#555>.</span>inv(Jl(est_T_12))
</span></span><span style=display:flex><span>    H[<span style=color:#f60>0</span>:<span style=color:#f60>3</span>, <span style=color:#f60>3</span>:<span style=color:#f60>6</span>] <span style=color:#555>=</span>  np<span style=color:#555>.</span>linalg<span style=color:#555>.</span>inv(Jr(est_T_12))
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    est_T_23 <span style=color:#555>=</span> Log(np<span style=color:#555>.</span>linalg<span style=color:#555>.</span>inv(T_2) <span style=color:#555>@</span> T_3)
</span></span><span style=display:flex><span>    H[<span style=color:#f60>3</span>:<span style=color:#f60>6</span>, <span style=color:#f60>3</span>:<span style=color:#f60>6</span>] <span style=color:#555>=</span> <span style=color:#555>-</span>np<span style=color:#555>.</span>linalg<span style=color:#555>.</span>inv(Jl(est_T_23))
</span></span><span style=display:flex><span>    H[<span style=color:#f60>3</span>:<span style=color:#f60>6</span>, <span style=color:#f60>6</span>:<span style=color:#f60>9</span>] <span style=color:#555>=</span>  np<span style=color:#555>.</span>linalg<span style=color:#555>.</span>inv(Jr(est_T_23))
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    est_range_R1 <span style=color:#555>=</span> np<span style=color:#555>.</span>sqrt(np<span style=color:#555>.</span>sum((T_1[:, <span style=color:#f60>2</span>] <span style=color:#555>-</span> L1) <span style=color:#555>**</span> <span style=color:#f60>2</span>))
</span></span><span style=display:flex><span>    <span style=color:#09f;font-style:italic># chain rule</span>
</span></span><span style=display:flex><span>    T1_inv <span style=color:#555>=</span> np<span style=color:#555>.</span>linalg<span style=color:#555>.</span>inv(T_1)
</span></span><span style=display:flex><span>    L1_transformed <span style=color:#555>=</span> (T1_inv <span style=color:#555>@</span> L1)[<span style=color:#f60>0</span>:<span style=color:#f60>2</span>]
</span></span><span style=display:flex><span>    H[<span style=color:#f60>6</span>, <span style=color:#f60>0</span>:<span style=color:#f60>3</span>] <span style=color:#555>=</span> J_df_dp(L1_transformed) <span style=color:#555>@</span> J_dTp_dT(T1_inv, L1[<span style=color:#f60>0</span>:<span style=color:#f60>2</span>]) <span style=color:#555>@</span> <span style=color:#555>-</span>Ad(T_1)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    est_range_R2 <span style=color:#555>=</span> np<span style=color:#555>.</span>sqrt(np<span style=color:#555>.</span>sum((T_3[:, <span style=color:#f60>2</span>] <span style=color:#555>-</span> L2) <span style=color:#555>**</span> <span style=color:#f60>2</span>))
</span></span><span style=display:flex><span>    <span style=color:#09f;font-style:italic># chain rule</span>
</span></span><span style=display:flex><span>    T3_inv <span style=color:#555>=</span> np<span style=color:#555>.</span>linalg<span style=color:#555>.</span>inv(T_3)
</span></span><span style=display:flex><span>    L2_transformed <span style=color:#555>=</span> (T3_inv <span style=color:#555>@</span> L2)[<span style=color:#f60>0</span>:<span style=color:#f60>2</span>]
</span></span><span style=display:flex><span>    H[<span style=color:#f60>7</span>, <span style=color:#f60>6</span>:<span style=color:#f60>9</span>] <span style=color:#555>=</span> J_df_dp(L2_transformed) <span style=color:#555>@</span> J_dTp_dT(T3_inv, L2[<span style=color:#f60>0</span>:<span style=color:#f60>2</span>]) <span style=color:#555>@</span> <span style=color:#555>-</span>Ad(T_3)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    residual <span style=color:#555>=</span> np<span style=color:#555>.</span>vstack((T_12 <span style=color:#555>-</span> est_T_12, 
</span></span><span style=display:flex><span>                          T_23 <span style=color:#555>-</span> est_T_23, 
</span></span><span style=display:flex><span>                          R1 <span style=color:#555>-</span> est_range_R1,
</span></span><span style=display:flex><span>                          R2 <span style=color:#555>-</span> est_range_R2))
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    delta <span style=color:#555>=</span> np<span style=color:#555>.</span>linalg<span style=color:#555>.</span>pinv(H<span style=color:#555>.</span>T <span style=color:#555>@</span> W <span style=color:#555>@</span> H) <span style=color:#555>@</span> H<span style=color:#555>.</span>T <span style=color:#555>@</span> W <span style=color:#555>@</span> residual
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    T_1 <span style=color:#555>=</span> T_1 <span style=color:#555>@</span> Exp(delta[<span style=color:#f60>0</span>:<span style=color:#f60>3</span>, :])
</span></span><span style=display:flex><span>    T_2 <span style=color:#555>=</span> T_2 <span style=color:#555>@</span> Exp(delta[<span style=color:#f60>3</span>:<span style=color:#f60>6</span>, :])
</span></span><span style=display:flex><span>    T_3 <span style=color:#555>=</span> T_3 <span style=color:#555>@</span> Exp(delta[<span style=color:#f60>6</span>:<span style=color:#f60>9</span>, :])
</span></span></code></pre></div><div class=spoiler><span class=spoilerText>Spoiler</span>
<input class=spoilerChecked type=checkbox showtext=Code><div class=spoilerContent><div class=highlight><pre tabindex=0 style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#069;font-weight:700>import</span> <span style=color:#0cf;font-weight:700>matplotlib.pylab</span> <span style=color:#069;font-weight:700>as</span> <span style=color:#0cf;font-weight:700>plt</span>
</span></span><span style=display:flex><span><span style=color:#069;font-weight:700>from</span> <span style=color:#0cf;font-weight:700>matplotlib.patches</span> <span style=color:#069;font-weight:700>import</span> Circle
</span></span><span style=display:flex><span><span style=color:#555>%</span>config InlineBackend<span style=color:#555>.</span>figure_format<span style=color:#555>=</span><span style=color:#c30>&#39;retina&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, ax <span style=color:#555>=</span> plt<span style=color:#555>.</span>subplots(<span style=color:#f60>1</span>, <span style=color:#f60>1</span>, figsize <span style=color:#555>=</span> (<span style=color:#f60>7</span>, <span style=color:#f60>5</span>))
</span></span><span style=display:flex><span>ax<span style=color:#555>.</span>plot([trueT_1[<span style=color:#f60>0</span>, <span style=color:#f60>2</span>], trueT_2[<span style=color:#f60>0</span>, <span style=color:#f60>2</span>], trueT_3[<span style=color:#f60>0</span>, <span style=color:#f60>2</span>]], [trueT_1[<span style=color:#f60>1</span>, <span style=color:#f60>2</span>], trueT_2[<span style=color:#f60>1</span>, <span style=color:#f60>2</span>], trueT_3[<span style=color:#f60>1</span>, <span style=color:#f60>2</span>]], <span style=color:#c30>&#39;o-&#39;</span>, label <span style=color:#555>=</span> <span style=color:#c30>&#39;True&#39;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#555>.</span>plot([T_1[<span style=color:#f60>0</span>, <span style=color:#f60>2</span>], T_2[<span style=color:#f60>0</span>, <span style=color:#f60>2</span>], T_3[<span style=color:#f60>0</span>, <span style=color:#f60>2</span>]], [T_1[<span style=color:#f60>1</span>, <span style=color:#f60>2</span>], T_2[<span style=color:#f60>1</span>, <span style=color:#f60>2</span>], T_3[<span style=color:#f60>1</span>, <span style=color:#f60>2</span>]], <span style=color:#c30>&#39;o-&#39;</span>, label <span style=color:#555>=</span> <span style=color:#c30>&#39;Optimized&#39;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#555>.</span>plot([pT_1[<span style=color:#f60>0</span>, <span style=color:#f60>2</span>], pT_2[<span style=color:#f60>0</span>, <span style=color:#f60>2</span>], pT_3[<span style=color:#f60>0</span>, <span style=color:#f60>2</span>]], [pT_1[<span style=color:#f60>1</span>, <span style=color:#f60>2</span>], pT_2[<span style=color:#f60>1</span>, <span style=color:#f60>2</span>], pT_3[<span style=color:#f60>1</span>, <span style=color:#f60>2</span>]], <span style=color:#c30>&#39;o-&#39;</span>, label <span style=color:#555>=</span> <span style=color:#c30>&#39;Initial&#39;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#555>.</span>scatter([L1[<span style=color:#f60>0</span>], L2[<span style=color:#f60>0</span>]], [L1[<span style=color:#f60>1</span>], L2[<span style=color:#f60>1</span>]], marker<span style=color:#555>=</span><span style=color:#c30>&#39;x&#39;</span>, s <span style=color:#555>=</span> <span style=color:#f60>120</span>, label <span style=color:#555>=</span> <span style=color:#c30>&#39;Landmarks&#39;</span>)
</span></span><span style=display:flex><span><span style=color:#069;font-weight:700>for</span> l, r <span style=color:#000;font-weight:700>in</span> <span style=color:#366>zip</span>((L1, L2), (R1, R2)):
</span></span><span style=display:flex><span>    circle <span style=color:#555>=</span> Circle((l[<span style=color:#f60>0</span>], l[<span style=color:#f60>1</span>]), r, facecolor<span style=color:#555>=</span><span style=color:#c30>&#39;none&#39;</span>, edgecolor<span style=color:#555>=</span><span style=color:#c30>&#39;tab:blue&#39;</span>, linewidth<span style=color:#555>=</span><span style=color:#f60>3</span>, alpha<span style=color:#555>=</span><span style=color:#f60>0.5</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#555>.</span>add_patch(circle)
</span></span><span style=display:flex><span>ax<span style=color:#555>.</span>axis(<span style=color:#c30>&#34;equal&#34;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#555>.</span>legend()
</span></span><span style=display:flex><span>ax<span style=color:#555>.</span>grid()
</span></span><span style=display:flex><span>ax<span style=color:#555>.</span>set_title(<span style=color:#c30>&#34;True, initial and estimated trajectories&#34;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#555>.</span>text(<span style=color:#f60>1</span>, <span style=color:#f60>2.25</span>, <span style=color:#c30>&#34;Circles - measured distances to the landmarks&#34;</span>, c <span style=color:#555>=</span> <span style=color:#c30>&#34;tab:blue&#34;</span>, alpha <span style=color:#555>=</span> <span style=color:#f60>0.8</span>);
</span></span></code></pre></div></div></div><p><img src=output_25_1.png#center alt=png></p><h1 id=references>References</h1><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://arxiv.org/abs/1812.01537>https://arxiv.org/abs/1812.01537</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref2:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href=https://www.roboticsbook.org/S44_logistics_perception.html>https://www.roboticsbook.org/S44_logistics_perception.html</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//mikoff-github-io.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></footer></article><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})'></script></section></div><footer class=footer><section class=container>© 2022
Aleksandr Mikoff
·
Powered by <a href=https://gohugo.io/>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/>Coder</a>.</section></footer><script src=//cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.slim.min.js></script></main></body></html>