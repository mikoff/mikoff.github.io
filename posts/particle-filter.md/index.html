<!doctype html><html lang=en><head><title>Particle Filter: localizing the robot · Aleksandr Mikoff's blog
</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Aleksandr Mikoff"><meta name=description content="Particle filter Link to heading In this post I would like to show the basic implementation of the Particle filter for robot localization using distance measurements to the known anchors, or landmarks. So why particle filter is so widely used? It&rsquo;s widespread application lies in its versatile nature and universalism. The filter is able to:
Work with nonlinearities. Handle non-gaussian distributions. Easily fuse various information sources. Simulate the processes. My sample implementation takes less then 100 lines of Python code and can be found here."><meta name=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="Particle Filter: localizing the robot"><meta name=twitter:description content="Particle filter Link to heading In this post I would like to show the basic implementation of the Particle filter for robot localization using distance measurements to the known anchors, or landmarks. So why particle filter is so widely used? It&rsquo;s widespread application lies in its versatile nature and universalism. The filter is able to:
Work with nonlinearities. Handle non-gaussian distributions. Easily fuse various information sources. Simulate the processes. My sample implementation takes less then 100 lines of Python code and can be found here."><meta property="og:title" content="Particle Filter: localizing the robot"><meta property="og:description" content="Particle filter Link to heading In this post I would like to show the basic implementation of the Particle filter for robot localization using distance measurements to the known anchors, or landmarks. So why particle filter is so widely used? It&rsquo;s widespread application lies in its versatile nature and universalism. The filter is able to:
Work with nonlinearities. Handle non-gaussian distributions. Easily fuse various information sources. Simulate the processes. My sample implementation takes less then 100 lines of Python code and can be found here."><meta property="og:type" content="article"><meta property="og:url" content="https://mikoff.github.io/posts/particle-filter.md/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-03-31T19:59:26+03:00"><meta property="article:modified_time" content="2020-03-31T19:59:26+03:00"><link rel=canonical href=https://mikoff.github.io/posts/particle-filter.md/><link rel=preload href=/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.577e3c5ead537873430da16f0964b754a120fd87c4e2203a00686e7c75b51378.css integrity="sha256-V348Xq1TeHNDDaFvCWS3VKEg/YfE4iA6AGhufHW1E3g=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/image.min.c1a5dfc6bac0eb1b85bcd8abf8aba0d18e0bf02fc972f9a0b17d2962f5ca8dd5.css integrity="sha256-waXfxrrA6xuFvNir+Kug0Y4L8C/JcvmgsX0pYvXKjdU=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/spoiler.min.bf901294afff95f520a8150a4df4249576eb9c49c4f40f5f9c2de750588dd594.css integrity="sha256-v5ASlK//lfUgqBUKTfQklXbrnEnE9A9fnC3nUFiN1ZQ=" crossorigin=anonymous media=screen><link rel=stylesheet href=/plugins/academic-icons/css/academicons.min.f6abb61f6b9b2e784eba22dfb93cd399ce30ee01825791830a2737d6bfcd2be9.css integrity="sha256-9qu2H2ubLnhOuiLfuTzTmc4w7gGCV5GDCic31r/NK+k=" crossorigin=anonymous media=screen><link rel=icon type=image/svg+xml href=/images/favicon.svg sizes=any><link rel=icon type=image/png href=/img/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/img/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://mikoff.github.io/>Aleksandr Mikoff's blog
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa-solid fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/about/>About</a></li><li class=navigation-item><a class=navigation-link href=/posts/>Posts</a></li><li class=navigation-item><a class=navigation-link href=/tags>Tags</a></li><li class=navigation-item><a class=navigation-link href=/notes/>Notes</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://mikoff.github.io/posts/particle-filter.md/>Particle Filter: localizing the robot</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa-solid fa-calendar" aria-hidden=true></i>
<time datetime=2020-03-31T19:59:26+03:00>March 31, 2020
</time></span><span class=reading-time><i class="fa-solid fa-clock" aria-hidden=true></i>
7-minute read</span></div><div class=tags><i class="fa-solid fa-tag" aria-hidden=true></i>
<span class=tag><a href=/tags/particle-filter/>Particle Filter</a>
</span><span class=separator>•</span>
<span class=tag><a href=/tags/sampling/>Sampling</a>
</span><span class=separator>•</span>
<span class=tag><a href=/tags/sensor-fusion/>Sensor Fusion</a></span></div></div></header><div class=post-content><h1 id=particle-filter>Particle filter
<a class=heading-link href=#particle-filter><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><p><img src=./intro.png alt=png></p><p>In this post I would like to show the basic implementation of the Particle filter for robot localization using distance measurements to the known anchors, or landmarks. So why particle filter is so widely used? It&rsquo;s widespread application lies in its versatile nature and universalism. The filter is able to:</p><ul><li>Work with nonlinearities.</li><li>Handle non-gaussian distributions.</li><li>Easily fuse various information sources.</li><li>Simulate the processes.</li></ul><p>My sample implementation takes less then 100 lines of Python code and can be found <a href=https://github.com/mikoff/blog_projects/tree/master/particle_filter class=external-link target=_blank rel=noopener>here</a>.</p><h2 id=idea>Idea
<a class=heading-link href=#idea><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>The idea of the particle filter is to represent the probability distribution by a set $X$ of random samples drawn from the original probability distribution. These samples usually called <em>particles</em>. Every particle $x^{(i)}_t$ can be seen as the hypothesis about what true state can be at time $t$.</p><p>In ideal world, the likelihood of getting a hypothesis $x^{(i)}_t$ shall be proportional to its Bayes posterior:</p>$$x^{(i)}_t \sim p(x_t | z_{1:t}, u_{1:t}).$$<p>The particle filter is the recursive one. That means that belief at time $t$ is being computed from the belief one time step earlier, $t-1$. Since the belief is represented by the particle set $X$, then the particles from $X_{t-1}$ can be transformed into the set $X_t$ based on system model.</p><h2 id=steps>Steps
<a class=heading-link href=#steps><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>Each particle filter iteration cycle can be broken into three steps:</p><ol><li><strong>Prediction</strong>.
Generate the particle set $X_t$ based on the particle set $X_{t-1}$ and the control $u_t$. If it is the initialization, then the particle set have to be generated across all possible states. Usually on this step some noise is injected into the model to accomodate for noise in control and to make particle set more distributed.</li><li><strong>Correction</strong>.
Calculate the importance factor, or weight of each particle. The importance factor is the probability to get the measurement $z_t$ given the hypothesis, or particle $x_t$: $w^{(i)}_t = p(z_t | x^{(i)}_t)$. If more than one measurement is available, say $M$, then all these measurements should be multiplied under the assumption that they are independent: $w^{(i)}_t = \prod_{j=1}^M p(z_{t,j} | x^{(i)}_t)$. Normalize the particle weights: $w_{t}^{(i)}={\frac {{ {w}}_{t}^{(i)}}{\sum _{i=1}^{N}{{w}}_{t}^{(i)}}}$. The set of weighted particles represents the filter belief.</li><li><strong>Resampling</strong>.
It is done through replacing when the more unlikely hypothesis with more likely ones. The probability of drawing each particle is given by its relative importance weight (w.r.t the whole set). <em>The idea of resampling is similar to the idea in volutionary algorithms: only the fittest ones should survive.</em></li></ol><p>Notes:</p><ol><li>It is not always the best idea to sample the particles across all possible state space on the initialization. Sometimes it is better to wait for few available measurements and sample from $p(z_t|m)$, where $m$ &ndash; is the map.</li><li>The resampling process is computational extensive. Therefore it is recommended to resample only when the effective number of particles is less than the given threshold $N_X$. It is shown, that the effective number of particles can be approximated as: $\hat {N}_{\mathit {eff}}={\frac {1}{\sum _{i=1}^{N}\left(w_{k}^{(i)}\right)^{2}}}$. This formula reflects the variance of particle weights.</li></ol><h2 id=importance-sampling>Importance Sampling
<a class=heading-link href=#importance-sampling><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>To understand the idea behind importance sampling more clearly let&rsquo;s reformulate the problem: say we would like to get a sample from target distribution $f$, from which direct sampling is very hard or even impossible.
However, we are able to generate the samples from some probability density function $g$, called proposal distribution.</p><p>What resampling step is able to do is to generate a new set of particles distributed according to the density function $f$ given the set of particles distributed according to density $g$.</p><p>To illustrate this let&rsquo;s generate samples from density $g$. The samples, drawn from $g$ are shown on the bottom of the plot.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>N_samples <span style=color:#000;font-weight:700>=</span> <span style=color:#099>1000</span>
</span></span><span style=display:flex><span>proposal_mean <span style=color:#000;font-weight:700>=</span> <span style=color:#099>25</span>
</span></span><span style=display:flex><span>proposal_std <span style=color:#000;font-weight:700>=</span> <span style=color:#099>10.0</span>
</span></span><span style=display:flex><span>xfrom, xto <span style=color:#000;font-weight:700>=</span> <span style=color:#000;font-weight:700>-</span><span style=color:#099>10</span>, <span style=color:#099>60</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>target_pdf</span>(x):
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>return</span> <span style=color:#099>0.5</span> <span style=color:#000;font-weight:700>*</span> norm<span style=color:#000;font-weight:700>.</span>pdf(x, <span style=color:#099>1.0</span>, <span style=color:#099>3.0</span>) <span style=color:#000;font-weight:700>+</span> <span style=color:#099>0.5</span> <span style=color:#000;font-weight:700>*</span> norm<span style=color:#000;font-weight:700>.</span>pdf(x, <span style=color:#099>12.0</span>, <span style=color:#099>4.0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>proposal_samples <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>normal(proposal_mean, proposal_std, size<span style=color:#000;font-weight:700>=</span>N_samples)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, ax <span style=color:#000;font-weight:700>=</span> plt<span style=color:#000;font-weight:700>.</span>subplots(<span style=color:#099>1</span>, <span style=color:#099>1</span>, figsize<span style=color:#000;font-weight:700>=</span>(<span style=color:#099>10</span>, <span style=color:#099>4</span>), sharex <span style=color:#000;font-weight:700>=</span> <span style=color:#000;font-weight:700>True</span>)
</span></span><span style=display:flex><span>x <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>linspace(xfrom, xto, <span style=color:#099>1000</span>)
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>plot(x, norm<span style=color:#000;font-weight:700>.</span>pdf(x, proposal_mean, proposal_std), label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;proposal pdf, $g(x)$&#39;</span>, c<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;red&#39;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>plot(x, target_pdf(x), label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;target pdf, $f(x)$&#39;</span>, c<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;green&#39;</span>)
</span></span><span style=display:flex><span><span style=color:#998;font-style:italic># plot rug plot</span>
</span></span><span style=display:flex><span>rel_rug_height <span style=color:#000;font-weight:700>=</span> ax<span style=color:#000;font-weight:700>.</span>get_ylim()[<span style=color:#099>1</span>] <span style=color:#000;font-weight:700>/</span> <span style=color:#099>20.0</span>
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>vlines(proposal_samples, [<span style=color:#099>0</span>] <span style=color:#000;font-weight:700>*</span> N_samples, [rel_rug_height] <span style=color:#000;font-weight:700>*</span> N_samples, 
</span></span><span style=display:flex><span>          alpha<span style=color:#000;font-weight:700>=</span><span style=color:#099>0.05</span>, colors<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;red&#39;</span>, label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;proposal samples&#39;</span>, linewidths<span style=color:#000;font-weight:700>=</span><span style=color:#099>5.0</span>)
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>set_xlim([xfrom, xto])
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>legend()
</span></span></code></pre></div><p><img src=./index_6_1.png alt=png></p><p>Samples from $f$ are obtained by attaching weights $w = f(x) / g(x)$ to each sample, drawn from $g$. The following plot shows the proposal samples with their associated weights (the height of the vertical lines). Some weights became equal to zero while the others are significantly increased. For example, in spite of the fact that the proposal density in range $(20, 30)$ is high, due to the weighing these samples became insignificant.</p><p>The combination of color intensity and the height of the vertical bars can be considered as the target probability density function. The more intensive and higher the vertical bars - the more probable the neighbourhood samples $x$ around it.
As an alternative, weights are shown as circles where the radius of the circle reflects the particle weight and the circle color intensity due to the overlapping - is their density in the given region.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>target_weights <span style=color:#000;font-weight:700>=</span> target_pdf(proposal_samples) <span style=color:#000;font-weight:700>/</span> norm<span style=color:#000;font-weight:700>.</span>pdf(proposal_samples, proposal_mean, proposal_std)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, ax <span style=color:#000;font-weight:700>=</span> plt<span style=color:#000;font-weight:700>.</span>subplots(<span style=color:#099>1</span>, <span style=color:#099>1</span>, figsize<span style=color:#000;font-weight:700>=</span>(<span style=color:#099>10</span>, <span style=color:#099>4</span>))
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>set_xlim([xfrom, xto])
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>vlines(proposal_samples, [<span style=color:#099>0</span>] <span style=color:#000;font-weight:700>*</span> N_samples, target_weights <span style=color:#000;font-weight:700>/</span> np<span style=color:#000;font-weight:700>.</span>sum(target_weights), 
</span></span><span style=display:flex><span>          alpha<span style=color:#000;font-weight:700>=</span><span style=color:#099>0.05</span>, colors<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;green&#39;</span>, label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;proposal samples with $ w = f(x) / g(x)$&#39;</span>, linewidths<span style=color:#000;font-weight:700>=</span><span style=color:#099>5.0</span>)
</span></span><span style=display:flex><span>x <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>linspace(xfrom, xto, <span style=color:#099>1000</span>)
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>plot(x, target_pdf(x), label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;target pdf, $f(x)$&#39;</span>, c<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;green&#39;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>scatter(proposal_samples, [ax<span style=color:#000;font-weight:700>.</span>get_ylim()[<span style=color:#099>0</span>]] <span style=color:#000;font-weight:700>*</span> N_samples, 
</span></span><span style=display:flex><span>           sizes<span style=color:#000;font-weight:700>=</span>target_weights <span style=color:#000;font-weight:700>/</span> np<span style=color:#000;font-weight:700>.</span>sum(target_weights) <span style=color:#000;font-weight:700>*</span> <span style=color:#099>10000</span>, alpha<span style=color:#000;font-weight:700>=</span><span style=color:#099>0.05</span>,
</span></span><span style=display:flex><span>           label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;proposal sample circles with $r \sim w$&#34;</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>legend()
</span></span></code></pre></div><p><img src=./index_8_1.png alt=png></p><p>Now, if we resample from the weighted samples distribution we get the samples from our target distribution (as $N \xrightarrow{}\infty$):</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>systematic_resample</span>(weights, samples):
</span></span><span style=display:flex><span>    weights, samples, n_samples <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>array(weights), np<span style=color:#000;font-weight:700>.</span>array(samples), <span style=color:#0086b3>len</span>(samples)
</span></span><span style=display:flex><span>    weights <span style=color:#000;font-weight:700>/=</span> np<span style=color:#000;font-weight:700>.</span>sum(weights)
</span></span><span style=display:flex><span>    r, c, i <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>uniform(<span style=color:#099>0.0</span>, <span style=color:#099>1.0</span> <span style=color:#000;font-weight:700>/</span> N_samples), weights[<span style=color:#099>0</span>], <span style=color:#099>0</span>
</span></span><span style=display:flex><span>    resampled <span style=color:#000;font-weight:700>=</span> []
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>for</span> m <span style=color:#000;font-weight:700>in</span> <span style=color:#0086b3>range</span>(<span style=color:#099>0</span>, n_samples):
</span></span><span style=display:flex><span>        U <span style=color:#000;font-weight:700>=</span> r <span style=color:#000;font-weight:700>+</span> m <span style=color:#000;font-weight:700>/</span> n_samples
</span></span><span style=display:flex><span>        <span style=color:#000;font-weight:700>while</span> c <span style=color:#000;font-weight:700>&lt;</span> U:
</span></span><span style=display:flex><span>            i <span style=color:#000;font-weight:700>+=</span> <span style=color:#099>1</span>
</span></span><span style=display:flex><span>            c <span style=color:#000;font-weight:700>+=</span> weights[i]
</span></span><span style=display:flex><span>        resampled<span style=color:#000;font-weight:700>.</span>append(deepcopy(samples[i]))
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>return</span> resampled
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, ax <span style=color:#000;font-weight:700>=</span> plt<span style=color:#000;font-weight:700>.</span>subplots(<span style=color:#099>1</span>, <span style=color:#099>1</span>, figsize<span style=color:#000;font-weight:700>=</span>(<span style=color:#099>10</span>, <span style=color:#099>4</span>))  
</span></span><span style=display:flex><span>x <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>linspace(xfrom, xto, <span style=color:#099>200</span>)
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>plot(x, target_pdf(x), label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;target pdf, $f(x)$&#39;</span>, c<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;green&#39;</span>)
</span></span><span style=display:flex><span>target_samples <span style=color:#000;font-weight:700>=</span> systematic_resample(target_weights, proposal_samples)
</span></span><span style=display:flex><span>rel_rug_height <span style=color:#000;font-weight:700>=</span> ax<span style=color:#000;font-weight:700>.</span>get_ylim()[<span style=color:#099>1</span>] <span style=color:#000;font-weight:700>/</span> <span style=color:#099>20.0</span>
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>vlines(target_samples, [<span style=color:#099>0</span>] <span style=color:#000;font-weight:700>*</span> N_samples, [rel_rug_height] <span style=color:#000;font-weight:700>*</span> N_samples, 
</span></span><span style=display:flex><span>          alpha<span style=color:#000;font-weight:700>=</span><span style=color:#099>0.05</span>, colors<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;violet&#39;</span>, label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;resampled&#39;</span>, linewidths<span style=color:#000;font-weight:700>=</span><span style=color:#099>5.0</span>)
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>scatter(target_samples, [ax<span style=color:#000;font-weight:700>.</span>get_ylim()[<span style=color:#099>0</span>]] <span style=color:#000;font-weight:700>*</span> N_samples, 
</span></span><span style=display:flex><span>           s<span style=color:#000;font-weight:700>=</span><span style=color:#099>100</span>, alpha<span style=color:#000;font-weight:700>=</span><span style=color:#099>0.05</span>,
</span></span><span style=display:flex><span>           label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;resampled samples with $r \sim w$&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>legend()
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>set_xlim([xfrom, xto])
</span></span><span style=display:flex><span>plt<span style=color:#000;font-weight:700>.</span>show()
</span></span></code></pre></div><p><img src=./index_10_0.png alt=png></p><h2 id=particle-filter-implementation>Particle filter implementation
<a class=heading-link href=#particle-filter-implementation><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>Now, having all key concepts explained, we can write the particle filter implementation for robot localization.
The filter state consists of:</p><ul><li>robot position - $(x, y)$.</li><li>robot heading angle - $\theta$.</li></ul><p>The robot moves along a map and measures the distances to the known landmarks, or anchors, when they are within its sense range.</p><p>The robot distance measurements to the landmarks and its motion controls are not perfect. To take that into account I inject the noises in particle filter process in the following forms:</p><ul><li>For predict step - the control $u_t$ that consists of $(\delta d, \delta \theta)$ is additionally pertrubated with random noise, $N(0, \sigma_{motion})$ and $N(0, \sigma_{\theta})$.</li><li>For correction step. Whenever the robot measures the distances to the known landmark $n$, we can asses the measurement likelihood given our state $(x, y, \theta)$. Having the predicted $\hat{d} = \sqrt{(x - x_{landmark})^2 + (y - y_{landmark})^2}$ and measured $d_n$ distances, and the measurement noise $\sigma_d$ the likelihood can be calculated as:
$$p(z_n|x_t) = {\frac {1}{\sigma_d {\sqrt {2\pi }}}}e^{-{\frac {1}{2}}\left({\frac {\hat{d}-d_{n} }{\sigma_d }}\right)^{2}}$$
The current particle weight have to be multiplied with $p(z_n|x_t)$ for each available measurement.</li></ul><p>Then the weights have to be renormalized, particles - resampled, if it is neccessary.
This process continues to evolve in iterative manner.</p><h3 id=animation>Animation
<a class=heading-link href=#animation><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>To test the code and view the particle filtering process in action you can simply execute <em>run.py</em> <a href=https://github.com/mikoff/blog_projects/tree/particle_filter/run.py class=external-link target=_blank rel=noopener>script</a>:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>python3 run<span style=color:#000;font-weight:700>.</span>py
</span></span></code></pre></div><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src="https://www.youtube.com/embed/tHozufezrpE?autoplay=1" style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><p>In the following animation the robot moves along a circle and measures the distances to anchors that are marked with red crosses.
The true robot position is shown with black plus sign. The blue lines, connecting the robot and the anchors - true distance measurements between the robot and the anchors, the grey circles - the measured distances between robot and anchor.
Feel free to experiment with configuration and add new types of measurements (for example the heading w.r.t to the anchors, or absolute motion heading).</p></div><footer><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//mikoff-github-io.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}(),document.addEventListener("themeChanged",function(){document.readyState=="complete"&&DISQUS.reset({reload:!0,config:disqus_config})})</script></footer></article><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0 crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})'></script></section></div><footer class=footer><section class=container>©
2024
Aleksandr Mikoff
·
Powered by <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/ target=_blank rel=noopener>Coder</a>.</section></footer></main><script src=/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script></body></html>