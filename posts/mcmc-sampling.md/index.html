<!doctype html><html lang=en><head><title>MCMC sampling · Aleksandr Mikoff's blog
</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Aleksandr Mikoff"><meta name=description content="Quite often we want to sample from distributions that have computationally untractable CDF. To draw samples from them the numerical procedures are used. In the following note I would like to demonstrate few approaches for one particular example: having 2D robot perception and a map we want to sample most probable poses of this robot. This problem often emerges during initialization or re-initialization of the estimated robot pose when the filter diverged or needs to be initialized from scratch and we want to guarantee the fast convergence."><meta name=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="MCMC sampling"><meta name=twitter:description content="Quite often we want to sample from distributions that have computationally untractable CDF. To draw samples from them the numerical procedures are used. In the following note I would like to demonstrate few approaches for one particular example: having 2D robot perception and a map we want to sample most probable poses of this robot. This problem often emerges during initialization or re-initialization of the estimated robot pose when the filter diverged or needs to be initialized from scratch and we want to guarantee the fast convergence."><meta property="og:title" content="MCMC sampling"><meta property="og:description" content="Quite often we want to sample from distributions that have computationally untractable CDF. To draw samples from them the numerical procedures are used. In the following note I would like to demonstrate few approaches for one particular example: having 2D robot perception and a map we want to sample most probable poses of this robot. This problem often emerges during initialization or re-initialization of the estimated robot pose when the filter diverged or needs to be initialized from scratch and we want to guarantee the fast convergence."><meta property="og:type" content="article"><meta property="og:url" content="https://mikoff.github.io/posts/mcmc-sampling.md/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-03-24T21:00:00+03:00"><meta property="article:modified_time" content="2024-03-24T21:00:00+03:00"><link rel=canonical href=https://mikoff.github.io/posts/mcmc-sampling.md/><link rel=preload href=/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.577e3c5ead537873430da16f0964b754a120fd87c4e2203a00686e7c75b51378.css integrity="sha256-V348Xq1TeHNDDaFvCWS3VKEg/YfE4iA6AGhufHW1E3g=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/image.min.c1a5dfc6bac0eb1b85bcd8abf8aba0d18e0bf02fc972f9a0b17d2962f5ca8dd5.css integrity="sha256-waXfxrrA6xuFvNir+Kug0Y4L8C/JcvmgsX0pYvXKjdU=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/spoiler.min.bf901294afff95f520a8150a4df4249576eb9c49c4f40f5f9c2de750588dd594.css integrity="sha256-v5ASlK//lfUgqBUKTfQklXbrnEnE9A9fnC3nUFiN1ZQ=" crossorigin=anonymous media=screen><link rel=stylesheet href=/plugins/academic-icons/css/academicons.min.f6abb61f6b9b2e784eba22dfb93cd399ce30ee01825791830a2737d6bfcd2be9.css integrity="sha256-9qu2H2ubLnhOuiLfuTzTmc4w7gGCV5GDCic31r/NK+k=" crossorigin=anonymous media=screen><link rel=icon type=image/svg+xml href=/images/favicon.svg sizes=any><link rel=icon type=image/png href=/img/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/img/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://mikoff.github.io/>Aleksandr Mikoff's blog
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa-solid fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/about/>About</a></li><li class=navigation-item><a class=navigation-link href=/posts/>Posts</a></li><li class=navigation-item><a class=navigation-link href=/tags>Tags</a></li><li class=navigation-item><a class=navigation-link href=/notes/>Notes</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://mikoff.github.io/posts/mcmc-sampling.md/>MCMC sampling</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa-solid fa-calendar" aria-hidden=true></i>
<time datetime=2024-03-24T21:00:00+03:00>March 24, 2024
</time></span><span class=reading-time><i class="fa-solid fa-clock" aria-hidden=true></i>
9-minute read</span></div><div class=tags><i class="fa-solid fa-tag" aria-hidden=true></i>
<span class=tag><a href=/tags/sampling/>Sampling</a>
</span><span class=separator>•</span>
<span class=tag><a href=/tags/gibbs/>Gibbs</a>
</span><span class=separator>•</span>
<span class=tag><a href=/tags/probability/>Probability</a>
</span><span class=separator>•</span>
<span class=tag><a href=/tags/statistics/>Statistics</a></span></div></div></header><div class=post-content><p>Quite often we want to sample from distributions that have computationally untractable CDF. To draw samples from them the numerical procedures are used. In the following note I would like to demonstrate few approaches for one particular example: having 2D robot perception and a map we want to sample most probable poses of this robot. This problem often emerges during initialization or re-initialization of the estimated robot pose when the filter diverged or needs to be initialized from scratch and we want to guarantee the <em>fast</em> convergence.</p><p>Most of the approaches discussed in this post come from [1].</p><h2 id=rejection-sampling>Rejection sampling
<a class=heading-link href=#rejection-sampling><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>Suppose we want to sample from an arbitrary distribution $p(\mathbf{z})$, which pdf has a complex form and we can not sample directly. However, we can easily calculate the actual value of $p(\mathbf{z})$ for any given $\mathbf{z}$ up to some normalizing constant $Z$:</p>$$
p(\mathbf{z}) = \frac{1}{Z_p}\tilde{p}(\mathbf{z}),
$$<p>where $\tilde{p}(\mathbf{z})$ can be readily evaluated, but $Z_p$ is unknown.
The idea is as follows:</p><ol><li>Draw a sample $z_0$ from a <em>proposal</em> distribution $q(\mathbf{z})$.</li><li>Draw a sample $u_0$ from the uniform distribution over $[0, kq(z_0)]$.</li><li>If $u_0 \leq \tilde{p}(z_0)$ then the sample $z_0$ is accepted, otherwise it is rejected.</li></ol><p>Here is the visualization of the algorithm. First we sample a random number $z_0$ from the proposal distribution (along horizontal). Then we sample a second number $u_0$ (along vertical), the upper bound of $u_o$ is equal to $kq(z_0)$, which makes perfects sense - our proposal distribution should cover all the distribution we would like to sample from. As a last step we check whether or not $u_0$ is above or under $p(z_0)$. If it is under, then we are <em>within</em> our target distribution and the sample should be retained.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000;font-weight:700>import</span> <span style=color:#555>matplotlib.pyplot</span> <span style=color:#000;font-weight:700>as</span> <span style=color:#555>plt</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>import</span> <span style=color:#555>numpy</span> <span style=color:#000;font-weight:700>as</span> <span style=color:#555>np</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>from</span> <span style=color:#555>scipy.stats</span> <span style=color:#000;font-weight:700>import</span> uniform
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>seed(<span style=color:#099>100</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>exp_pdf <span style=color:#000;font-weight:700>=</span> <span style=color:#000;font-weight:700>lambda</span> x, Lambda<span style=color:#000;font-weight:700>=</span><span style=color:#099>0.5</span>: Lambda <span style=color:#000;font-weight:700>*</span> np<span style=color:#000;font-weight:700>.</span>exp(<span style=color:#000;font-weight:700>-</span>Lambda <span style=color:#000;font-weight:700>*</span> x)
</span></span><span style=display:flex><span>uniform_pdf <span style=color:#000;font-weight:700>=</span> uniform(<span style=color:#099>0</span>, <span style=color:#099>10</span>)<span style=color:#000;font-weight:700>.</span>pdf
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>samples <span style=color:#000;font-weight:700>=</span> []
</span></span><span style=display:flex><span><span style=color:#998;font-style:italic># sample from our proposal distribution</span>
</span></span><span style=display:flex><span>z0 <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>uniform(<span style=color:#099>0</span>, <span style=color:#099>10</span>, size <span style=color:#000;font-weight:700>=</span> <span style=color:#099>1000000</span>)
</span></span><span style=display:flex><span><span style=color:#998;font-style:italic># sample from the uniform over our range</span>
</span></span><span style=display:flex><span><span style=color:#998;font-style:italic># since our proposal is uniform, we know the pdf of each sample = 0.1</span>
</span></span><span style=display:flex><span><span style=color:#998;font-style:italic># k should be equal to 5 to make sure that k * q(z) &gt;= p(z)</span>
</span></span><span style=display:flex><span>k <span style=color:#000;font-weight:700>=</span> <span style=color:#099>5.</span>
</span></span><span style=display:flex><span>u0 <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>uniform(<span style=color:#099>0</span>, k <span style=color:#000;font-weight:700>*</span> <span style=color:#099>0.1</span>, size <span style=color:#000;font-weight:700>=</span> <span style=color:#099>1000000</span>)
</span></span><span style=display:flex><span>samples <span style=color:#000;font-weight:700>=</span> z0[u0 <span style=color:#000;font-weight:700>&lt;=</span> exp_pdf(z0)]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>xx <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>arange(<span style=color:#099>0</span>, <span style=color:#099>10</span>, <span style=color:#099>0.05</span>)
</span></span><span style=display:flex><span>fig, axes <span style=color:#000;font-weight:700>=</span> plt<span style=color:#000;font-weight:700>.</span>subplots(<span style=color:#099>2</span>, <span style=color:#099>4</span>, figsize <span style=color:#000;font-weight:700>=</span> (<span style=color:#099>10</span>, <span style=color:#099>4</span>), sharex <span style=color:#000;font-weight:700>=</span> <span style=color:#000;font-weight:700>True</span>, sharey <span style=color:#000;font-weight:700>=</span> <span style=color:#000;font-weight:700>True</span>)
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>for</span> i, ax <span style=color:#000;font-weight:700>in</span> <span style=color:#0086b3>enumerate</span>(axes<span style=color:#000;font-weight:700>.</span>flatten()):
</span></span><span style=display:flex><span>    ax<span style=color:#000;font-weight:700>.</span>plot(xx, exp_pdf(xx), label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;$p(z)$&#34;</span>, c<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;tab:orange&#34;</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#000;font-weight:700>.</span>plot(xx, uniform_pdf(xx) <span style=color:#000;font-weight:700>*</span> k, label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;$kq(z)$&#34;</span>, c<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;tab:blue&#34;</span>)
</span></span><span style=display:flex><span>    z <span style=color:#000;font-weight:700>=</span> z0[i]
</span></span><span style=display:flex><span>    u <span style=color:#000;font-weight:700>=</span> u0[i]
</span></span><span style=display:flex><span>    ax<span style=color:#000;font-weight:700>.</span>scatter([z], [u], label <span style=color:#000;font-weight:700>=</span> <span style=color:#d14>&#34;$u_0$&#34;</span>)          <span style=color:#998;font-style:italic># that is our </span>
</span></span><span style=display:flex><span>    ax<span style=color:#000;font-weight:700>.</span>scatter([z], [exp_pdf(z)], label <span style=color:#000;font-weight:700>=</span> <span style=color:#d14>&#34;$p(z_0)$&#34;</span>) <span style=color:#998;font-style:italic># that is the pdf we want to sample from</span>
</span></span><span style=display:flex><span>    ax<span style=color:#000;font-weight:700>.</span>text(z <span style=color:#000;font-weight:700>+</span> <span style=color:#099>0.5</span>, u, <span style=color:#d14>f</span><span style=color:#d14>&#39;</span><span style=color:#d14>{</span><span style=color:#d14>&#34;Accept&#34;</span> <span style=color:#000;font-weight:700>if</span> u <span style=color:#000;font-weight:700>&lt;=</span> exp_pdf(z) <span style=color:#000;font-weight:700>else</span> <span style=color:#d14>&#34;Reject&#34;</span><span style=color:#d14>}</span><span style=color:#d14>&#39;</span>, fontsize <span style=color:#000;font-weight:700>=</span> <span style=color:#099>7.5</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#000;font-weight:700>.</span>legend(loc<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;upper right&#34;</span>, fontsize <span style=color:#000;font-weight:700>=</span> <span style=color:#099>7.5</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#000;font-weight:700>.</span>set(xlabel <span style=color:#000;font-weight:700>=</span> <span style=color:#d14>&#34;$z$&#34;</span>, ylabel <span style=color:#000;font-weight:700>=</span> <span style=color:#d14>&#34;pdf&#34;</span>)
</span></span></code></pre></div><p><img src=./20240322220518.png alt=png></p><p>It is worth to note several things:</p><ul><li>The original values of $z$ are accepted with probability $\frac{p(z)}{kq(z)}$. If we take the integral it becomes obvious that the fraction of points that are rejected depends on the ratio of the area under the unnormalized distribution $p(z)$ to the are under the curve $kq(z)$.</li><li>As a consequence of this the proposal distribution should be as close as possible to the target distribution to achieve the high acceptance rate.</li><li>If we sample from uniform distribution, we can get rid of $kq(z)$ evaluation, since it is constant.</li></ul><p>Let&rsquo;s confirm that our samples reflect the original distribution we wanted to sample from:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>fig, ax <span style=color:#000;font-weight:700>=</span> plt<span style=color:#000;font-weight:700>.</span>subplots(<span style=color:#099>1</span>, <span style=color:#099>1</span>, figsize <span style=color:#000;font-weight:700>=</span> (<span style=color:#099>5</span>, <span style=color:#099>3</span>))
</span></span><span style=display:flex><span>xx <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>arange(<span style=color:#099>0</span>, <span style=color:#099>10</span>, <span style=color:#099>0.05</span>)
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>hist(samples, density<span style=color:#000;font-weight:700>=</span><span style=color:#000;font-weight:700>True</span>, stacked<span style=color:#000;font-weight:700>=</span><span style=color:#000;font-weight:700>True</span>, bins <span style=color:#000;font-weight:700>=</span> <span style=color:#099>100</span>, label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;samples&#34;</span>);
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>plot(xx, exp_pdf(xx), label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;$p(z)$&#34;</span>, c<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;tab:orange&#34;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>grid()
</span></span><span style=display:flex><span>ax<span style=color:#000;font-weight:700>.</span>legend()
</span></span></code></pre></div><p><img src=./20240322220533.png alt=png></p><h2 id=mcmc-sampling>MCMC sampling
<a class=heading-link href=#mcmc-sampling><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>Since direct sampling from a multidimensional distribution is hard, another method is required. Such a family of methods is called Markov chain Monte Carlo (MCMC), which allows sampling from a large class of distributions and scales well for high-dimensional spaces.</p><p>The idea is quite close to the rejection sampling, but this time we keep a record of the current state $\mathbf{z}^{(\tau)}$, and the proposal distribution $q(\mathbf{z}|\mathbf{z}^{(\tau)})$ depends on this current state, and the sequence of samples forms a Markov chain.</p><p>At each cycle of the algorithm, a candidate sample $\mathbf{z}^*$ is generated and then accepted based on an appropriate criterion.</p><h3 id=metropolis-algorithm>Metropolis algorithm
<a class=heading-link href=#metropolis-algorithm><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>In Metropolis algorithm, it is assumed that the proposal distribution is symmetric and the candidate sample is accepted with probability:</p>$$
A(\mathbf{z}^*, \mathbf{z}^{(\tau)}) = \min\left( 1, \frac{\tilde{p}(\mathbf{z}^*)}{ \tilde{p}(\mathbf{z}^{(\tau)})} \right).
$$<p>The simplest method to achieve this is by selecting a random number $\mathbf{u}$ from a uniform distribution and then accepting the sample if $A > u$.
<em>Notes:</em></p><ul><li>In contrast to rejection sampling, the candidate is kept not only if the sampled value falls &ldquo;within&rdquo; our target distribution, but also if the next drawn sample leads to an increase of the $p(\mathbf{z})$.</li><li>If proposal distribution is not symmetric, then the Metropolis-Hastings criterion shall be used, that applies the correction term.</li></ul><h3 id=gibbs-sampling>Gibbs Sampling
<a class=heading-link href=#gibbs-sampling><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>The concept of Gibbs sampling is relatively straightforward: at each iteration, we update the value of one variable by sampling from its conditional distribution given the values of the other variables. This process iterates through each variable in a cyclical manner.</p><p>The practical utility of Gibbs sampling relies on the ease of sampling from the conditional distributions $p(z_k|\mathbf{z}_{\not k})$. Two effective approaches are:</p><ul><li>Utilizing rejection sampling techniques, as previously discussed.</li><li>Precomputing $p(\mathbf{z})$ on a multidimensional grid and subsequently leveraging this grid to compute the conditional probability density functions.</li></ul><h2 id=sampling>Sampling
<a class=heading-link href=#sampling><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>Now let&rsquo;s actually sample the robot poses given our perception. For a simplicity let&rsquo;s assume that our map consists of 5 points and we also perceive same 5 points, but in robot coordinate system.</p><h3 id=option-1>Option 1
<a class=heading-link href=#option-1><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>The first option is to directly sample from our uniform distribution and check whether or not the next sample should be discarded using Metropolis algorithm, while iterating through our state variables.</p><div class=spoiler><span class=spoilerText>Spoiler</span>
<input class=spoilerChecked type=checkbox showtext=Code><div class=spoilerContent><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000;font-weight:700>import</span> <span style=color:#555>numpy</span> <span style=color:#000;font-weight:700>as</span> <span style=color:#555>np</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>from</span> <span style=color:#555>scipy.spatial</span> <span style=color:#000;font-weight:700>import</span> KDTree
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>from</span> <span style=color:#555>scipy.stats</span> <span style=color:#000;font-weight:700>import</span> norm
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>norm_pdf</span>(x, mu, sigma):
</span></span><span style=display:flex><span>    <span style=color:#d14>&#34;&#34;&#34;Calculates normal pdf for sample x given parameters mu and sigma.&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    variance <span style=color:#000;font-weight:700>=</span> sigma<span style=color:#000;font-weight:700>**</span><span style=color:#099>2</span>
</span></span><span style=display:flex><span>    numerator <span style=color:#000;font-weight:700>=</span> x <span style=color:#000;font-weight:700>-</span> mu
</span></span><span style=display:flex><span>    denomenator <span style=color:#000;font-weight:700>=</span> <span style=color:#099>2</span><span style=color:#000;font-weight:700>*</span>variance
</span></span><span style=display:flex><span>    pdf <span style=color:#000;font-weight:700>=</span> ((<span style=color:#099>1</span><span style=color:#000;font-weight:700>/</span>(np<span style=color:#000;font-weight:700>.</span>sqrt(<span style=color:#099>2</span><span style=color:#000;font-weight:700>*</span>np<span style=color:#000;font-weight:700>.</span>pi)<span style=color:#000;font-weight:700>*</span>sigma))<span style=color:#000;font-weight:700>*</span>np<span style=color:#000;font-weight:700>.</span>exp(<span style=color:#000;font-weight:700>-</span>(numerator<span style=color:#000;font-weight:700>**</span><span style=color:#099>2</span>)<span style=color:#000;font-weight:700>/</span>denomenator))
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>return</span> pdf
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>transform_to_world</span>(perception, pose):
</span></span><span style=display:flex><span>    <span style=color:#d14>&#34;&#34;&#34;Resolves perception in world coordinate frame based on current pose.&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    x, y, theta <span style=color:#000;font-weight:700>=</span> pose
</span></span><span style=display:flex><span>    c, s <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>cos(theta), np<span style=color:#000;font-weight:700>.</span>sin(theta)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    perception_world <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>zeros_like(perception)
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>for</span> i, p <span style=color:#000;font-weight:700>in</span> <span style=color:#0086b3>enumerate</span>(perception):
</span></span><span style=display:flex><span>        perception_world[i, :] <span style=color:#000;font-weight:700>=</span> (p[<span style=color:#099>0</span>] <span style=color:#000;font-weight:700>*</span> c <span style=color:#000;font-weight:700>-</span> p[<span style=color:#099>1</span>] <span style=color:#000;font-weight:700>*</span> s <span style=color:#000;font-weight:700>+</span> x, p[<span style=color:#099>0</span>] <span style=color:#000;font-weight:700>*</span> s <span style=color:#000;font-weight:700>+</span> p[<span style=color:#099>1</span>] <span style=color:#000;font-weight:700>*</span> c <span style=color:#000;font-weight:700>+</span> y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>return</span> perception_world
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>estimate_perception_logpdf</span>(perception, x, y, theta, sigma<span style=color:#000;font-weight:700>=</span><span style=color:#099>1.</span>):
</span></span><span style=display:flex><span>    <span style=color:#d14>&#34;&#34;&#34;Calculates pdf of perception given the pose.&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    perception_world <span style=color:#000;font-weight:700>=</span> transform_to_world(perception, (x, y, theta))
</span></span><span style=display:flex><span>    distances, _ <span style=color:#000;font-weight:700>=</span> tree<span style=color:#000;font-weight:700>.</span>query(perception_world, k<span style=color:#000;font-weight:700>=</span><span style=color:#099>1</span>)
</span></span><span style=display:flex><span>    w <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>sum(np<span style=color:#000;font-weight:700>.</span>log(norm_pdf(distances, <span style=color:#099>0.</span>, sigma)))
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>return</span> w
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>gibbs_sample_step</span>(perception, current_logpdf, current_pose, dim_to_sample, n_attempts<span style=color:#000;font-weight:700>=</span><span style=color:#099>500</span>):
</span></span><span style=display:flex><span>    <span style=color:#d14>&#34;&#34;&#34;Tries to draw the next sample based on current pose, perception and current pdf.&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    x, y, theta <span style=color:#000;font-weight:700>=</span> current_pose
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>for</span> i <span style=color:#000;font-weight:700>in</span> <span style=color:#0086b3>range</span>(<span style=color:#099>0</span>, n_attempts):
</span></span><span style=display:flex><span>        <span style=color:#000;font-weight:700>if</span> dim_to_sample <span style=color:#000;font-weight:700>==</span> <span style=color:#d14>&#39;x&#39;</span>:
</span></span><span style=display:flex><span>            x <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>uniform(<span style=color:#099>0</span>, <span style=color:#099>20</span>)
</span></span><span style=display:flex><span>        <span style=color:#000;font-weight:700>elif</span> dim_to_sample <span style=color:#000;font-weight:700>==</span> <span style=color:#d14>&#39;y&#39;</span>:
</span></span><span style=display:flex><span>            y <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>uniform(<span style=color:#099>0</span>, <span style=color:#099>20</span>)
</span></span><span style=display:flex><span>        <span style=color:#000;font-weight:700>elif</span> dim_to_sample <span style=color:#000;font-weight:700>==</span> <span style=color:#d14>&#39;theta&#39;</span>:
</span></span><span style=display:flex><span>            theta <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>uniform(<span style=color:#000;font-weight:700>-</span>np<span style=color:#000;font-weight:700>.</span>pi, np<span style=color:#000;font-weight:700>.</span>pi)
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>        pose_logpdf <span style=color:#000;font-weight:700>=</span> estimate_perception_logpdf(perception, x, y, theta)
</span></span><span style=display:flex><span>        k <span style=color:#000;font-weight:700>=</span> pose_logpdf <span style=color:#000;font-weight:700>-</span> current_logpdf
</span></span><span style=display:flex><span>        <span style=color:#000;font-weight:700>if</span> k <span style=color:#000;font-weight:700>&gt;=</span> <span style=color:#099>0.0</span> <span style=color:#000;font-weight:700>or</span> np<span style=color:#000;font-weight:700>.</span>log(np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>uniform()) <span style=color:#000;font-weight:700>&lt;</span> k:
</span></span><span style=display:flex><span>            <span style=color:#000;font-weight:700>return</span> (x, y, theta), pose_logpdf
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>return</span> (x, y, theta), pose_logpdf
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#998;font-style:italic># Define world points</span>
</span></span><span style=display:flex><span>map_points <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>array([[<span style=color:#099>10.</span>, <span style=color:#099>7.5</span>], [<span style=color:#099>7.5</span>, <span style=color:#099>10.</span>], [<span style=color:#099>10.</span>, <span style=color:#099>10.</span>], [<span style=color:#099>12.5</span>, <span style=color:#099>10.</span>], [<span style=color:#099>10.</span>, <span style=color:#099>12.5</span>]])
</span></span><span style=display:flex><span>tree <span style=color:#000;font-weight:700>=</span> KDTree(map_points)
</span></span><span style=display:flex><span><span style=color:#998;font-style:italic># Define robot perception of the world</span>
</span></span><span style=display:flex><span>perception <span style=color:#000;font-weight:700>=</span> [[<span style=color:#099>2.</span>, <span style=color:#099>0</span>], [<span style=color:#099>4.5</span>, <span style=color:#000;font-weight:700>-</span><span style=color:#099>2.5</span>], [<span style=color:#099>4.5</span>, <span style=color:#099>0.</span>], [<span style=color:#099>4.5</span>, <span style=color:#099>2.5</span>], [<span style=color:#099>7.</span>, <span style=color:#099>0</span>]]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>samples <span style=color:#000;font-weight:700>=</span> []
</span></span><span style=display:flex><span>current_pose <span style=color:#000;font-weight:700>=</span> (np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>uniform(<span style=color:#099>0</span>, <span style=color:#099>20</span>), np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>uniform(<span style=color:#099>0</span>, <span style=color:#099>20</span>), np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>uniform(<span style=color:#000;font-weight:700>-</span>np<span style=color:#000;font-weight:700>.</span>pi, np<span style=color:#000;font-weight:700>.</span>pi))
</span></span><span style=display:flex><span>pose_logpdf <span style=color:#000;font-weight:700>=</span> <span style=color:#000;font-weight:700>-</span>np<span style=color:#000;font-weight:700>.</span>inf
</span></span><span style=display:flex><span>np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>seed(<span style=color:#099>100</span>)
</span></span><span style=display:flex><span><span style=color:#998;font-style:italic># sample the robot poses using gibbs sampling procedure</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>for</span> i <span style=color:#000;font-weight:700>in</span> <span style=color:#0086b3>range</span>(<span style=color:#099>0</span>, <span style=color:#099>2000</span>):
</span></span><span style=display:flex><span>    current_pose, pose_logpdf <span style=color:#000;font-weight:700>=</span> gibbs_sample_step(perception, pose_logpdf, current_pose, <span style=color:#d14>&#39;x&#39;</span>)
</span></span><span style=display:flex><span>    samples<span style=color:#000;font-weight:700>.</span>append(current_pose)
</span></span><span style=display:flex><span>    current_pose, pose_logpdf <span style=color:#000;font-weight:700>=</span> gibbs_sample_step(perception, pose_logpdf, current_pose, <span style=color:#d14>&#39;y&#39;</span>)
</span></span><span style=display:flex><span>    samples<span style=color:#000;font-weight:700>.</span>append(current_pose)
</span></span><span style=display:flex><span>    current_pose, pose_logpdf <span style=color:#000;font-weight:700>=</span> gibbs_sample_step(perception, pose_logpdf, current_pose, <span style=color:#d14>&#39;theta&#39;</span>)
</span></span><span style=display:flex><span>    samples<span style=color:#000;font-weight:700>.</span>append(current_pose)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, ax <span style=color:#000;font-weight:700>=</span> plt<span style=color:#000;font-weight:700>.</span>subplots(<span style=color:#099>1</span>, <span style=color:#099>2</span>, figsize <span style=color:#000;font-weight:700>=</span> (<span style=color:#099>8</span>, <span style=color:#099>4</span>))
</span></span><span style=display:flex><span>samples <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>array(samples)
</span></span><span style=display:flex><span>ax[<span style=color:#099>0</span>]<span style=color:#000;font-weight:700>.</span>scatter(samples[:, <span style=color:#099>0</span>], samples[:, <span style=color:#099>1</span>], s<span style=color:#000;font-weight:700>=</span><span style=color:#099>1</span>, alpha <span style=color:#000;font-weight:700>=</span> <span style=color:#099>0.2</span>, c<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;tab:blue&#34;</span>, label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;Sampled poses&#34;</span>)
</span></span><span style=display:flex><span>ax[<span style=color:#099>0</span>]<span style=color:#000;font-weight:700>.</span>scatter(map_points[:, <span style=color:#099>0</span>], map_points[:, <span style=color:#099>1</span>], c<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;tab:orange&#39;</span>, label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;Map points&#34;</span>)
</span></span><span style=display:flex><span>ax[<span style=color:#099>0</span>]<span style=color:#000;font-weight:700>.</span>set(xlim<span style=color:#000;font-weight:700>=</span>(<span style=color:#099>0</span>, <span style=color:#099>20</span>), ylim<span style=color:#000;font-weight:700>=</span>(<span style=color:#099>0</span>, <span style=color:#099>20</span>), xlabel<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;x, m&#34;</span>, ylabel<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;y, m&#34;</span>)
</span></span><span style=display:flex><span>ax[<span style=color:#099>0</span>]<span style=color:#000;font-weight:700>.</span>legend()
</span></span><span style=display:flex><span>ax[<span style=color:#099>1</span>]<span style=color:#000;font-weight:700>.</span>scatter(np<span style=color:#000;font-weight:700>.</span>arange(<span style=color:#099>0</span>, <span style=color:#0086b3>len</span>(samples)), samples[:, <span style=color:#099>2</span>], s<span style=color:#000;font-weight:700>=</span><span style=color:#099>1</span>, alpha <span style=color:#000;font-weight:700>=</span> <span style=color:#099>0.1</span>, c<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;tab:blue&#34;</span>, label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;Sampled poses theta&#34;</span>)
</span></span><span style=display:flex><span>ax[<span style=color:#099>1</span>]<span style=color:#000;font-weight:700>.</span>set(xlabel<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;sample number&#34;</span>, ylabel<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;theta, radians&#34;</span>)
</span></span></code></pre></div></div></div><p><img src=./20240322233256.png alt=png></p><h3 id=option-2>Option 2
<a class=heading-link href=#option-2><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>Now let&rsquo;s assume that we want to draw a lot of samples. What we can do is to precalculate the likelihood on a grid and directly sample from our conditional distribution.</p><div class=spoiler><span class=spoilerText>Spoiler</span>
<input class=spoilerChecked type=checkbox showtext=Code><div class=spoilerContent><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000;font-weight:700>import</span> <span style=color:#555>numpy</span> <span style=color:#000;font-weight:700>as</span> <span style=color:#555>np</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>from</span> <span style=color:#555>scipy.spatial</span> <span style=color:#000;font-weight:700>import</span> KDTree
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>from</span> <span style=color:#555>scipy.stats</span> <span style=color:#000;font-weight:700>import</span> norm
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>import</span> <span style=color:#555>matplotlib.pyplot</span> <span style=color:#000;font-weight:700>as</span> <span style=color:#555>plt</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>norm_pdf</span>(x, mu, sigma):
</span></span><span style=display:flex><span>    <span style=color:#d14>&#34;&#34;&#34;Calculates normal pdf for sample x given parameters mu and sigma.&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    variance <span style=color:#000;font-weight:700>=</span> sigma<span style=color:#000;font-weight:700>**</span><span style=color:#099>2</span>
</span></span><span style=display:flex><span>    numerator <span style=color:#000;font-weight:700>=</span> x <span style=color:#000;font-weight:700>-</span> mu
</span></span><span style=display:flex><span>    denomenator <span style=color:#000;font-weight:700>=</span> <span style=color:#099>2</span><span style=color:#000;font-weight:700>*</span>variance
</span></span><span style=display:flex><span>    pdf <span style=color:#000;font-weight:700>=</span> ((<span style=color:#099>1</span><span style=color:#000;font-weight:700>/</span>(np<span style=color:#000;font-weight:700>.</span>sqrt(<span style=color:#099>2</span><span style=color:#000;font-weight:700>*</span>np<span style=color:#000;font-weight:700>.</span>pi)<span style=color:#000;font-weight:700>*</span>sigma))<span style=color:#000;font-weight:700>*</span>np<span style=color:#000;font-weight:700>.</span>exp(<span style=color:#000;font-weight:700>-</span>(numerator<span style=color:#000;font-weight:700>**</span><span style=color:#099>2</span>)<span style=color:#000;font-weight:700>/</span>denomenator))
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>return</span> pdf
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>transform_to_world</span>(perception, pose):
</span></span><span style=display:flex><span>    <span style=color:#d14>&#34;&#34;&#34;Resolves perception in world coordinate frame based on current pose.&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    x, y, theta <span style=color:#000;font-weight:700>=</span> pose
</span></span><span style=display:flex><span>    c, s <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>cos(theta), np<span style=color:#000;font-weight:700>.</span>sin(theta)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    perception_world <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>zeros_like(perception)
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>for</span> i, p <span style=color:#000;font-weight:700>in</span> <span style=color:#0086b3>enumerate</span>(perception):
</span></span><span style=display:flex><span>        perception_world[i, :] <span style=color:#000;font-weight:700>=</span> (p[<span style=color:#099>0</span>] <span style=color:#000;font-weight:700>*</span> c <span style=color:#000;font-weight:700>-</span> p[<span style=color:#099>1</span>] <span style=color:#000;font-weight:700>*</span> s <span style=color:#000;font-weight:700>+</span> x, p[<span style=color:#099>0</span>] <span style=color:#000;font-weight:700>*</span> s <span style=color:#000;font-weight:700>+</span> p[<span style=color:#099>1</span>] <span style=color:#000;font-weight:700>*</span> c <span style=color:#000;font-weight:700>+</span> y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>return</span> perception_world
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>estimate_perception_logpdf</span>(perception, x, y, theta, sigma<span style=color:#000;font-weight:700>=</span><span style=color:#099>1.</span>):
</span></span><span style=display:flex><span>    <span style=color:#d14>&#34;&#34;&#34;Calculates pdf of perception given the pose.&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    perception_world <span style=color:#000;font-weight:700>=</span> transform_to_world(perception, (x, y, theta))
</span></span><span style=display:flex><span>    distances, _ <span style=color:#000;font-weight:700>=</span> tree<span style=color:#000;font-weight:700>.</span>query(perception_world, k<span style=color:#000;font-weight:700>=</span><span style=color:#099>1</span>)
</span></span><span style=display:flex><span>    w <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>sum(np<span style=color:#000;font-weight:700>.</span>log(norm_pdf(distances, <span style=color:#099>0.</span>, sigma)))
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>return</span> w
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>normalized_weights</span>(taus):
</span></span><span style=display:flex><span>    <span style=color:#d14>&#34;&#34;&#34;Used to normalize and converts weights to normal scale&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    max_tau <span style=color:#000;font-weight:700>=</span> taus<span style=color:#000;font-weight:700>.</span>max()
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>return</span> np<span style=color:#000;font-weight:700>.</span>exp(taus <span style=color:#000;font-weight:700>-</span> max_tau <span style=color:#000;font-weight:700>-</span> np<span style=color:#000;font-weight:700>.</span>log(np<span style=color:#000;font-weight:700>.</span>sum(np<span style=color:#000;font-weight:700>.</span>exp(taus <span style=color:#000;font-weight:700>-</span> max_tau))))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>get_logpdf_on_a_grid</span>(perception):
</span></span><span style=display:flex><span>    <span style=color:#d14>&#34;&#34;&#34;Get PDF on a grid&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#998;font-style:italic># used to map x to idx on a grid</span>
</span></span><span style=display:flex><span>    x_to_idx <span style=color:#000;font-weight:700>=</span> {x:i <span style=color:#000;font-weight:700>for</span> i, x <span style=color:#000;font-weight:700>in</span> <span style=color:#0086b3>enumerate</span>(np<span style=color:#000;font-weight:700>.</span>arange(<span style=color:#099>0</span>, <span style=color:#099>20.</span>, <span style=color:#099>0.25</span>))}
</span></span><span style=display:flex><span>    y_to_idx <span style=color:#000;font-weight:700>=</span> {y:i <span style=color:#000;font-weight:700>for</span> i, y <span style=color:#000;font-weight:700>in</span> <span style=color:#0086b3>enumerate</span>(np<span style=color:#000;font-weight:700>.</span>arange(<span style=color:#099>0</span>, <span style=color:#099>20.</span>, <span style=color:#099>0.25</span>))}
</span></span><span style=display:flex><span>    theta_to_idx <span style=color:#000;font-weight:700>=</span> {theta:i <span style=color:#000;font-weight:700>for</span> i, theta <span style=color:#000;font-weight:700>in</span> <span style=color:#0086b3>enumerate</span>(np<span style=color:#000;font-weight:700>.</span>deg2rad(np<span style=color:#000;font-weight:700>.</span>linspace(<span style=color:#000;font-weight:700>-</span><span style=color:#099>180</span>, <span style=color:#099>180</span> <span style=color:#000;font-weight:700>-</span> <span style=color:#099>180</span><span style=color:#000;font-weight:700>/</span><span style=color:#099>4</span>, <span style=color:#099>8</span>)))}
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    logpdf_xytheta <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>zeros((<span style=color:#0086b3>len</span>(x_to_idx), <span style=color:#0086b3>len</span>(y_to_idx), <span style=color:#0086b3>len</span>(theta_to_idx)))
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>for</span> x <span style=color:#000;font-weight:700>in</span> x_to_idx<span style=color:#000;font-weight:700>.</span>keys():
</span></span><span style=display:flex><span>        <span style=color:#000;font-weight:700>for</span> y <span style=color:#000;font-weight:700>in</span> y_to_idx<span style=color:#000;font-weight:700>.</span>keys():
</span></span><span style=display:flex><span>            <span style=color:#000;font-weight:700>for</span> theta <span style=color:#000;font-weight:700>in</span> theta_to_idx<span style=color:#000;font-weight:700>.</span>keys():
</span></span><span style=display:flex><span>                logpdf_xytheta[x_to_idx[x], y_to_idx[y], theta_to_idx[theta]] <span style=color:#000;font-weight:700>=</span> estimate_perception_logpdf(perception, x, y, theta)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>return</span> logpdf_xytheta, x_to_idx, y_to_idx, theta_to_idx
</span></span><span style=display:flex><span>                
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>sample_from_conditional_logpdf</span>(conditional_logpdf, values_to_sample_from):
</span></span><span style=display:flex><span>    <span style=color:#998;font-style:italic># first sample the bin given bin weights</span>
</span></span><span style=display:flex><span>    bin_center <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>choice(values_to_sample_from, size<span style=color:#000;font-weight:700>=</span><span style=color:#099>1</span>, p<span style=color:#000;font-weight:700>=</span>normalized_weights(conditional_logpdf))[<span style=color:#099>0</span>]
</span></span><span style=display:flex><span>    <span style=color:#998;font-style:italic># then sample actual value inside bin</span>
</span></span><span style=display:flex><span>    bin_width <span style=color:#000;font-weight:700>=</span> values_to_sample_from[<span style=color:#099>1</span>] <span style=color:#000;font-weight:700>-</span> values_to_sample_from[<span style=color:#099>0</span>]
</span></span><span style=display:flex><span>    sample <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>uniform(bin_center <span style=color:#000;font-weight:700>-</span> bin_width<span style=color:#000;font-weight:700>/</span><span style=color:#099>2</span>, bin_center <span style=color:#000;font-weight:700>+</span> bin_width<span style=color:#000;font-weight:700>/</span><span style=color:#099>2</span>)
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>return</span> sample
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#998;font-style:italic># Define world points</span>
</span></span><span style=display:flex><span>map_points <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>array([[<span style=color:#099>10.</span>, <span style=color:#099>7.5</span>], [<span style=color:#099>7.5</span>, <span style=color:#099>10.</span>], [<span style=color:#099>10.</span>, <span style=color:#099>10.</span>], [<span style=color:#099>12.5</span>, <span style=color:#099>10.</span>], [<span style=color:#099>10.</span>, <span style=color:#099>12.5</span>]])
</span></span><span style=display:flex><span>tree <span style=color:#000;font-weight:700>=</span> KDTree(map_points)
</span></span><span style=display:flex><span><span style=color:#998;font-style:italic># Define robot perception of the world</span>
</span></span><span style=display:flex><span>perception <span style=color:#000;font-weight:700>=</span> [[<span style=color:#099>2.</span>, <span style=color:#099>0</span>], [<span style=color:#099>4.5</span>, <span style=color:#000;font-weight:700>-</span><span style=color:#099>2.5</span>], [<span style=color:#099>4.5</span>, <span style=color:#099>0.</span>], [<span style=color:#099>4.5</span>, <span style=color:#099>2.5</span>], [<span style=color:#099>7.</span>, <span style=color:#099>0</span>]]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>logpdf_xytheta, x_to_idx, y_to_idx, theta_to_idx <span style=color:#000;font-weight:700>=</span> get_logpdf_on_a_grid(perception)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>current_pose <span style=color:#000;font-weight:700>=</span> (np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>uniform(<span style=color:#099>0</span>, <span style=color:#099>20</span>), np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>uniform(<span style=color:#099>0</span>, <span style=color:#099>20</span>), np<span style=color:#000;font-weight:700>.</span>random<span style=color:#000;font-weight:700>.</span>uniform(<span style=color:#000;font-weight:700>-</span>np<span style=color:#000;font-weight:700>.</span>pi, np<span style=color:#000;font-weight:700>.</span>pi))
</span></span><span style=display:flex><span>samples <span style=color:#000;font-weight:700>=</span> [current_pose]
</span></span><span style=display:flex><span>xx, yy, tt <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>array(<span style=color:#0086b3>list</span>(x_to_idx<span style=color:#000;font-weight:700>.</span>keys())), np<span style=color:#000;font-weight:700>.</span>array(<span style=color:#0086b3>list</span>(y_to_idx<span style=color:#000;font-weight:700>.</span>keys())), np<span style=color:#000;font-weight:700>.</span>array(<span style=color:#0086b3>list</span>(theta_to_idx<span style=color:#000;font-weight:700>.</span>keys()))
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>for</span> i <span style=color:#000;font-weight:700>in</span> <span style=color:#0086b3>range</span>(<span style=color:#099>0</span>, <span style=color:#099>10000</span>):
</span></span><span style=display:flex><span>    x, y, theta <span style=color:#000;font-weight:700>=</span> samples[<span style=color:#000;font-weight:700>-</span><span style=color:#099>1</span>]
</span></span><span style=display:flex><span>    <span style=color:#998;font-style:italic># find the conditional pdf row, column given current y coordinate and theta angle</span>
</span></span><span style=display:flex><span>    y_idx, theta_idx <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>abs(yy <span style=color:#000;font-weight:700>-</span> y)<span style=color:#000;font-weight:700>.</span>argmin(), np<span style=color:#000;font-weight:700>.</span>abs(tt <span style=color:#000;font-weight:700>-</span> theta)<span style=color:#000;font-weight:700>.</span>argmin()
</span></span><span style=display:flex><span>    <span style=color:#998;font-style:italic># sample from logpdf_x_given_ytheta</span>
</span></span><span style=display:flex><span>    sampled_x <span style=color:#000;font-weight:700>=</span> sample_from_conditional_logpdf(logpdf_xytheta[:, y_idx, theta_idx], xx)
</span></span><span style=display:flex><span>    samples<span style=color:#000;font-weight:700>.</span>append((sampled_x, y, theta))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    x, y, theta <span style=color:#000;font-weight:700>=</span> samples[<span style=color:#000;font-weight:700>-</span><span style=color:#099>1</span>]
</span></span><span style=display:flex><span>    <span style=color:#998;font-style:italic># find the conditional pdf row, column given current x coordinate and theta angle</span>
</span></span><span style=display:flex><span>    x_idx, theta_idx <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>abs(xx <span style=color:#000;font-weight:700>-</span> x)<span style=color:#000;font-weight:700>.</span>argmin(), np<span style=color:#000;font-weight:700>.</span>abs(tt <span style=color:#000;font-weight:700>-</span> theta)<span style=color:#000;font-weight:700>.</span>argmin()
</span></span><span style=display:flex><span>    <span style=color:#998;font-style:italic># sample from logpdf_y_given_xtheta</span>
</span></span><span style=display:flex><span>    sampled_y <span style=color:#000;font-weight:700>=</span> sample_from_conditional_logpdf(logpdf_xytheta[x_idx, :, theta_idx], yy)
</span></span><span style=display:flex><span>    samples<span style=color:#000;font-weight:700>.</span>append((x, sampled_y, theta))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    x, y, theta <span style=color:#000;font-weight:700>=</span> samples[<span style=color:#000;font-weight:700>-</span><span style=color:#099>1</span>]
</span></span><span style=display:flex><span>    <span style=color:#998;font-style:italic># find the conditional pdf row, column given current x and y coordinates</span>
</span></span><span style=display:flex><span>    x_idx, y_idx <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>abs(xx <span style=color:#000;font-weight:700>-</span> x)<span style=color:#000;font-weight:700>.</span>argmin(), np<span style=color:#000;font-weight:700>.</span>abs(yy <span style=color:#000;font-weight:700>-</span> y)<span style=color:#000;font-weight:700>.</span>argmin()
</span></span><span style=display:flex><span>    <span style=color:#998;font-style:italic># sample from logpdf_theta_given_xy</span>
</span></span><span style=display:flex><span>    sampled_theta <span style=color:#000;font-weight:700>=</span> sample_from_conditional_logpdf(logpdf_xytheta[x_idx, y_idx, :], tt)
</span></span><span style=display:flex><span>    samples<span style=color:#000;font-weight:700>.</span>append((x, y, sampled_theta))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, ax <span style=color:#000;font-weight:700>=</span> plt<span style=color:#000;font-weight:700>.</span>subplots(<span style=color:#099>1</span>, <span style=color:#099>2</span>, figsize <span style=color:#000;font-weight:700>=</span> (<span style=color:#099>8</span>, <span style=color:#099>4</span>))
</span></span><span style=display:flex><span>samples <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>array(samples)
</span></span><span style=display:flex><span>ax[<span style=color:#099>0</span>]<span style=color:#000;font-weight:700>.</span>scatter(samples[:, <span style=color:#099>0</span>], samples[:, <span style=color:#099>1</span>], s<span style=color:#000;font-weight:700>=</span><span style=color:#099>1</span>, alpha <span style=color:#000;font-weight:700>=</span> <span style=color:#099>0.2</span>, c<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;tab:blue&#34;</span>, label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;Sampled poses&#34;</span>)
</span></span><span style=display:flex><span>ax[<span style=color:#099>0</span>]<span style=color:#000;font-weight:700>.</span>scatter(map_points[:, <span style=color:#099>0</span>], map_points[:, <span style=color:#099>1</span>], c<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;tab:orange&#39;</span>, label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;Map points&#34;</span>)
</span></span><span style=display:flex><span>ax[<span style=color:#099>0</span>]<span style=color:#000;font-weight:700>.</span>set(xlim<span style=color:#000;font-weight:700>=</span>(<span style=color:#099>0</span>, <span style=color:#099>20</span>), ylim<span style=color:#000;font-weight:700>=</span>(<span style=color:#099>0</span>, <span style=color:#099>20</span>), xlabel<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;x, m&#34;</span>, ylabel<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;y, m&#34;</span>)
</span></span><span style=display:flex><span>ax[<span style=color:#099>0</span>]<span style=color:#000;font-weight:700>.</span>legend()
</span></span><span style=display:flex><span>ax[<span style=color:#099>1</span>]<span style=color:#000;font-weight:700>.</span>scatter(np<span style=color:#000;font-weight:700>.</span>arange(<span style=color:#099>0</span>, <span style=color:#0086b3>len</span>(samples)), samples[:, <span style=color:#099>2</span>], s<span style=color:#000;font-weight:700>=</span><span style=color:#099>1</span>, alpha <span style=color:#000;font-weight:700>=</span> <span style=color:#099>0.1</span>, c<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;tab:blue&#34;</span>, label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;Sampled poses theta&#34;</span>)
</span></span><span style=display:flex><span>ax[<span style=color:#099>1</span>]<span style=color:#000;font-weight:700>.</span>set(xlabel<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;sample number&#34;</span>, ylabel<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;theta, radians&#34;</span>)
</span></span></code></pre></div></div></div><p><img src=./20240324204042.png alt=png></p><h2 id=references>References
<a class=heading-link href=#references><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>[1]: <a href=https://www.bishopbook.com/ class=external-link target=_blank rel=noopener>https://www.bishopbook.com/</a>, Ch. 14.</p></div><footer><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//mikoff-github-io.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}(),document.addEventListener("themeChanged",function(){document.readyState=="complete"&&DISQUS.reset({reload:!0,config:disqus_config})})</script></footer></article><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0 crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})'></script></section></div><footer class=footer><section class=container>©
2024
Aleksandr Mikoff
·
Powered by <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/ target=_blank rel=noopener>Coder</a>.</section></footer></main><script src=/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script></body></html>