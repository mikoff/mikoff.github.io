<!doctype html><html lang=en><head><title>Inverse transform sampling · Aleksandr Mikoff's blog
</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Aleksandr Mikoff"><meta name=description content="Probability density and cumulative distribution functions Link to heading Probability density function $f(x)$ is a function, which allows us to evaluate the probability that the sample, drawn from the distribution, will be equal to the value $X$. Also we can use PDF to calculate the probability that the randomly drawn sample from distribution will be in certain range, for example, $a \leq X \leq b$. This probability equals to the area under the PDF curve on the given interval and can be calculated by integration: $$ P(a \leq X \leq b) = \int _a^b f(x) dx $$ Cumulative distribution function shows us the probability (portion of data, frequence) to draw a number $X$ less or equal than $x$: $$ P(X \leq x) = F(x)."><meta name=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="Inverse transform sampling"><meta name=twitter:description content="Probability density and cumulative distribution functions Link to heading Probability density function $f(x)$ is a function, which allows us to evaluate the probability that the sample, drawn from the distribution, will be equal to the value $X$. Also we can use PDF to calculate the probability that the randomly drawn sample from distribution will be in certain range, for example, $a \leq X \leq b$. This probability equals to the area under the PDF curve on the given interval and can be calculated by integration: $$ P(a \leq X \leq b) = \int _a^b f(x) dx $$ Cumulative distribution function shows us the probability (portion of data, frequence) to draw a number $X$ less or equal than $x$: $$ P(X \leq x) = F(x)."><meta property="og:title" content="Inverse transform sampling"><meta property="og:description" content="Probability density and cumulative distribution functions Link to heading Probability density function $f(x)$ is a function, which allows us to evaluate the probability that the sample, drawn from the distribution, will be equal to the value $X$. Also we can use PDF to calculate the probability that the randomly drawn sample from distribution will be in certain range, for example, $a \leq X \leq b$. This probability equals to the area under the PDF curve on the given interval and can be calculated by integration: $$ P(a \leq X \leq b) = \int _a^b f(x) dx $$ Cumulative distribution function shows us the probability (portion of data, frequence) to draw a number $X$ less or equal than $x$: $$ P(X \leq x) = F(x)."><meta property="og:type" content="article"><meta property="og:url" content="https://mikoff.github.io/posts/inverse-transform-sampling.md/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-02-09T14:56:13+03:00"><meta property="article:modified_time" content="2020-02-09T14:56:13+03:00"><link rel=canonical href=https://mikoff.github.io/posts/inverse-transform-sampling.md/><link rel=preload href=/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.577e3c5ead537873430da16f0964b754a120fd87c4e2203a00686e7c75b51378.css integrity="sha256-V348Xq1TeHNDDaFvCWS3VKEg/YfE4iA6AGhufHW1E3g=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/image.min.c1a5dfc6bac0eb1b85bcd8abf8aba0d18e0bf02fc972f9a0b17d2962f5ca8dd5.css integrity="sha256-waXfxrrA6xuFvNir+Kug0Y4L8C/JcvmgsX0pYvXKjdU=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/spoiler.min.bf901294afff95f520a8150a4df4249576eb9c49c4f40f5f9c2de750588dd594.css integrity="sha256-v5ASlK//lfUgqBUKTfQklXbrnEnE9A9fnC3nUFiN1ZQ=" crossorigin=anonymous media=screen><link rel=stylesheet href=/plugins/academic-icons/css/academicons.min.f6abb61f6b9b2e784eba22dfb93cd399ce30ee01825791830a2737d6bfcd2be9.css integrity="sha256-9qu2H2ubLnhOuiLfuTzTmc4w7gGCV5GDCic31r/NK+k=" crossorigin=anonymous media=screen><link rel=icon type=image/svg+xml href=/images/favicon.svg sizes=any><link rel=icon type=image/png href=/img/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/img/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://mikoff.github.io/>Aleksandr Mikoff's blog
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa-solid fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/about/>About</a></li><li class=navigation-item><a class=navigation-link href=/posts/>Posts</a></li><li class=navigation-item><a class=navigation-link href=/tags>Tags</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://mikoff.github.io/posts/inverse-transform-sampling.md/>Inverse transform sampling</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa-solid fa-calendar" aria-hidden=true></i>
<time datetime=2020-02-09T14:56:13+03:00>February 9, 2020
</time></span><span class=reading-time><i class="fa-solid fa-clock" aria-hidden=true></i>
10-minute read</span></div><div class=tags><i class="fa-solid fa-tag" aria-hidden=true></i>
<span class=tag><a href=/tags/sampling/>Sampling</a>
</span><span class=separator>•</span>
<span class=tag><a href=/tags/statistics/>Statistics</a></span></div></div></header><div class=post-content><h1 id=probability-density-and-cumulative-distribution-functions>Probability density and cumulative distribution functions
<a class=heading-link href=#probability-density-and-cumulative-distribution-functions><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><p>Probability density function $f(x)$ is a function, which allows us to evaluate the probability that the sample, drawn from the distribution, will be equal to the value $X$.
Also we can use PDF to calculate the probability that the randomly drawn sample from distribution will be in certain range, for example, $a \leq X \leq b$. This probability equals to the area under the PDF curve on the given interval and can be calculated by integration:</p>$$
P(a \leq X \leq b) = \int _a^b f(x) dx
$$<p>Cumulative distribution function shows us the probability (portion of data, frequence) to draw a number $X$ less or equal than $x$:</p>$$
P(X \leq x) = F(x).
$$<p>It is obvious, that the probability that value lies in semi-closed interval $[a, b)$ can be represented as:</p>$$
P(a \leq X \leq b) = F(b) - F(a)
$$<p>Let&rsquo;s experiment with normal distribution, its PDF has the following form:</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>x, pi, sigma, mu = sp.symbols(<span style=color:#0ff;font-weight:700>&#39;x, pi, sigma, mu&#39;</span>, positive = <span style=color:#fff;font-weight:700>True</span>)
</span></span><span style=display:flex><span>pdf = ((<span style=color:#ff0;font-weight:700>2.0</span> * sp.pi) ** sp.Rational(-<span style=color:#ff0;font-weight:700>1</span>, <span style=color:#ff0;font-weight:700>2</span>) / sigma) * sp.exp(-<span style=color:#ff0;font-weight:700>0.5</span> * ((x - mu)/sigma) ** <span style=color:#ff0;font-weight:700>2</span>)
</span></span><span style=display:flex><span>display(pdf)
</span></span></code></pre></div><p>$\displaystyle \frac{0.707106781186548 e^{- \frac{0.5 \left(- \mu + x\right)^{2}}{\sigma^{2}}}}{\sqrt{\pi} \sigma}$</p><p>Its CDF can be found by integration:</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>cdf = sp.simplify(sp.integrate(pdf, x)) + <span style=color:#ff0;font-weight:700>0.5</span>
</span></span><span style=display:flex><span>display(cdf)
</span></span></code></pre></div><p>$\displaystyle 0.5 - 0.5 \operatorname{erf}{\left(\frac{0.707106781186548 \left(\mu - x\right)}{\sigma} \right)}$</p><p>To get 3-sigma 68-95-99.7 rule, which tells us that 68%-95%-99.7% of data lies within one-two-three standard deviation of the mean, we can just integrate the pdf on the following intervals: $[\mu - n\sigma, \mu + n\sigma]$, where $n = {1, 2, 3}$:</p><p>Data portion within $\mu \pm \sigma$ interval:</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>display(<span style=color:#fff;font-weight:700>float</span>(sp.integrate(pdf, (x, mu-sigma, mu+sigma))))
</span></span></code></pre></div><p>$\displaystyle 0.682689492137086$</p><p>Data portion within $\mu \pm 2\sigma$ interval:</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>display(cdf.subs({x: mu + <span style=color:#ff0;font-weight:700>2</span> * sigma}) - cdf.subs({x: mu - <span style=color:#ff0;font-weight:700>2</span> * sigma}))
</span></span></code></pre></div><p>$\displaystyle 0.954499736103642$</p><p>Data portion within $\mu \pm 3\sigma$ interval:</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>display(cdf.subs({x: mu + <span style=color:#ff0;font-weight:700>3</span> * sigma}) - cdf.subs({x: mu - <span style=color:#ff0;font-weight:700>3</span> * sigma}))
</span></span></code></pre></div><p>$\displaystyle 0.99730020393674$</p><p>And now let&rsquo;s visualize it as the area under gaussian PDF within given ranges:</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>gaussian_pdf = sp.lambdify((x, mu, sigma), pdf)
</span></span><span style=display:flex><span>gaussian_cdf = sp.lambdify((x, mu, sigma), cdf)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Mu, Sigma = <span style=color:#ff0;font-weight:700>4.0</span>, <span style=color:#ff0;font-weight:700>1.0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, ax = plt.subplots(<span style=color:#ff0;font-weight:700>1</span>, <span style=color:#ff0;font-weight:700>1</span>, figsize=(<span style=color:#ff0;font-weight:700>8</span>, <span style=color:#ff0;font-weight:700>4</span>))
</span></span><span style=display:flex><span>spanFrom, spanTo = Mu - <span style=color:#ff0;font-weight:700>4</span> * Sigma, Mu + <span style=color:#ff0;font-weight:700>4</span> * Sigma
</span></span><span style=display:flex><span>span = np.linspace(spanFrom, spanTo, <span style=color:#ff0;font-weight:700>100</span>)
</span></span><span style=display:flex><span>ax.plot(span, gaussian_pdf(span, Mu, Sigma), label=<span style=color:#0ff;font-weight:700>&#39;pdf&#39;</span>)
</span></span><span style=display:flex><span>ax.set(xlabel=<span style=color:#0ff;font-weight:700>&#39;$x$&#39;</span>, ylabel=<span style=color:#0ff;font-weight:700>&#39;$p = f(x)$&#39;</span>, title=<span style=color:#0ff;font-weight:700>&#39;$X \sim \mathcal</span><span style=color:#0ff;font-weight:700>{N}</span><span style=color:#0ff;font-weight:700> (&#39;</span> + <span style=color:#fff;font-weight:700>str</span>(Mu) + <span style=color:#0ff;font-weight:700>&#34;, &#34;</span> + <span style=color:#fff;font-weight:700>str</span>(Sigma**<span style=color:#ff0;font-weight:700>2</span>) + <span style=color:#0ff;font-weight:700>&#34;)$&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#fff;font-weight:700>for</span> i in <span style=color:#fff;font-weight:700>range</span>(-<span style=color:#ff0;font-weight:700>3</span>, <span style=color:#ff0;font-weight:700>3</span>):
</span></span><span style=display:flex><span>    spanStart, spanEnd = Mu + i * Sigma, Mu + (i + <span style=color:#ff0;font-weight:700>1</span>) * Sigma
</span></span><span style=display:flex><span>    span = np.linspace(spanStart, spanEnd, <span style=color:#ff0;font-weight:700>100</span>)
</span></span><span style=display:flex><span>    ax.fill_between(span, gaussian_pdf(span, Mu, Sigma), interpolate=<span style=color:#fff;font-weight:700>True</span>, alpha=<span style=color:#ff0;font-weight:700>0.5</span>)
</span></span><span style=display:flex><span>    ax.annotate(<span style=color:#fff;font-weight:700>str</span>(np.round_(<span style=color:#ff0;font-weight:700>100</span> * (gaussian_cdf(spanEnd, Mu, Sigma) - gaussian_cdf(spanStart, Mu, Sigma)), <span style=color:#ff0;font-weight:700>1</span>)) + <span style=color:#0ff;font-weight:700>&#39;%&#39;</span>, 
</span></span><span style=display:flex><span>                xy=((spanStart + spanEnd) * <span style=color:#ff0;font-weight:700>0.5</span>, <span style=color:#ff0;font-weight:700>0.025</span>), ha=<span style=color:#0ff;font-weight:700>&#39;center&#39;</span>)
</span></span></code></pre></div><p><img src=./index_15_0.png alt=png></p><p>Let&rsquo;s find Gaussian distribution mean, or first moment, which, by definition equals to $\int_{-\infty}^\infty x f(x) dx$:</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>mean = sp.integrate(pdf * x, (x, -sp.oo, sp.oo))
</span></span><span style=display:flex><span>display(mean)
</span></span></code></pre></div><p>$\displaystyle 1.0 \mu$</p><p>The variance can be found using second moment and mean, $Var(X) = \mathbb E[X^2] - \mathbb E [X]^2$</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>variance = sp.integrate(pdf * x * x, (x, -sp.oo, sp.oo)) - mean**<span style=color:#ff0;font-weight:700>2</span>
</span></span><span style=display:flex><span>display(variance)
</span></span></code></pre></div><p>$\displaystyle 1.0 \sigma^{2}$</p><p>And verify that the area under the curve, or total probability should be equal to 1.0:</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>area = sp.integrate(pdf, (x, -sp.oo, sp.oo))
</span></span><span style=display:flex><span>display(area)
</span></span></code></pre></div><p>$\displaystyle 1.0$</p><h1 id=inverse-cdf>Inverse CDF
<a class=heading-link href=#inverse-cdf><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><p>The inverse of CDF is called quantile function. If $F(x) = P(X \leq x) = p$ tells us the probability to draw a number less or equal than the value $x$ from distribution then $F^{-1}(p)$ tells us vise versa: what is the value of $x$, such that $F(X\leq x) = p$.
For example, $F^{-1}(0.5)$ is the median of the distribution, $F^{-1}(0.25)$ is the lower quartile.
In other words, it answer on the following question: what is the proportion of data, which is less or equal to the given value $x$.</p><p>Inverse CDF for gaussian distribution has the following form:</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>p = sp.symbols(<span style=color:#0ff;font-weight:700>&#39;p&#39;</span>)
</span></span><span style=display:flex><span>inverse_cdf = sp.solve(cdf - p, x)[<span style=color:#ff0;font-weight:700>0</span>]
</span></span><span style=display:flex><span>display(inverse_cdf)
</span></span></code></pre></div><p>$\displaystyle \mu - 1.41421356237309 \sigma \operatorname{erfinv}{\left(1.0 - 2.0 p \right)}$</p><p>Now wish we would like to answer on the following questions: what is the value $x$ for which the half of the data is less than it?</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>display(inverse_cdf.subs({p:<span style=color:#ff0;font-weight:700>0.5</span>}))
</span></span></code></pre></div><p>$\displaystyle \mu$</p><p>This makes sense: we know, that for gaussian its mean is equal to $mu$ and the half of the data should be less than this value.</p><p>The following plot helps to understand an idea:</p><ul><li>CDF maps $x$ value to the portion of data, which is less or equal than $x$</li><li>Inverse of CDF gives an answer on the following question: for given $p$ what is the value $x$, for which $P(X \leq x) = p$ satisfies?</li></ul><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>Mu, Sigma = <span style=color:#ff0;font-weight:700>4.0</span>, <span style=color:#ff0;font-weight:700>1.0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>spanFrom, spanTo = Mu - <span style=color:#ff0;font-weight:700>4</span> * Sigma, Mu + <span style=color:#ff0;font-weight:700>4</span> * Sigma
</span></span><span style=display:flex><span>span = np.linspace(spanFrom, spanTo, <span style=color:#ff0;font-weight:700>100</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, ax = plt.subplots(<span style=color:#ff0;font-weight:700>1</span>, <span style=color:#ff0;font-weight:700>1</span>, figsize=(<span style=color:#ff0;font-weight:700>8</span>, <span style=color:#ff0;font-weight:700>4</span>))
</span></span><span style=display:flex><span>ax.plot(span, gaussian_cdf(span, Mu, Sigma), label=<span style=color:#0ff;font-weight:700>&#39;cdf&#39;</span>)
</span></span><span style=display:flex><span>ax.set(xlabel=<span style=color:#0ff;font-weight:700>&#39;$x = F^{-1}(p)$&#39;</span>, ylabel=<span style=color:#0ff;font-weight:700>&#39;$p = F(x)$&#39;</span>, title=<span style=color:#0ff;font-weight:700>&#39;Cumulative distribution function&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cdf_value = <span style=color:#fff;font-weight:700>float</span>(sp.integrate(pdf, (x, -sp.oo, mu)))
</span></span><span style=display:flex><span>X, Y = [Mu, Mu, spanFrom], [<span style=color:#ff0;font-weight:700>0.0</span>, cdf_value, cdf_value]
</span></span><span style=display:flex><span>ax.quiver(X[:-<span style=color:#ff0;font-weight:700>1</span>], Y[:-<span style=color:#ff0;font-weight:700>1</span>], np.diff(X), np.diff(Y), angles=<span style=color:#0ff;font-weight:700>&#39;xy&#39;</span>, scale_units=<span style=color:#0ff;font-weight:700>&#39;xy&#39;</span>, scale=<span style=color:#ff0;font-weight:700>1</span>, width=<span style=color:#ff0;font-weight:700>0.005</span>, color=<span style=color:#0ff;font-weight:700>&#39;C1&#39;</span>, label=<span style=color:#0ff;font-weight:700>&#39;CDF&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cdf_value = <span style=color:#fff;font-weight:700>float</span>(sp.integrate(pdf, (x, -sp.oo, mu-sigma)))
</span></span><span style=display:flex><span>X, Y = [spanFrom, Mu - Sigma, Mu-Sigma], [cdf_value, cdf_value, <span style=color:#ff0;font-weight:700>0.0</span>]
</span></span><span style=display:flex><span>ax.quiver(X[:-<span style=color:#ff0;font-weight:700>1</span>], Y[:-<span style=color:#ff0;font-weight:700>1</span>], np.diff(X), np.diff(Y), angles=<span style=color:#0ff;font-weight:700>&#39;xy&#39;</span>, scale_units=<span style=color:#0ff;font-weight:700>&#39;xy&#39;</span>, scale=<span style=color:#ff0;font-weight:700>1</span>, width=<span style=color:#ff0;font-weight:700>0.005</span>, color=<span style=color:#0ff;font-weight:700>&#39;C7&#39;</span>, label=<span style=color:#0ff;font-weight:700>&#39;inverse CDF&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax.xaxis.set_major_locator(plticker.MultipleLocator(base=<span style=color:#ff0;font-weight:700>1.0</span>))
</span></span><span style=display:flex><span>ax.yaxis.set_major_locator(plticker.MultipleLocator(base=<span style=color:#ff0;font-weight:700>0.1</span>))
</span></span><span style=display:flex><span>ax.legend(loc=<span style=color:#0ff;font-weight:700>&#39;lower right&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax.set_xlim(spanFrom, spanTo)
</span></span><span style=display:flex><span>ax.set_ylim(<span style=color:#ff0;font-weight:700>0.0</span>, <span style=color:#ff0;font-weight:700>1.0</span>)
</span></span></code></pre></div><p>$\displaystyle \left( 0.0, \ 1.0\right)$</p><p><img src=./index_30_1.png alt=png></p><h1 id=inverse-transform-sampling>Inverse transform sampling
<a class=heading-link href=#inverse-transform-sampling><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><p>Now, having this function, which maps $p$ to $x$ it should be obvious how to sample from our desired distribution having the samples from the uniform one.</p><p>Let&rsquo;s illustrate the idea with the set of uniformly distributed points along $p$ and map all of them to $x$ using inverse CDF. It&rsquo;s clearly seen then after applying this transformation the points are not evenly spaced anymore.</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>gaussian_inverse_cdf = sp.lambdify((p, mu, sigma), inverse_cdf)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Mu, Sigma = <span style=color:#ff0;font-weight:700>3.0</span>, <span style=color:#ff0;font-weight:700>2.0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>spanFrom, spanTo = Mu - <span style=color:#ff0;font-weight:700>4</span> * Sigma, Mu + <span style=color:#ff0;font-weight:700>4</span> * Sigma
</span></span><span style=display:flex><span>span = np.linspace(spanFrom, spanTo, <span style=color:#ff0;font-weight:700>100</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, ax = plt.subplots(<span style=color:#ff0;font-weight:700>1</span>, <span style=color:#ff0;font-weight:700>1</span>, figsize=(<span style=color:#ff0;font-weight:700>8</span>, <span style=color:#ff0;font-weight:700>4</span>))
</span></span><span style=display:flex><span>ax.plot(span, gaussian_cdf(span, Mu, Sigma), label=<span style=color:#0ff;font-weight:700>&#39;cdf&#39;</span>)
</span></span><span style=display:flex><span>ax.set(xlabel=<span style=color:#0ff;font-weight:700>&#39;$x = F^{-1}(p)$, sample space&#39;</span>, ylabel=<span style=color:#0ff;font-weight:700>&#39;$p = F(x)$, uniform values&#39;</span>)
</span></span><span style=display:flex><span>uniform_samples = np.linspace(<span style=color:#ff0;font-weight:700>0.01</span>, <span style=color:#ff0;font-weight:700>0.99</span>, <span style=color:#ff0;font-weight:700>21</span>)
</span></span><span style=display:flex><span><span style=color:#fff;font-weight:700>for</span> sample in uniform_samples:
</span></span><span style=display:flex><span>    cdfValue = gaussian_inverse_cdf(sample, Mu, Sigma)
</span></span><span style=display:flex><span>    X, Y = [spanFrom, cdfValue, cdfValue], [sample, sample, <span style=color:#ff0;font-weight:700>0.0</span>]
</span></span><span style=display:flex><span>    ax.quiver(X[:-<span style=color:#ff0;font-weight:700>1</span>], Y[:-<span style=color:#ff0;font-weight:700>1</span>], np.diff(X), np.diff(Y), angles=<span style=color:#0ff;font-weight:700>&#39;xy&#39;</span>, scale_units=<span style=color:#0ff;font-weight:700>&#39;xy&#39;</span>, scale=<span style=color:#ff0;font-weight:700>1</span>, width=<span style=color:#ff0;font-weight:700>0.001</span>, color=<span style=color:#0ff;font-weight:700>&#39;C7&#39;</span>, label=<span style=color:#0ff;font-weight:700>&#39;inverse CDF&#39;</span>,
</span></span><span style=display:flex><span>                headlength=<span style=color:#ff0;font-weight:700>30.0</span>, headwidth=<span style=color:#ff0;font-weight:700>20.0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax.scatter(gaussian_inverse_cdf(uniform_samples, Mu, Sigma), [<span style=color:#ff0;font-weight:700>0</span>] * <span style=color:#fff;font-weight:700>len</span>(uniform_samples), alpha=<span style=color:#ff0;font-weight:700>0.3</span>, c = <span style=color:#0ff;font-weight:700>&#39;C2&#39;</span>)
</span></span><span style=display:flex><span>ax.scatter([Mu - <span style=color:#ff0;font-weight:700>3</span> * Sigma] * <span style=color:#fff;font-weight:700>len</span>(uniform_samples), uniform_samples, alpha=<span style=color:#ff0;font-weight:700>0.3</span>, c = <span style=color:#0ff;font-weight:700>&#39;C1&#39;</span>)
</span></span><span style=display:flex><span>ax.set_xlim(Mu - <span style=color:#ff0;font-weight:700>3</span> * Sigma, Mu + <span style=color:#ff0;font-weight:700>3</span> * Sigma)
</span></span><span style=display:flex><span>ax.set_ylim(<span style=color:#ff0;font-weight:700>0.0</span>, <span style=color:#ff0;font-weight:700>1.0</span>)
</span></span><span style=display:flex><span>ax.xaxis.set_major_locator(plticker.MultipleLocator(base=<span style=color:#ff0;font-weight:700>1.0</span>))
</span></span></code></pre></div><p><img src=./index_33_0.png alt=png></p><p>Now, thanks to CDF, we have one-to-one correspondance between uniformly sampled numbers $p$ (because for uniform distribution every sample is equally probable) and $x$, which maps $p$ to the value $x$ from our desired distribution. To have this one-to-one correspondance, CDF should be monotonically increasing.</p><p>To experimentally verify that everythink works as expected we can randomly draw uniformly distributed numbers and map them to our desired distribution.</p><h2 id=inverse-transform-sampling-for-normal-distribution>Inverse transform sampling for Normal distribution
<a class=heading-link href=#inverse-transform-sampling-for-normal-distribution><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>As a first experiment, we will proceed with inverse of Gaussian CDF. To do so we sample from Uniform distribution and transform them to the Gaussian one.</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#fff;font-weight:700>import</span> seaborn <span style=color:#fff;font-weight:700>as</span> sns
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Mu, Sigma = <span style=color:#ff0;font-weight:700>5</span>, <span style=color:#ff0;font-weight:700>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>uniform_samples = np.random.uniform(size=<span style=color:#ff0;font-weight:700>5000</span>)
</span></span><span style=display:flex><span>gaussian_samples = gaussian_inverse_cdf(uniform_samples, Mu, Sigma)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax = sns.jointplot(np.array(gaussian_samples).astype(<span style=color:#fff;font-weight:700>float</span>), uniform_samples, marginal_kws=<span style=color:#fff;font-weight:700>dict</span>(bins=<span style=color:#ff0;font-weight:700>30</span>, rug=<span style=color:#fff;font-weight:700>True</span>),
</span></span><span style=display:flex><span>             joint_kws=<span style=color:#fff;font-weight:700>dict</span>(alpha=<span style=color:#ff0;font-weight:700>0.5</span>, linewidth=<span style=color:#fff;font-weight:700>None</span>, marker=<span style=color:#0ff;font-weight:700>&#39;x&#39;</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>spanFrom, spanTo = Mu - <span style=color:#ff0;font-weight:700>4</span> * Sigma, Mu + <span style=color:#ff0;font-weight:700>4</span> * Sigma
</span></span><span style=display:flex><span>span = np.linspace(spanFrom, spanTo, <span style=color:#ff0;font-weight:700>100</span>)
</span></span><span style=display:flex><span>ax.ax_joint.plot(span, gaussian_cdf(span, Mu, Sigma), color=<span style=color:#0ff;font-weight:700>&#39;red&#39;</span>, label=<span style=color:#0ff;font-weight:700>&#39;CDF&#39;</span>)
</span></span><span style=display:flex><span>ax.fig.set_figwidth(<span style=color:#ff0;font-weight:700>6</span>)
</span></span><span style=display:flex><span>ax.fig.set_figheight(<span style=color:#ff0;font-weight:700>4</span>)
</span></span><span style=display:flex><span>ax.set_axis_labels(<span style=color:#0ff;font-weight:700>&#39;Mapped to Gaussian using inverse CDF&#39;</span>, <span style=color:#0ff;font-weight:700>&#39;Uniformly sampled points&#39;</span>, fontsize=<span style=color:#ff0;font-weight:700>10</span>)
</span></span></code></pre></div><pre><code>&lt;seaborn.axisgrid.JointGrid at 0x7f2462c25b10&gt;
</code></pre><p><img src=./index_38_1.png alt=png></p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>fig, ax = plt.subplots(<span style=color:#ff0;font-weight:700>1</span>, <span style=color:#ff0;font-weight:700>1</span>, figsize=(<span style=color:#ff0;font-weight:700>6</span>, <span style=color:#ff0;font-weight:700>3</span>))
</span></span><span style=display:flex><span>ax.hist(gaussian_samples, bins=<span style=color:#ff0;font-weight:700>31</span>, density=<span style=color:#fff;font-weight:700>True</span>, label=<span style=color:#0ff;font-weight:700>&#39;Sampled using inverse transform&#39;</span>)
</span></span><span style=display:flex><span>spanFrom, spanTo = Mu - <span style=color:#ff0;font-weight:700>4</span> * Sigma, Mu + <span style=color:#ff0;font-weight:700>4</span> * Sigma
</span></span><span style=display:flex><span>span = np.linspace(spanFrom, spanTo, <span style=color:#ff0;font-weight:700>100</span>)
</span></span><span style=display:flex><span>ax.plot(span, gaussian_pdf(span, Mu, Sigma), color=<span style=color:#0ff;font-weight:700>&#39;red&#39;</span>, label=<span style=color:#0ff;font-weight:700>&#39;Analytical CDF&#39;</span>)
</span></span><span style=display:flex><span>ax.set(xlabel=<span style=color:#0ff;font-weight:700>&#39;$x$&#39;</span>, ylabel=<span style=color:#0ff;font-weight:700>&#39;$p = f(x)$&#39;</span>, title=<span style=color:#0ff;font-weight:700>&#39;$X \sim \mathcal</span><span style=color:#0ff;font-weight:700>{N}</span><span style=color:#0ff;font-weight:700> (&#39;</span> + <span style=color:#fff;font-weight:700>str</span>(Mu) + <span style=color:#0ff;font-weight:700>&#34;, &#34;</span> + <span style=color:#fff;font-weight:700>str</span>(Sigma**<span style=color:#ff0;font-weight:700>2</span>) + <span style=color:#0ff;font-weight:700>&#34;)$&#34;</span>)
</span></span><span style=display:flex><span>ax.legend(loc=<span style=color:#0ff;font-weight:700>&#39;upper left&#39;</span>)
</span></span></code></pre></div><pre><code>&lt;matplotlib.legend.Legend at 0x7f24509bdf90&gt;
</code></pre><p><img src=./index_39_1.png alt=png></p><h2 id=inverse-transform-sampling-for-exponential-distribution>Inverse transform sampling for Exponential distribution
<a class=heading-link href=#inverse-transform-sampling-for-exponential-distribution><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>First, define exponential distribution PDF.</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>x, lambd, p = sp.symbols(<span style=color:#0ff;font-weight:700>&#39;x, lambda, p&#39;</span>, positive = <span style=color:#fff;font-weight:700>True</span>)
</span></span><span style=display:flex><span>pdf_exponential = lambd * sp.exp(-lambd * x)
</span></span><span style=display:flex><span>display(pdf_exponential)
</span></span></code></pre></div><p>$\displaystyle \lambda e^{- \lambda x}$</p><p>Second, integrate PDF to obtain CDF.</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>cdf_exponential = <span style=color:#ff0;font-weight:700>1.0</span> + sp.integrate(pdf_exponential, x)
</span></span><span style=display:flex><span>display(cdf_exponential)
</span></span></code></pre></div><p>$\displaystyle 1.0 - e^{- \lambda x}$</p><p>Third, invert it.</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>inverse_cdf_exponential = sp.solve(cdf_exponential - p, x)
</span></span><span style=display:flex><span>display(inverse_cdf_exponential)
</span></span></code></pre></div><p>$\displaystyle \left[ \frac{\log{\left(- \frac{1}{p - 1.0} \right)}}{\lambda}\right]$</p><p>Now we are ready to transform samples from uniform space to the exponential one.</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>Lambda = <span style=color:#ff0;font-weight:700>1.25</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>exponential_pdf = sp.lambdify((x, lambd), pdf_exponential)
</span></span><span style=display:flex><span>exponential_cdf = sp.lambdify((x, lambd), cdf_exponential)
</span></span><span style=display:flex><span>exponential_inverse_cdf = sp.lambdify((p, lambd), inverse_cdf_exponential)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>uniform_samples = np.random.uniform(size=<span style=color:#ff0;font-weight:700>5000</span>)
</span></span><span style=display:flex><span>exponential_samples = exponential_inverse_cdf(uniform_samples, Lambda)[<span style=color:#ff0;font-weight:700>0</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax = sns.jointplot(exponential_samples, uniform_samples, marginal_kws=<span style=color:#fff;font-weight:700>dict</span>(bins=<span style=color:#ff0;font-weight:700>30</span>, rug=<span style=color:#fff;font-weight:700>True</span>),
</span></span><span style=display:flex><span>             joint_kws=<span style=color:#fff;font-weight:700>dict</span>(alpha=<span style=color:#ff0;font-weight:700>0.5</span>, linewidth=<span style=color:#fff;font-weight:700>None</span>, marker=<span style=color:#0ff;font-weight:700>&#39;x&#39;</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>spanFrom, spanTo = <span style=color:#ff0;font-weight:700>0.0</span>, exponential_inverse_cdf(<span style=color:#ff0;font-weight:700>0.9999</span>, Lambda)
</span></span><span style=display:flex><span>span = np.linspace(spanFrom, spanTo, <span style=color:#ff0;font-weight:700>100</span>)
</span></span><span style=display:flex><span>ax.ax_joint.plot(span, exponential_cdf(span, Lambda), color=<span style=color:#0ff;font-weight:700>&#39;red&#39;</span>, label=<span style=color:#0ff;font-weight:700>&#39;CDF&#39;</span>)
</span></span><span style=display:flex><span>ax.fig.set_figwidth(<span style=color:#ff0;font-weight:700>6</span>)
</span></span><span style=display:flex><span>ax.fig.set_figheight(<span style=color:#ff0;font-weight:700>4</span>)
</span></span><span style=display:flex><span>ax.set_axis_labels(<span style=color:#0ff;font-weight:700>&#39;Mapped to Exponential using inverse CDF&#39;</span>, <span style=color:#0ff;font-weight:700>&#39;Uniformly sampled points&#39;</span>, fontsize=<span style=color:#ff0;font-weight:700>10</span>)
</span></span></code></pre></div><pre><code>&lt;seaborn.axisgrid.JointGrid at 0x7f246350dd50&gt;
</code></pre><p><img src=./index_48_1.png alt=png></p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>fig, ax = plt.subplots(<span style=color:#ff0;font-weight:700>1</span>, <span style=color:#ff0;font-weight:700>1</span>, figsize=(<span style=color:#ff0;font-weight:700>6</span>, <span style=color:#ff0;font-weight:700>3</span>))
</span></span><span style=display:flex><span>ax.hist(exponential_samples, bins=<span style=color:#ff0;font-weight:700>31</span>, density=<span style=color:#fff;font-weight:700>True</span>, label=<span style=color:#0ff;font-weight:700>&#39;Sampled using inverse transform&#39;</span>)
</span></span><span style=display:flex><span>spanFrom, spanTo = <span style=color:#ff0;font-weight:700>0.0</span>, exponential_inverse_cdf(<span style=color:#ff0;font-weight:700>0.9999</span>, Lambda)
</span></span><span style=display:flex><span>span = np.linspace(spanFrom, spanTo, <span style=color:#ff0;font-weight:700>100</span>)
</span></span><span style=display:flex><span>ax.plot(span, exponential_pdf(span, Lambda), color=<span style=color:#0ff;font-weight:700>&#39;red&#39;</span>, label=<span style=color:#0ff;font-weight:700>&#39;Analytical CDF&#39;</span>)
</span></span><span style=display:flex><span>ax.set(xlabel=<span style=color:#0ff;font-weight:700>&#39;$x$&#39;</span>, ylabel=<span style=color:#0ff;font-weight:700>&#39;$p = f(x)$&#39;</span>, 
</span></span><span style=display:flex><span>       title=<span style=color:#0ff;font-weight:700>&#39;$X \sim Exp(&#39;</span> + <span style=color:#fff;font-weight:700>str</span>(Lambda) + <span style=color:#0ff;font-weight:700>&#34;)$&#34;</span>)
</span></span><span style=display:flex><span>ax.legend(loc=<span style=color:#0ff;font-weight:700>&#39;upper right&#39;</span>)
</span></span></code></pre></div><pre><code>&lt;matplotlib.legend.Legend at 0x7f24507760d0&gt;
</code></pre><p><img src=./index_49_1.png alt=png></p><h1 id=sampling-from-experimental-distribution>Sampling from experimental distribution
<a class=heading-link href=#sampling-from-experimental-distribution><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><p>Now assume that we have experimentally gathered data and we can visualize it using histogram. How we can sample from it?
One of the easiest approaches can be the following:</p><ul><li>Approximate the histogram with a polynom.</li><li>Find polynom inverse.</li><li>Sample using inverse transform.</li></ul><p>However, finding polynom inverse analytically is not easy task. So, instead of finding it analytiall we can just solve for the root numerically each time.</p><p>For example, let&rsquo;s simulate experimental data:</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>data = np.hstack([np.random.normal(<span style=color:#ff0;font-weight:700>6.0</span>, <span style=color:#ff0;font-weight:700>1.0</span>, <span style=color:#ff0;font-weight:700>10000</span>), np.random.gumbel(<span style=color:#ff0;font-weight:700>1.5</span>, <span style=color:#ff0;font-weight:700>0.5</span>, <span style=color:#ff0;font-weight:700>10000</span>)])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, ax = plt.subplots(<span style=color:#ff0;font-weight:700>1</span>, <span style=color:#ff0;font-weight:700>1</span>, figsize=(<span style=color:#ff0;font-weight:700>6</span>, <span style=color:#ff0;font-weight:700>3</span>))
</span></span><span style=display:flex><span>ax.hist(data, bins=<span style=color:#ff0;font-weight:700>100</span>, density=<span style=color:#fff;font-weight:700>True</span>);
</span></span></code></pre></div><p><img src=./index_52_0.png alt=png></p><p>Fit polynom to the histogram CDF and define inverse CDF as a function which finds the root:</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#fff;font-weight:700>from</span> scipy <span style=color:#fff;font-weight:700>import</span> interpolate
</span></span><span style=display:flex><span><span style=color:#fff;font-weight:700>import</span> scipy.optimize <span style=color:#fff;font-weight:700>as</span> scop
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>heights, bins = np.histogram(data, bins=<span style=color:#ff0;font-weight:700>100</span>, density=<span style=color:#fff;font-weight:700>True</span>)
</span></span><span style=display:flex><span>histogram_cdf = np.hstack([<span style=color:#ff0;font-weight:700>0</span>, np.cumsum(heights * np.diff(bins))])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>experimental_cdf = interpolate.interp1d(bins, histogram_cdf, fill_value=<span style=color:#0ff;font-weight:700>&#34;extrapolate&#34;</span>)
</span></span><span style=display:flex><span>experimental_inverse_cdf = <span style=color:#fff;font-weight:700>lambda</span> p: scop.fsolve(<span style=color:#fff;font-weight:700>lambda</span> x : experimental_cdf(x) - p, <span style=color:#ff0;font-weight:700>0.0</span>)[<span style=color:#ff0;font-weight:700>0</span>]
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>uniform_samples = np.random.uniform(size=<span style=color:#ff0;font-weight:700>5000</span>)
</span></span><span style=display:flex><span>experimental_samples = [experimental_inverse_cdf(u) <span style=color:#fff;font-weight:700>for</span> u in uniform_samples];
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax = sns.jointplot(experimental_samples, uniform_samples, marginal_kws=<span style=color:#fff;font-weight:700>dict</span>(bins=<span style=color:#ff0;font-weight:700>30</span>, rug=<span style=color:#fff;font-weight:700>True</span>),
</span></span><span style=display:flex><span>             joint_kws=<span style=color:#fff;font-weight:700>dict</span>(alpha=<span style=color:#ff0;font-weight:700>0.5</span>, linewidth=<span style=color:#fff;font-weight:700>None</span>, marker=<span style=color:#0ff;font-weight:700>&#39;x&#39;</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>spanFrom, spanTo = <span style=color:#ff0;font-weight:700>0.0</span>, experimental_inverse_cdf(<span style=color:#ff0;font-weight:700>0.9999</span>)
</span></span><span style=display:flex><span>span = np.linspace(spanFrom, spanTo, <span style=color:#ff0;font-weight:700>100</span>)
</span></span><span style=display:flex><span>ax.ax_joint.plot(span, experimental_cdf(span), color=<span style=color:#0ff;font-weight:700>&#39;red&#39;</span>, label=<span style=color:#0ff;font-weight:700>&#39;CDF&#39;</span>)
</span></span><span style=display:flex><span>ax.fig.set_figwidth(<span style=color:#ff0;font-weight:700>6</span>)
</span></span><span style=display:flex><span>ax.fig.set_figheight(<span style=color:#ff0;font-weight:700>4</span>)
</span></span><span style=display:flex><span>ax.set_axis_labels(<span style=color:#0ff;font-weight:700>&#39;Mapped to Experimental distribution using inverse CDF&#39;</span>, <span style=color:#0ff;font-weight:700>&#39;Uniformly sampled points&#39;</span>, fontsize=<span style=color:#ff0;font-weight:700>10</span>)
</span></span></code></pre></div><pre><code>&lt;seaborn.axisgrid.JointGrid at 0x7f24508bb950&gt;
</code></pre><p><img src=./index_55_2.png alt=png></p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>fig, ax = plt.subplots(<span style=color:#ff0;font-weight:700>1</span>, <span style=color:#ff0;font-weight:700>1</span>, figsize=(<span style=color:#ff0;font-weight:700>6</span>, <span style=color:#ff0;font-weight:700>3</span>))
</span></span><span style=display:flex><span>ax.hist(data, bins=<span style=color:#ff0;font-weight:700>31</span>, density=<span style=color:#fff;font-weight:700>True</span>, label=<span style=color:#0ff;font-weight:700>&#39;True data&#39;</span>, alpha=<span style=color:#ff0;font-weight:700>0.5</span>)
</span></span><span style=display:flex><span>ax.hist(experimental_samples, bins=<span style=color:#ff0;font-weight:700>31</span>, density=<span style=color:#fff;font-weight:700>True</span>, label=<span style=color:#0ff;font-weight:700>&#39;Sampled using inverse transform&#39;</span>, alpha=<span style=color:#ff0;font-weight:700>0.5</span>)
</span></span><span style=display:flex><span>ax.set(xlabel=<span style=color:#0ff;font-weight:700>&#39;$x$&#39;</span>, ylabel=<span style=color:#0ff;font-weight:700>&#39;$p = f(x)$&#39;</span>, title=<span style=color:#0ff;font-weight:700>&#39;Experimental data vs Sampled from experimental distribution&#39;</span>)
</span></span><span style=display:flex><span>ax.legend(loc=<span style=color:#0ff;font-weight:700>&#39;upper right&#39;</span>)
</span></span></code></pre></div><pre><code>&lt;matplotlib.legend.Legend at 0x7f244fb17a10&gt;
</code></pre><p><img src=./index_56_1.png alt=png></p><p>It works, however, its not efficient, because to find inverse CDF we have to numerically solve equation $F(x) - p = 0$. To overcome this computational overhead it is much better to just swap $x$ and $y$ on interpolation step. By doing so we directly obtain required inverse CDF for newly generated dataset:</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>data = np.hstack([np.random.normal(<span style=color:#ff0;font-weight:700>4.0</span>, <span style=color:#ff0;font-weight:700>2.0</span>, <span style=color:#ff0;font-weight:700>10000</span>), 
</span></span><span style=display:flex><span>                  np.random.gumbel(<span style=color:#ff0;font-weight:700>0.5</span>, <span style=color:#ff0;font-weight:700>0.5</span>, <span style=color:#ff0;font-weight:700>10000</span>), 
</span></span><span style=display:flex><span>                  np.random.gumbel(<span style=color:#ff0;font-weight:700>7.5</span>, <span style=color:#ff0;font-weight:700>1.0</span>, <span style=color:#ff0;font-weight:700>10000</span>),
</span></span><span style=display:flex><span>                  np.random.normal(<span style=color:#ff0;font-weight:700>13.5</span>, <span style=color:#ff0;font-weight:700>1.0</span>, <span style=color:#ff0;font-weight:700>10000</span>)])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>heights, bins = np.histogram(data, bins=<span style=color:#ff0;font-weight:700>100</span>, density=<span style=color:#fff;font-weight:700>True</span>)
</span></span><span style=display:flex><span>histogram_cdf = np.hstack([<span style=color:#ff0;font-weight:700>0</span>, np.cumsum(heights * np.diff(bins))])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>experimental_cdf = interpolate.interp1d(bins, histogram_cdf, fill_value=<span style=color:#0ff;font-weight:700>&#34;extrapolate&#34;</span>)
</span></span><span style=display:flex><span>experimental_inverse_cdf = interpolate.interp1d(histogram_cdf, bins, fill_value=<span style=color:#0ff;font-weight:700>&#34;extrapolate&#34;</span>)
</span></span></code></pre></div><p>And we can use this function directly:</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>uniform_samples = np.random.uniform(size=<span style=color:#ff0;font-weight:700>5000</span>)
</span></span><span style=display:flex><span>experimental_samples = [experimental_inverse_cdf(u) <span style=color:#fff;font-weight:700>for</span> u in uniform_samples]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax = sns.jointplot(experimental_samples, uniform_samples, marginal_kws=<span style=color:#fff;font-weight:700>dict</span>(bins=<span style=color:#ff0;font-weight:700>30</span>, rug=<span style=color:#fff;font-weight:700>True</span>),
</span></span><span style=display:flex><span>             joint_kws=<span style=color:#fff;font-weight:700>dict</span>(alpha=<span style=color:#ff0;font-weight:700>0.5</span>, linewidth=<span style=color:#fff;font-weight:700>None</span>, marker=<span style=color:#0ff;font-weight:700>&#39;x&#39;</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>spanFrom, spanTo = <span style=color:#ff0;font-weight:700>0.0</span>, experimental_inverse_cdf(<span style=color:#ff0;font-weight:700>0.9999</span>)
</span></span><span style=display:flex><span>span = np.linspace(spanFrom, spanTo, <span style=color:#ff0;font-weight:700>100</span>)
</span></span><span style=display:flex><span>ax.ax_joint.plot(span, experimental_cdf(span), color=<span style=color:#0ff;font-weight:700>&#39;red&#39;</span>, label=<span style=color:#0ff;font-weight:700>&#39;CDF&#39;</span>)
</span></span><span style=display:flex><span>ax.fig.set_figwidth(<span style=color:#ff0;font-weight:700>6</span>)
</span></span><span style=display:flex><span>ax.fig.set_figheight(<span style=color:#ff0;font-weight:700>4</span>)
</span></span><span style=display:flex><span>ax.set_axis_labels(<span style=color:#0ff;font-weight:700>&#39;Mapped to Experimental distribution using inverse CDF&#39;</span>, <span style=color:#0ff;font-weight:700>&#39;Uniformly sampled points&#39;</span>, fontsize=<span style=color:#ff0;font-weight:700>10</span>)
</span></span></code></pre></div><pre><code>&lt;seaborn.axisgrid.JointGrid at 0x7f244fa194d0&gt;
</code></pre><p><img src=./index_60_1.png alt=png></p><p>Compare with experimental distribution:</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>fig, ax = plt.subplots(<span style=color:#ff0;font-weight:700>1</span>, <span style=color:#ff0;font-weight:700>1</span>, figsize=(<span style=color:#ff0;font-weight:700>6</span>, <span style=color:#ff0;font-weight:700>3</span>))
</span></span><span style=display:flex><span>ax.hist(data, bins=<span style=color:#ff0;font-weight:700>31</span>, density=<span style=color:#fff;font-weight:700>True</span>, label=<span style=color:#0ff;font-weight:700>&#39;True data&#39;</span>, alpha=<span style=color:#ff0;font-weight:700>0.5</span>)
</span></span><span style=display:flex><span>ax.hist(experimental_samples, bins=<span style=color:#ff0;font-weight:700>31</span>, density=<span style=color:#fff;font-weight:700>True</span>, label=<span style=color:#0ff;font-weight:700>&#39;Sampled using inverse transform&#39;</span>, alpha=<span style=color:#ff0;font-weight:700>0.5</span>)
</span></span><span style=display:flex><span>ax.set(xlabel=<span style=color:#0ff;font-weight:700>&#39;$x$&#39;</span>, ylabel=<span style=color:#0ff;font-weight:700>&#39;$p = f(x)$&#39;</span>, title=<span style=color:#0ff;font-weight:700>&#39;Experimental data vs Sampled from experimental distribution&#39;</span>)
</span></span><span style=display:flex><span>ax.legend(loc=<span style=color:#0ff;font-weight:700>&#39;upper right&#39;</span>)
</span></span></code></pre></div><pre><code>&lt;matplotlib.legend.Legend at 0x7f244f3d53d0&gt;
</code></pre><p><img src=./index_62_1.png alt=png></p><h1 id=conclusions>Conclusions
<a class=heading-link href=#conclusions><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><p>After all, it should become clear what inverse transform sampling actually does and how to sample from any distribution, which inverse CDF can be derived.
In the next posts I am planning to show some examples on rejection, Metropolis Hastings and Gibbs sampling. These methods are usually used when direct sampling from probability distribution is difficult.</p></div><footer><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//mikoff-github-io.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}(),document.addEventListener("themeChanged",function(){document.readyState=="complete"&&DISQUS.reset({reload:!0,config:disqus_config})})</script></footer></article><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0 crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})'></script></section></div><footer class=footer><section class=container>©
2024
Aleksandr Mikoff
·
Powered by <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/ target=_blank rel=noopener>Coder</a>.</section></footer></main><script src=/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script></body></html>