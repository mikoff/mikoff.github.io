<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Backpropagation on Aleksandr Mikoff's blog</title><link>https://mikoff.github.io/tags/backpropagation/</link><description>Recent content in Backpropagation on Aleksandr Mikoff's blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 19 Feb 2022 23:00:00 +0300</lastBuildDate><atom:link href="https://mikoff.github.io/tags/backpropagation/index.xml" rel="self" type="application/rss+xml"/><item><title>Notes on backpropagation</title><link>https://mikoff.github.io/posts/notes-on-backpropagation/</link><pubDate>Sat, 19 Feb 2022 23:00:00 +0300</pubDate><guid>https://mikoff.github.io/posts/notes-on-backpropagation/</guid><description>Notes on backpropagation Link to heading In optimization and machine learning applications the widely used tool for finding the model parameters is the gradient descent. It allows to find the maximum or minimum of the target function w.r.t. the parameters, in other words, to minimize the discrepancy between the model and the data.
However, to use this method the gradient has to be computed. The first problem is that if our function has a complex form the process of differentiating is quite tricky.</description></item></channel></rss>